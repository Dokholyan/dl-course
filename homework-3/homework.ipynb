{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5WVASxK_7oqI"
   },
   "source": [
    "# Homework 3\n",
    "\n",
    "Hi! Today you have a difficult task.\n",
    "You need to implement two ideas to upgrade the metric learning pipeline: HardClusterSampler and HierarchicalTripletLoss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Nb5_yl-aVDxT"
   },
   "outputs": [],
   "source": [
    "# !pip install -U catalyst albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "zn1ibXQbVHhN"
   },
   "outputs": [],
   "source": [
    "from catalyst.utils import set_global_seed\n",
    "\n",
    "\n",
    "set_global_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NcERM9BxVH1F"
   },
   "source": [
    "# Metric Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "BxWXtT02VJSV"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P3Ag8n9LVNXY"
   },
   "source": [
    "## Omniglot\n",
    "\n",
    "Remember dataset: [Omniglot](https://github.com/brendenlake/omniglot). It contains 1623 different handwritten characters from 50 different alphabets. They have been written by 20 different people and collect via Amazon's Mechanical Turk. Some of the characters are presented on the picture:\n",
    "\n",
    "![photo](https://raw.githubusercontent.com/brendenlake/omniglot/master/omniglot_grid.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "SeSQX6O2VOJz"
   },
   "outputs": [],
   "source": [
    "# Download dataset\n",
    "# !git clone https://github.com/brendenlake/omniglot\n",
    "# !unzip omniglot/python/images_background\n",
    "# !unzip omniglot/python/images_evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ek5rO5bIJtb"
   },
   "source": [
    "Look at the file structure. Each folder is called after alphabetic system and contains character's folder with drawn examples.\n",
    "\n",
    "Let's show the `a` character from the Latin alphabet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "PpXIVViPqWTv"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 15 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "latin_a = Path(\"images_background/Latin/character01\")\n",
    "paths = list(latin_a.glob(\"*.png\"))\n",
    "\n",
    "_, axs = plt.subplots(3, 5, figsize=(15, 10))\n",
    "\n",
    "for i in range(15):\n",
    "    image = Image.open(paths[i])\n",
    "    axs[i % 3][i % 5].imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pnzArRZjIpAk"
   },
   "source": [
    "We use `images_background` as train part of dataset and `images_evaluation` as valid part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "SLKviaYGBCkI"
   },
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"train\": {\"labels\": [], \"image_paths\": [], \"cls2label\": {}, \"root\": Path(\"images_background\")},\n",
    "    \"valid\": {\"labels\": [], \"image_paths\": [], \"cls2label\": {}, \"root\": Path(\"images_evaluation\")}\n",
    "}\n",
    "\n",
    "for part in data:\n",
    "    cur_part = data[part]\n",
    "    for alphabet_path in cur_part[\"root\"].iterdir():\n",
    "        for ch in alphabet_path.iterdir():\n",
    "            cur_part[\"labels\"].extend(f\"{alphabet_path.name}_{ch.name}\" for _ in ch.glob(\"*.png\"))\n",
    "            cur_part[\"image_paths\"].extend(ch.glob(\"*.png\"))\n",
    "    \n",
    "    cur_part[\"labels\"] = np.array(cur_part[\"labels\"])\n",
    "    cur_part[\"image_paths\"] = np.array(cur_part[\"image_paths\"])\n",
    "    cur_part[\"cls2label\"] = {c: num for num, c in enumerate(np.unique(cur_part[\"labels\"]))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6RyJZHIgVO0p"
   },
   "source": [
    "## Metric Learning Pipeline\n",
    "\n",
    "Remember the Metric Learning pipeline in training stage\n",
    "\n",
    "![training stage](https://miro.medium.com/max/1400/1*_kwjkuV7MtJCCYriwwo3uA.png)\n",
    "\n",
    "and in validation stage \n",
    "\n",
    "![validating stage](https://miro.medium.com/max/1400/1*w3NVYqXA_e-EwWrvnvvrDw.png)\n",
    "\n",
    "\n",
    "(from [Metric Learning with Catalyst](https://medium.com/pytorch/metric-learning-with-catalyst-8c8337dfab1a) by [@AlexeySh](https://github.com/AlekseySh))\n",
    "\n",
    "To train model for Netric Learning objective, we need:\n",
    "\n",
    "- Metric Learning Dataset for training\n",
    "- Query/Gallery Dataset for validation\n",
    "- In-batch sampler of triplets\n",
    "- Triplet Loss criterion\n",
    "\n",
    "We have implemented this. But you need to understand some parts of this pipeline.\n",
    "That's why we left `HardTripletSampler` and `TripletMarginLossWithSampler`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-hO8W9rWAOJe"
   },
   "source": [
    "### Data Loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vbNLSRhki7HI"
   },
   "source": [
    "Metric Learning Dataset is similar with usual dataset. One difference is the `get_labels` method. It should return all labels in dataset. That used for class balanced batch sampler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "jjPyLMj0bucU"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from catalyst.utils import imread\n",
    "from catalyst.data import (\n",
    "    MetricLearningTrainDataset,\n",
    "    QueryGalleryDataset,\n",
    ")\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class OmniGlotMLDataset(MetricLearningTrainDataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        images,\n",
    "        targets,\n",
    "        transform=None\n",
    "    ):\n",
    "        self.images = images\n",
    "        self.targets = targets\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img, target = self.images[index], int(self.targets[index])\n",
    "        img = imread(img)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(image=img)[\"image\"].mean(0, keepdims=True)\n",
    "        \n",
    "        return img, target\n",
    "\n",
    "    # The most important method!\n",
    "    def get_labels(self):\n",
    "        return self.targets.tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.images.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x9UymmY4jnSz"
   },
   "source": [
    "For validation, we need to create an Query-Gallery Dataset. Some of the object must be marked as query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "gi_-V_dpqWNw"
   },
   "outputs": [],
   "source": [
    "class OmniGlotQGDataset(QueryGalleryDataset):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        images,\n",
    "        targets,\n",
    "        transform=None,\n",
    "        gallery_fraq=0.2,\n",
    "    ):\n",
    "        self._omniglot = OmniGlotMLDataset(\n",
    "            images=images, targets=targets, transform=transform\n",
    "        )\n",
    "\n",
    "        self._is_query = np.zeros(len(self._omniglot)).astype(bool)\n",
    "        labels = np.array(self._omniglot.get_labels())\n",
    "        self._query_size = 0\n",
    "        # creating query/gallery partition\n",
    "        for label in np.unique(targets):\n",
    "            query_size = \\\n",
    "                np.ceil(np.sum(labels == label) * gallery_fraq).astype(int)\n",
    "            # defining query size for current label\n",
    "            idx = np.arange(len(self._omniglot))[labels == label]\n",
    "            # indexes with current label\n",
    "            assert len(idx) >= query_size\n",
    "            \n",
    "            query_idx = np.random.choice(idx, size=query_size, replace=False)\n",
    "            # sampling query\n",
    "            self._is_query[query_idx] = True\n",
    "            # changing is_query flag\n",
    "            self._query_size += query_size\n",
    "            # incrementing query size\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        image, label = self._omniglot[idx]\n",
    "        return {\n",
    "            \"features\": image,\n",
    "            \"targets\": label,\n",
    "            \"is_query\": self._is_query[idx],\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._omniglot)\n",
    "\n",
    "    @property\n",
    "    def gallery_size(self):\n",
    "        return len(self._omniglot) - self._query_size\n",
    "\n",
    "    @property\n",
    "    def query_size(self):\n",
    "        return self._query_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wfMjYZUtJkxc"
   },
   "source": [
    "We won't use augmentation in our pipeline. But the reason we'll use `albumentations` is that it has convinient tools for the image preprocessing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "T0Hm6nievNak"
   },
   "outputs": [],
   "source": [
    "import albumentations as albu\n",
    "from albumentations.pytorch import ToTensorV2 as ToTensor\n",
    "\n",
    "\n",
    "IMAGE_SIZE = 32\n",
    "\n",
    "transform = albu.Compose([\n",
    "    albu.LongestMaxSize(IMAGE_SIZE),\n",
    "    albu.PadIfNeeded(IMAGE_SIZE, IMAGE_SIZE, border_mode=0),\n",
    "    albu.Rotate(limit=30),\n",
    "    albu.Normalize(),\n",
    "    ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SH1oDudDK1Pc"
   },
   "source": [
    "Process train/valid data, create datasets and loaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ND43OdI9h7Q5"
   },
   "outputs": [],
   "source": [
    "train_images = data[\"train\"][\"image_paths\"]\n",
    "train_labels = data[\"train\"][\"labels\"]\n",
    "\n",
    "indexes = np.arange(train_images.shape[0])\n",
    "np.random.shuffle(indexes)\n",
    "train_images = train_images[indexes]\n",
    "train_targets = np.array([data[\"train\"][\"cls2label\"][c] for c in train_labels])[indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "lTryxzI1Atkc"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from catalyst.data import BalanceBatchSampler\n",
    "\n",
    "dataset_train = OmniGlotMLDataset(images=train_images, targets=train_targets, transform=transform)\n",
    "sampler = BalanceBatchSampler(labels=dataset_train.get_labels(), p=64, k=16)\n",
    "train_loader = DataLoader(dataset=dataset_train, sampler=sampler, batch_size=sampler.batch_size)\n",
    "\n",
    "valid_images = data[\"valid\"][\"image_paths\"]\n",
    "valid_labels = data[\"valid\"][\"labels\"]\n",
    "valid_targets = np.array([data[\"valid\"][\"cls2label\"][c] for c in valid_labels])\n",
    "\n",
    "dataset_valid = OmniGlotQGDataset(images=valid_images, targets=valid_targets, transform=transform, gallery_fraq=0.2)\n",
    "valid_loader = DataLoader(dataset=dataset_valid, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T8pjY2glAQnT"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "jfrefovqAjBk"
   },
   "outputs": [],
   "source": [
    "from itertools import combinations, product\n",
    "from random import sample, choices\n",
    "from sys import maxsize\n",
    "\n",
    "from catalyst.data import InBatchTripletsSampler\n",
    "from catalyst.contrib.utils.misc import find_value_ids\n",
    "from catalyst.data.utils import convert_labels2list\n",
    "from catalyst.utils.torch import normalize\n",
    "\n",
    "\n",
    "class HardTripletsSampler(InBatchTripletsSampler):\n",
    "    \"\"\"\n",
    "    This sampler selects hardest triplets based on distances between features:\n",
    "    the hardest positive sample has the maximal distance to the anchor sample,\n",
    "    the hardest negative sample has the minimal distance to the anchor sample.\n",
    "    Note that a typical triplet loss chart is as follows:\n",
    "    1. Falling: loss decreases to a value equal to the margin.\n",
    "    2. Long plato: the loss oscillates near the margin.\n",
    "    3. Falling: loss decreases to zero.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, norm_required=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            norm_required: set True if features normalisation is needed\n",
    "        \"\"\"\n",
    "        self._norm_required = norm_required\n",
    "\n",
    "    def _sample(self, features, labels):\n",
    "        \"\"\"\n",
    "        This method samples the hardest triplets inside the batch.\n",
    "        Args:\n",
    "            features: has the shape of [batch_size, feature_size]\n",
    "            labels: labels of the samples in the batch\n",
    "        Returns:\n",
    "            the batch of the triplets in the order below:\n",
    "            (anchor, positive, negative)\n",
    "        \"\"\"\n",
    "        assert features.shape[0] == len(labels)\n",
    "\n",
    "        if self._norm_required:\n",
    "            features = normalize(samples=features.detach())\n",
    "\n",
    "        dist_mat = torch.cdist(x1=features, x2=features, p=2)\n",
    "\n",
    "        ids_anchor, ids_pos, ids_neg = self._sample_from_distmat(\n",
    "            distmat=dist_mat, labels=labels\n",
    "        )\n",
    "\n",
    "        return ids_anchor, ids_pos, ids_neg\n",
    "\n",
    "    @staticmethod\n",
    "    def _sample_from_distmat(distmat, labels):\n",
    "        \"\"\"\n",
    "        This method samples the hardest triplets based on the given\n",
    "        distances matrix. It chooses each sample in the batch as an\n",
    "        anchor and then finds the harderst positive and negative pair.\n",
    "        Args:\n",
    "            distmat: matrix of distances between the features\n",
    "            labels: labels of the samples in the batch\n",
    "        Returns:\n",
    "            the batch of triplets in the order below:\n",
    "            (anchor, positive, negative)\n",
    "        \"\"\"\n",
    "        ids_all = set(range(len(labels)))\n",
    "\n",
    "        ids_anchor, ids_pos, ids_neg = [], [], []\n",
    "\n",
    "        for i_anch, label in enumerate(labels):\n",
    "            ids_label = set(find_value_ids(it=labels, value=label))\n",
    "\n",
    "            ids_pos_cur = np.array(list(ids_label - {i_anch}), int)\n",
    "            ids_neg_cur = np.array(list(ids_all - ids_label), int)\n",
    "\n",
    "            i_pos = ids_pos_cur[distmat[i_anch, ids_pos_cur].argmax()]\n",
    "            i_neg = ids_neg_cur[distmat[i_anch, ids_neg_cur].argmin()]\n",
    "\n",
    "            ids_anchor.append(i_anch)\n",
    "            ids_pos.append(i_pos)\n",
    "            ids_neg.append(i_neg)\n",
    "\n",
    "        return ids_anchor, ids_pos, ids_neg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pmlFkb9HLndy"
   },
   "source": [
    "Torch has the TripletLoss criterion. But it doesn't work with in-batch sampler. We must join these two enteties in new one. It has to sample triplets by the given rule and calculate triplet loss with the margin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "7q0UsHNtAkJs"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class TripletMarginLossWithSampler(nn.Module):\n",
    "    \"\"\"\n",
    "    This class combines in-batch sampling of triplets and\n",
    "    default TripletMargingLoss from PyTorch.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, margin, sampler_inbatch):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            margin: margin value\n",
    "            sampler_inbatch: sampler for forming triplets inside the batch\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self._sampler_inbatch = sampler_inbatch\n",
    "        self._triplet_margin_loss = nn.TripletMarginLoss(margin=margin)\n",
    "\n",
    "    def forward(self, features, labels):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            features: features with the shape of [batch_size, features_dim]\n",
    "            labels: labels of samples having batch_size elements\n",
    "        Returns: loss value\n",
    "        \"\"\"\n",
    "        labels_list = convert_labels2list(labels)\n",
    "\n",
    "        (\n",
    "            features_anchor,\n",
    "            features_positive,\n",
    "            features_negative,\n",
    "        ) = self._sampler_inbatch.sample(features=features, labels=labels_list)\n",
    "\n",
    "        loss = self._triplet_margin_loss(\n",
    "            anchor=features_anchor,\n",
    "            positive=features_positive,\n",
    "            negative=features_negative,\n",
    "        )\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FbHDxzRvMWNr"
   },
   "source": [
    "Create simple model with pretrained MobileNet backbone. It's able to increase training time. Good model must be trained for long time (several hundreads epochs). For educational purposes, we adjust train time to one epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catalyst.contrib.nn import Normalize\n",
    "\n",
    "\n",
    "def conv_block(in_feature, out_feature):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_feature, out_feature, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(out_feature),\n",
    "        nn.Dropout(0.2),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2, stride=2)\n",
    "    )\n",
    "\n",
    "model = nn.Sequential(\n",
    "    conv_block(1, 4),\n",
    "    conv_block(4, 8),\n",
    "    conv_block(8, 16),\n",
    "    conv_block(16, 32),\n",
    "    conv_block(32, 64),\n",
    "    nn.Flatten(),\n",
    "    Normalize()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "ULcfnZSWVUJI"
   },
   "outputs": [],
   "source": [
    "from catalyst import dl, utils\n",
    "from catalyst.contrib.nn import TripletMarginLossWithSampler, RAdam\n",
    "\n",
    "\n",
    "num_epochs = 300\n",
    "lr = 1e-2\n",
    "\n",
    "optimizer = RAdam(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, [100,])\n",
    "\n",
    "sampler_inbatch = HardTripletsSampler()\n",
    "criterion = TripletMarginLossWithSampler(margin=0.3, sampler_inbatch=sampler_inbatch)\n",
    "\n",
    "callbacks = [\n",
    "    dl.ControlFlowCallback(\n",
    "        dl.CriterionCallback(), \n",
    "        loaders=\"train\"\n",
    "    ),\n",
    "    dl.ControlFlowCallback(dl.CMCScoreCallback(topk_args=[1, 5, 10]), loaders=\"valid\"),\n",
    "    dl.PeriodicLoaderCallback(valid=10),\n",
    "    dl.SchedulerCallback(),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "DxUcNn0MB0HS",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/300 * Epoch (train):   6% 1/16 [00:19<04:46, 19.13s/it, loss=0.621]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adchumachenko/.local/lib/python3.6/site-packages/catalyst/contrib/nn/optimizers/radam.py:85: UserWarning:\n",
      "\n",
      "This overload of addcmul_ is deprecated:\n",
      "\taddcmul_(Number value, Tensor tensor1, Tensor tensor2)\n",
      "Consider using one of the following signatures instead:\n",
      "\taddcmul_(Tensor tensor1, Tensor tensor2, *, Number value) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/300 * Epoch (train): 100% 16/16 [00:30<00:00,  1.92s/it, loss=0.599]\n",
      "[2020-10-20 06:43:46,121] \n",
      "1/300 * Epoch 1 (_base): lr=0.0100 | momentum=0.9000\n",
      "1/300 * Epoch 1 (train): cmc05=-inf | loss=0.6017\n",
      "2/300 * Epoch (train):   0% 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adchumachenko/.local/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:396: UserWarning:\n",
      "\n",
      "To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.523]\n",
      "[2020-10-20 06:43:58,611] \n",
      "2/300 * Epoch 2 (_base): lr=0.0100 | momentum=0.9000\n",
      "2/300 * Epoch 2 (train): cmc05=-inf | loss=0.5527\n",
      "3/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.27it/s, loss=0.462]\n",
      "[2020-10-20 06:44:11,197] \n",
      "3/300 * Epoch 3 (_base): lr=0.0100 | momentum=0.9000\n",
      "3/300 * Epoch 3 (train): cmc05=-inf | loss=0.5130\n",
      "4/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.25it/s, loss=0.469]\n",
      "[2020-10-20 06:44:23,960] \n",
      "4/300 * Epoch 4 (_base): lr=0.0100 | momentum=0.9000\n",
      "4/300 * Epoch 4 (train): cmc05=-inf | loss=0.4916\n",
      "5/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.413]\n",
      "[2020-10-20 06:44:36,454] \n",
      "5/300 * Epoch 5 (_base): lr=0.0100 | momentum=0.9000\n",
      "5/300 * Epoch 5 (train): cmc05=-inf | loss=0.4783\n",
      "6/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.26it/s, loss=0.445]\n",
      "[2020-10-20 06:44:49,133] \n",
      "6/300 * Epoch 6 (_base): lr=0.0100 | momentum=0.9000\n",
      "6/300 * Epoch 6 (train): cmc05=-inf | loss=0.4623\n",
      "7/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.436]\n",
      "[2020-10-20 06:45:01,668] \n",
      "7/300 * Epoch 7 (_base): lr=0.0100 | momentum=0.9000\n",
      "7/300 * Epoch 7 (train): cmc05=-inf | loss=0.4446\n",
      "8/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.436]\n",
      "[2020-10-20 06:45:14,208] \n",
      "8/300 * Epoch 8 (_base): lr=0.0100 | momentum=0.9000\n",
      "8/300 * Epoch 8 (train): cmc05=-inf | loss=0.4400\n",
      "9/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.27it/s, loss=0.423]\n",
      "[2020-10-20 06:45:26,796] \n",
      "9/300 * Epoch 9 (_base): lr=0.0100 | momentum=0.9000\n",
      "9/300 * Epoch 9 (train): cmc05=-inf | loss=0.4391\n",
      "10/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.424]\n",
      "10/300 * Epoch (valid): 100% 52/52 [00:19<00:00,  2.64it/s]\n",
      "[2020-10-20 06:45:59,047] \n",
      "10/300 * Epoch 10 (_base): lr=0.0100 | momentum=0.9000\n",
      "10/300 * Epoch 10 (train): loss=0.4411\n",
      "10/300 * Epoch 10 (valid): cmc01=0.1233 | cmc05=0.2917 | cmc10=0.3919\n",
      "11/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.29it/s, loss=0.430]\n",
      "[2020-10-20 06:46:11,500] \n",
      "11/300 * Epoch 11 (_base): lr=0.0100 | momentum=0.9000\n",
      "11/300 * Epoch 11 (train): cmc05=-inf | loss=0.4372\n",
      "12/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.436]\n",
      "[2020-10-20 06:46:24,042] \n",
      "12/300 * Epoch 12 (_base): lr=0.0100 | momentum=0.9000\n",
      "12/300 * Epoch 12 (train): cmc05=-inf | loss=0.4358\n",
      "13/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.29it/s, loss=0.415]\n",
      "[2020-10-20 06:46:36,492] \n",
      "13/300 * Epoch 13 (_base): lr=0.0100 | momentum=0.9000\n",
      "13/300 * Epoch 13 (train): cmc05=-inf | loss=0.4349\n",
      "14/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.433]\n",
      "[2020-10-20 06:46:49,011] \n",
      "14/300 * Epoch 14 (_base): lr=0.0100 | momentum=0.9000\n",
      "14/300 * Epoch 14 (train): cmc05=-inf | loss=0.4328\n",
      "15/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.406]\n",
      "[2020-10-20 06:47:01,503] \n",
      "15/300 * Epoch 15 (_base): lr=0.0100 | momentum=0.9000\n",
      "15/300 * Epoch 15 (train): cmc05=-inf | loss=0.4348\n",
      "16/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.432]\n",
      "[2020-10-20 06:47:14,001] \n",
      "16/300 * Epoch 16 (_base): lr=0.0100 | momentum=0.9000\n",
      "16/300 * Epoch 16 (train): cmc05=-inf | loss=0.4357\n",
      "17/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.26it/s, loss=0.423]\n",
      "[2020-10-20 06:47:26,744] \n",
      "17/300 * Epoch 17 (_base): lr=0.0100 | momentum=0.9000\n",
      "17/300 * Epoch 17 (train): cmc05=-inf | loss=0.4329\n",
      "18/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.409]\n",
      "[2020-10-20 06:47:39,244] \n",
      "18/300 * Epoch 18 (_base): lr=0.0100 | momentum=0.9000\n",
      "18/300 * Epoch 18 (train): cmc05=-inf | loss=0.4310\n",
      "19/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.419]\n",
      "[2020-10-20 06:47:51,733] \n",
      "19/300 * Epoch 19 (_base): lr=0.0100 | momentum=0.9000\n",
      "19/300 * Epoch 19 (train): cmc05=-inf | loss=0.4336\n",
      "20/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.474]\n",
      "20/300 * Epoch (valid): 100% 52/52 [00:19<00:00,  2.70it/s]\n",
      "[2020-10-20 06:48:23,487] \n",
      "20/300 * Epoch 20 (_base): lr=0.0100 | momentum=0.9000\n",
      "20/300 * Epoch 20 (train): loss=0.4288\n",
      "20/300 * Epoch 20 (valid): cmc01=0.2060 | cmc05=0.4340 | cmc10=0.5565\n",
      "21/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.29it/s, loss=0.435]\n",
      "[2020-10-20 06:48:35,905] \n",
      "21/300 * Epoch 21 (_base): lr=0.0100 | momentum=0.9000\n",
      "21/300 * Epoch 21 (train): cmc05=-inf | loss=0.4298\n",
      "22/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.29it/s, loss=0.399]\n",
      "[2020-10-20 06:48:48,334] \n",
      "22/300 * Epoch 22 (_base): lr=0.0100 | momentum=0.9000\n",
      "22/300 * Epoch 22 (train): cmc05=-inf | loss=0.4295\n",
      "23/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.407]\n",
      "[2020-10-20 06:49:00,868] \n",
      "23/300 * Epoch 23 (_base): lr=0.0100 | momentum=0.9000\n",
      "23/300 * Epoch 23 (train): cmc05=-inf | loss=0.4278\n",
      "24/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.416]\n",
      "[2020-10-20 06:49:13,349] \n",
      "24/300 * Epoch 24 (_base): lr=0.0100 | momentum=0.9000\n",
      "24/300 * Epoch 24 (train): cmc05=-inf | loss=0.4275\n",
      "25/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.29it/s, loss=0.465]\n",
      "[2020-10-20 06:49:25,797] \n",
      "25/300 * Epoch 25 (_base): lr=0.0100 | momentum=0.9000\n",
      "25/300 * Epoch 25 (train): cmc05=-inf | loss=0.4239\n",
      "26/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.449]\n",
      "[2020-10-20 06:49:38,319] \n",
      "26/300 * Epoch 26 (_base): lr=0.0100 | momentum=0.9000\n",
      "26/300 * Epoch 26 (train): cmc05=-inf | loss=0.4273\n",
      "27/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.30it/s, loss=0.435]\n",
      "[2020-10-20 06:49:50,678] \n",
      "27/300 * Epoch 27 (_base): lr=0.0100 | momentum=0.9000\n",
      "27/300 * Epoch 27 (train): cmc05=-inf | loss=0.4234\n",
      "28/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.423]\n",
      "[2020-10-20 06:50:03,192] \n",
      "28/300 * Epoch 28 (_base): lr=0.0100 | momentum=0.9000\n",
      "28/300 * Epoch 28 (train): cmc05=-inf | loss=0.4256\n",
      "29/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.443]\n",
      "[2020-10-20 06:50:15,697] \n",
      "29/300 * Epoch 29 (_base): lr=0.0100 | momentum=0.9000\n",
      "29/300 * Epoch 29 (train): cmc05=-inf | loss=0.4259\n",
      "30/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.26it/s, loss=0.425]\n",
      "30/300 * Epoch (valid): 100% 52/52 [00:19<00:00,  2.72it/s]\n",
      "[2020-10-20 06:50:47,439] \n",
      "30/300 * Epoch 30 (_base): lr=0.0100 | momentum=0.9000\n",
      "30/300 * Epoch 30 (train): loss=0.4249\n",
      "30/300 * Epoch 30 (valid): cmc01=0.2731 | cmc05=0.5478 | cmc10=0.6574\n",
      "31/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.27it/s, loss=0.453]\n",
      "[2020-10-20 06:51:00,033] \n",
      "31/300 * Epoch 31 (_base): lr=0.0100 | momentum=0.9000\n",
      "31/300 * Epoch 31 (train): cmc05=-inf | loss=0.4255\n",
      "32/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.29it/s, loss=0.449]\n",
      "[2020-10-20 06:51:12,468] \n",
      "32/300 * Epoch 32 (_base): lr=0.0100 | momentum=0.9000\n",
      "32/300 * Epoch 32 (train): cmc05=-inf | loss=0.4252\n",
      "33/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.403]\n",
      "[2020-10-20 06:51:25,006] \n",
      "33/300 * Epoch 33 (_base): lr=0.0100 | momentum=0.9000\n",
      "33/300 * Epoch 33 (train): cmc05=-inf | loss=0.4246\n",
      "34/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.422]\n",
      "[2020-10-20 06:51:37,532] \n",
      "34/300 * Epoch 34 (_base): lr=0.0100 | momentum=0.9000\n",
      "34/300 * Epoch 34 (train): cmc05=-inf | loss=0.4231\n",
      "35/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.29it/s, loss=0.428]\n",
      "[2020-10-20 06:51:49,957] \n",
      "35/300 * Epoch 35 (_base): lr=0.0100 | momentum=0.9000\n",
      "35/300 * Epoch 35 (train): cmc05=-inf | loss=0.4224\n",
      "36/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.402]\n",
      "[2020-10-20 06:52:02,458] \n",
      "36/300 * Epoch 36 (_base): lr=0.0100 | momentum=0.9000\n",
      "36/300 * Epoch 36 (train): cmc05=-inf | loss=0.4202\n",
      "37/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.29it/s, loss=0.413]\n",
      "[2020-10-20 06:52:14,835] \n",
      "37/300 * Epoch 37 (_base): lr=0.0100 | momentum=0.9000\n",
      "37/300 * Epoch 37 (train): cmc05=-inf | loss=0.4216\n",
      "38/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.29it/s, loss=0.409]\n",
      "[2020-10-20 06:52:27,273] \n",
      "38/300 * Epoch 38 (_base): lr=0.0100 | momentum=0.9000\n",
      "38/300 * Epoch 38 (train): cmc05=-inf | loss=0.4228\n",
      "39/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.25it/s, loss=0.440]\n",
      "[2020-10-20 06:52:40,032] \n",
      "39/300 * Epoch 39 (_base): lr=0.0100 | momentum=0.9000\n",
      "39/300 * Epoch 39 (train): cmc05=-inf | loss=0.4211\n",
      "40/300 * Epoch (train): 100% 16/16 [00:13<00:00,  1.20it/s, loss=0.450]\n",
      "40/300 * Epoch (valid): 100% 52/52 [00:19<00:00,  2.64it/s]\n",
      "[2020-10-20 06:53:13,067] \n",
      "40/300 * Epoch 40 (_base): lr=0.0100 | momentum=0.9000\n",
      "40/300 * Epoch 40 (train): loss=0.4202\n",
      "40/300 * Epoch 40 (valid): cmc01=0.3376 | cmc05=0.5956 | cmc10=0.7026\n",
      "41/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.27it/s, loss=0.417]\n",
      "[2020-10-20 06:53:25,696] \n",
      "41/300 * Epoch 41 (_base): lr=0.0100 | momentum=0.9000\n",
      "41/300 * Epoch 41 (train): cmc05=-inf | loss=0.4204\n",
      "42/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.432]\n",
      "[2020-10-20 06:53:38,195] \n",
      "42/300 * Epoch 42 (_base): lr=0.0100 | momentum=0.9000\n",
      "42/300 * Epoch 42 (train): cmc05=-inf | loss=0.4198\n",
      "43/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.442]\n",
      "[2020-10-20 06:53:50,717] \n",
      "43/300 * Epoch 43 (_base): lr=0.0100 | momentum=0.9000\n",
      "43/300 * Epoch 43 (train): cmc05=-inf | loss=0.4163\n",
      "44/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.30it/s, loss=0.435]\n",
      "[2020-10-20 06:54:03,065] \n",
      "44/300 * Epoch 44 (_base): lr=0.0100 | momentum=0.9000\n",
      "44/300 * Epoch 44 (train): cmc05=-inf | loss=0.4217\n",
      "45/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.29it/s, loss=0.480]\n",
      "[2020-10-20 06:54:15,476] \n",
      "45/300 * Epoch 45 (_base): lr=0.0100 | momentum=0.9000\n",
      "45/300 * Epoch 45 (train): cmc05=-inf | loss=0.4198\n",
      "46/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.29it/s, loss=0.460]\n",
      "[2020-10-20 06:54:27,853] \n",
      "46/300 * Epoch 46 (_base): lr=0.0100 | momentum=0.9000\n",
      "46/300 * Epoch 46 (train): cmc05=-inf | loss=0.4214\n",
      "47/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.30it/s, loss=0.451]\n",
      "[2020-10-20 06:54:40,184] \n",
      "47/300 * Epoch 47 (_base): lr=0.0100 | momentum=0.9000\n",
      "47/300 * Epoch 47 (train): cmc05=-inf | loss=0.4221\n",
      "48/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.431]\n",
      "[2020-10-20 06:54:52,677] \n",
      "48/300 * Epoch 48 (_base): lr=0.0100 | momentum=0.9000\n",
      "48/300 * Epoch 48 (train): cmc05=-inf | loss=0.4177\n",
      "49/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.29it/s, loss=0.412]\n",
      "[2020-10-20 06:55:05,094] \n",
      "49/300 * Epoch 49 (_base): lr=0.0100 | momentum=0.9000\n",
      "49/300 * Epoch 49 (train): cmc05=-inf | loss=0.4207\n",
      "50/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.413]\n",
      "50/300 * Epoch (valid): 100% 52/52 [00:19<00:00,  2.67it/s]\n",
      "[2020-10-20 06:55:37,046] \n",
      "50/300 * Epoch 50 (_base): lr=0.0100 | momentum=0.9000\n",
      "50/300 * Epoch 50 (train): loss=0.4201\n",
      "50/300 * Epoch 50 (valid): cmc01=0.3574 | cmc05=0.6373 | cmc10=0.7394\n",
      "51/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.29it/s, loss=0.424]\n",
      "[2020-10-20 06:55:49,433] \n",
      "51/300 * Epoch 51 (_base): lr=0.0100 | momentum=0.9000\n",
      "51/300 * Epoch 51 (train): cmc05=-inf | loss=0.4186\n",
      "52/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.29it/s, loss=0.408]\n",
      "[2020-10-20 06:56:01,842] \n",
      "52/300 * Epoch 52 (_base): lr=0.0100 | momentum=0.9000\n",
      "52/300 * Epoch 52 (train): cmc05=-inf | loss=0.4165\n",
      "53/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.421]\n",
      "[2020-10-20 06:56:14,387] \n",
      "53/300 * Epoch 53 (_base): lr=0.0100 | momentum=0.9000\n",
      "53/300 * Epoch 53 (train): cmc05=-inf | loss=0.4182\n",
      "54/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.463]\n",
      "[2020-10-20 06:56:26,870] \n",
      "54/300 * Epoch 54 (_base): lr=0.0100 | momentum=0.9000\n",
      "54/300 * Epoch 54 (train): cmc05=-inf | loss=0.4184\n",
      "55/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.29it/s, loss=0.449]\n",
      "[2020-10-20 06:56:39,266] \n",
      "55/300 * Epoch 55 (_base): lr=0.0100 | momentum=0.9000\n",
      "55/300 * Epoch 55 (train): cmc05=-inf | loss=0.4167\n",
      "56/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.27it/s, loss=0.424]\n",
      "[2020-10-20 06:56:51,910] \n",
      "56/300 * Epoch 56 (_base): lr=0.0100 | momentum=0.9000\n",
      "56/300 * Epoch 56 (train): cmc05=-inf | loss=0.4159\n",
      "57/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.433]\n",
      "[2020-10-20 06:57:04,445] \n",
      "57/300 * Epoch 57 (_base): lr=0.0100 | momentum=0.9000\n",
      "57/300 * Epoch 57 (train): cmc05=-inf | loss=0.4192\n",
      "58/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.29it/s, loss=0.410]\n",
      "[2020-10-20 06:57:16,880] \n",
      "58/300 * Epoch 58 (_base): lr=0.0100 | momentum=0.9000\n",
      "58/300 * Epoch 58 (train): cmc05=-inf | loss=0.4167\n",
      "59/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.29it/s, loss=0.448]\n",
      "[2020-10-20 06:57:29,252] \n",
      "59/300 * Epoch 59 (_base): lr=0.0100 | momentum=0.9000\n",
      "59/300 * Epoch 59 (train): cmc05=-inf | loss=0.4161\n",
      "60/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.30it/s, loss=0.419]\n",
      "60/300 * Epoch (valid): 100% 52/52 [00:19<00:00,  2.71it/s]\n",
      "[2020-10-20 06:58:00,780] \n",
      "60/300 * Epoch 60 (_base): lr=0.0100 | momentum=0.9000\n",
      "60/300 * Epoch 60 (train): loss=0.4206\n",
      "60/300 * Epoch 60 (valid): cmc01=0.3942 | cmc05=0.6692 | cmc10=0.7701\n",
      "61/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.450]\n",
      "[2020-10-20 06:58:13,246] \n",
      "61/300 * Epoch 61 (_base): lr=0.0100 | momentum=0.9000\n",
      "61/300 * Epoch 61 (train): cmc05=-inf | loss=0.4150\n",
      "62/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.421]\n",
      "[2020-10-20 06:58:25,734] \n",
      "62/300 * Epoch 62 (_base): lr=0.0100 | momentum=0.9000\n",
      "62/300 * Epoch 62 (train): cmc05=-inf | loss=0.4184\n",
      "63/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.423]\n",
      "[2020-10-20 06:58:38,232] \n",
      "63/300 * Epoch 63 (_base): lr=0.0100 | momentum=0.9000\n",
      "63/300 * Epoch 63 (train): cmc05=-inf | loss=0.4152\n",
      "64/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.27it/s, loss=0.416]\n",
      "[2020-10-20 06:58:50,805] \n",
      "64/300 * Epoch 64 (_base): lr=0.0100 | momentum=0.9000\n",
      "64/300 * Epoch 64 (train): cmc05=-inf | loss=0.4166\n",
      "65/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.29it/s, loss=0.427]\n",
      "[2020-10-20 06:59:03,185] \n",
      "65/300 * Epoch 65 (_base): lr=0.0100 | momentum=0.9000\n",
      "65/300 * Epoch 65 (train): cmc05=-inf | loss=0.4136\n",
      "66/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.29it/s, loss=0.446]\n",
      "[2020-10-20 06:59:15,584] \n",
      "66/300 * Epoch 66 (_base): lr=0.0100 | momentum=0.9000\n",
      "66/300 * Epoch 66 (train): cmc05=-inf | loss=0.4167\n",
      "67/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.26it/s, loss=0.417]\n",
      "[2020-10-20 06:59:28,274] \n",
      "67/300 * Epoch 67 (_base): lr=0.0100 | momentum=0.9000\n",
      "67/300 * Epoch 67 (train): cmc05=-inf | loss=0.4170\n",
      "68/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.414]\n",
      "[2020-10-20 06:59:40,759] \n",
      "68/300 * Epoch 68 (_base): lr=0.0100 | momentum=0.9000\n",
      "68/300 * Epoch 68 (train): cmc05=-inf | loss=0.4125\n",
      "69/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.30it/s, loss=0.429]\n",
      "[2020-10-20 06:59:53,049] \n",
      "69/300 * Epoch 69 (_base): lr=0.0100 | momentum=0.9000\n",
      "69/300 * Epoch 69 (train): cmc05=-inf | loss=0.4166\n",
      "70/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.434]\n",
      "70/300 * Epoch (valid): 100% 52/52 [00:19<00:00,  2.67it/s]\n",
      "[2020-10-20 07:00:25,048] \n",
      "70/300 * Epoch 70 (_base): lr=0.0100 | momentum=0.9000\n",
      "70/300 * Epoch 70 (train): loss=0.4144\n",
      "70/300 * Epoch 70 (valid): cmc01=0.4010 | cmc05=0.6844 | cmc10=0.7803\n",
      "71/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.30it/s, loss=0.447]\n",
      "[2020-10-20 07:00:37,382] \n",
      "71/300 * Epoch 71 (_base): lr=0.0100 | momentum=0.9000\n",
      "71/300 * Epoch 71 (train): cmc05=-inf | loss=0.4141\n",
      "72/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.442]\n",
      "[2020-10-20 07:00:49,906] \n",
      "72/300 * Epoch 72 (_base): lr=0.0100 | momentum=0.9000\n",
      "72/300 * Epoch 72 (train): cmc05=-inf | loss=0.4157\n",
      "73/300 * Epoch (train): 100% 16/16 [00:13<00:00,  1.18it/s, loss=0.424]\n",
      "[2020-10-20 07:01:03,516] \n",
      "73/300 * Epoch 73 (_base): lr=0.0100 | momentum=0.9000\n",
      "73/300 * Epoch 73 (train): cmc05=-inf | loss=0.4111\n",
      "74/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.27it/s, loss=0.440]\n",
      "[2020-10-20 07:01:16,080] \n",
      "74/300 * Epoch 74 (_base): lr=0.0100 | momentum=0.9000\n",
      "74/300 * Epoch 74 (train): cmc05=-inf | loss=0.4140\n",
      "75/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.30it/s, loss=0.438]\n",
      "[2020-10-20 07:01:28,401] \n",
      "75/300 * Epoch 75 (_base): lr=0.0100 | momentum=0.9000\n",
      "75/300 * Epoch 75 (train): cmc05=-inf | loss=0.4147\n",
      "76/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.30it/s, loss=0.410]\n",
      "[2020-10-20 07:01:40,702] \n",
      "76/300 * Epoch 76 (_base): lr=0.0100 | momentum=0.9000\n",
      "76/300 * Epoch 76 (train): cmc05=-inf | loss=0.4161\n",
      "77/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.444]\n",
      "[2020-10-20 07:01:53,248] \n",
      "77/300 * Epoch 77 (_base): lr=0.0100 | momentum=0.9000\n",
      "77/300 * Epoch 77 (train): cmc05=-inf | loss=0.4105\n",
      "78/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.27it/s, loss=0.419]\n",
      "[2020-10-20 07:02:05,824] \n",
      "78/300 * Epoch 78 (_base): lr=0.0100 | momentum=0.9000\n",
      "78/300 * Epoch 78 (train): cmc05=-inf | loss=0.4141\n",
      "79/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.29it/s, loss=0.479]\n",
      "[2020-10-20 07:02:18,258] \n",
      "79/300 * Epoch 79 (_base): lr=0.0100 | momentum=0.9000\n",
      "79/300 * Epoch 79 (train): cmc05=-inf | loss=0.4138\n",
      "80/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.27it/s, loss=0.422]\n",
      "80/300 * Epoch (valid): 100% 52/52 [00:19<00:00,  2.62it/s]\n",
      "[2020-10-20 07:02:50,707] \n",
      "80/300 * Epoch 80 (_base): lr=0.0100 | momentum=0.9000\n",
      "80/300 * Epoch 80 (train): loss=0.4103\n",
      "80/300 * Epoch 80 (valid): cmc01=0.4317 | cmc05=0.7136 | cmc10=0.8050\n",
      "81/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.27it/s, loss=0.466]\n",
      "[2020-10-20 07:03:03,312] \n",
      "81/300 * Epoch 81 (_base): lr=0.0100 | momentum=0.9000\n",
      "81/300 * Epoch 81 (train): cmc05=-inf | loss=0.4138\n",
      "82/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.441]\n",
      "[2020-10-20 07:03:15,858] \n",
      "82/300 * Epoch 82 (_base): lr=0.0100 | momentum=0.9000\n",
      "82/300 * Epoch 82 (train): cmc05=-inf | loss=0.4126\n",
      "83/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.27it/s, loss=0.450]\n",
      "[2020-10-20 07:03:28,491] \n",
      "83/300 * Epoch 83 (_base): lr=0.0100 | momentum=0.9000\n",
      "83/300 * Epoch 83 (train): cmc05=-inf | loss=0.4105\n",
      "84/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.24it/s, loss=0.437]\n",
      "[2020-10-20 07:03:41,411] \n",
      "84/300 * Epoch 84 (_base): lr=0.0100 | momentum=0.9000\n",
      "84/300 * Epoch 84 (train): cmc05=-inf | loss=0.4117\n",
      "85/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.25it/s, loss=0.445]\n",
      "[2020-10-20 07:03:54,201] \n",
      "85/300 * Epoch 85 (_base): lr=0.0100 | momentum=0.9000\n",
      "85/300 * Epoch 85 (train): cmc05=-inf | loss=0.4128\n",
      "86/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.423]\n",
      "[2020-10-20 07:04:06,737] \n",
      "86/300 * Epoch 86 (_base): lr=0.0100 | momentum=0.9000\n",
      "86/300 * Epoch 86 (train): cmc05=-inf | loss=0.4143\n",
      "87/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.27it/s, loss=0.425]\n",
      "[2020-10-20 07:04:19,314] \n",
      "87/300 * Epoch 87 (_base): lr=0.0100 | momentum=0.9000\n",
      "87/300 * Epoch 87 (train): cmc05=-inf | loss=0.4130\n",
      "88/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.29it/s, loss=0.424]\n",
      "[2020-10-20 07:04:31,737] \n",
      "88/300 * Epoch 88 (_base): lr=0.0100 | momentum=0.9000\n",
      "88/300 * Epoch 88 (train): cmc05=-inf | loss=0.4110\n",
      "89/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.24it/s, loss=0.426]\n",
      "[2020-10-20 07:04:44,695] \n",
      "89/300 * Epoch 89 (_base): lr=0.0100 | momentum=0.9000\n",
      "89/300 * Epoch 89 (train): cmc05=-inf | loss=0.4099\n",
      "90/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.423]\n",
      "90/300 * Epoch (valid): 100% 52/52 [00:19<00:00,  2.68it/s]\n",
      "[2020-10-20 07:05:16,579] \n",
      "90/300 * Epoch 90 (_base): lr=0.0100 | momentum=0.9000\n",
      "90/300 * Epoch 90 (train): loss=0.4107\n",
      "90/300 * Epoch 90 (valid): cmc01=0.4275 | cmc05=0.7170 | cmc10=0.8190\n",
      "91/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.27it/s, loss=0.440]\n",
      "[2020-10-20 07:05:29,188] \n",
      "91/300 * Epoch 91 (_base): lr=0.0100 | momentum=0.9000\n",
      "91/300 * Epoch 91 (train): cmc05=-inf | loss=0.4095\n",
      "92/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.27it/s, loss=0.425]\n",
      "[2020-10-20 07:05:41,820] \n",
      "92/300 * Epoch 92 (_base): lr=0.0100 | momentum=0.9000\n",
      "92/300 * Epoch 92 (train): cmc05=-inf | loss=0.4103\n",
      "93/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.27it/s, loss=0.435]\n",
      "[2020-10-20 07:05:54,447] \n",
      "93/300 * Epoch 93 (_base): lr=0.0100 | momentum=0.9000\n",
      "93/300 * Epoch 93 (train): cmc05=-inf | loss=0.4115\n",
      "94/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.30it/s, loss=0.438]\n",
      "[2020-10-20 07:06:06,791] \n",
      "94/300 * Epoch 94 (_base): lr=0.0100 | momentum=0.9000\n",
      "94/300 * Epoch 94 (train): cmc05=-inf | loss=0.4105\n",
      "95/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.29it/s, loss=0.413]\n",
      "[2020-10-20 07:06:19,175] \n",
      "95/300 * Epoch 95 (_base): lr=0.0100 | momentum=0.9000\n",
      "95/300 * Epoch 95 (train): cmc05=-inf | loss=0.4092\n",
      "96/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.29it/s, loss=0.408]\n",
      "[2020-10-20 07:06:31,573] \n",
      "96/300 * Epoch 96 (_base): lr=0.0100 | momentum=0.9000\n",
      "96/300 * Epoch 96 (train): cmc05=-inf | loss=0.4102\n",
      "97/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.29it/s, loss=0.458]\n",
      "[2020-10-20 07:06:43,968] \n",
      "97/300 * Epoch 97 (_base): lr=0.0100 | momentum=0.9000\n",
      "97/300 * Epoch 97 (train): cmc05=-inf | loss=0.4088\n",
      "98/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.30it/s, loss=0.410]\n",
      "[2020-10-20 07:06:56,271] \n",
      "98/300 * Epoch 98 (_base): lr=0.0100 | momentum=0.9000\n",
      "98/300 * Epoch 98 (train): cmc05=-inf | loss=0.4120\n",
      "99/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.409]\n",
      "[2020-10-20 07:07:08,808] \n",
      "99/300 * Epoch 99 (_base): lr=0.0100 | momentum=0.9000\n",
      "99/300 * Epoch 99 (train): cmc05=-inf | loss=0.4091\n",
      "100/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.457]\n",
      "100/300 * Epoch (valid): 100% 52/52 [00:19<00:00,  2.61it/s]\n",
      "[2020-10-20 07:07:41,295] \n",
      "100/300 * Epoch 100 (_base): lr=0.0001 | momentum=0.9000\n",
      "100/300 * Epoch 100 (train): loss=0.4093\n",
      "100/300 * Epoch 100 (valid): cmc01=0.4476 | cmc05=0.7344 | cmc10=0.8221\n",
      "101/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.27it/s, loss=0.443]\n",
      "[2020-10-20 07:07:53,894] \n",
      "101/300 * Epoch 101 (_base): lr=0.0010 | momentum=0.9000\n",
      "101/300 * Epoch 101 (train): cmc05=-inf | loss=0.4089\n",
      "102/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.27it/s, loss=0.432]\n",
      "[2020-10-20 07:08:06,472] \n",
      "102/300 * Epoch 102 (_base): lr=0.0010 | momentum=0.9000\n",
      "102/300 * Epoch 102 (train): cmc05=-inf | loss=0.4074\n",
      "103/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.417]\n",
      "[2020-10-20 07:08:18,976] \n",
      "103/300 * Epoch 103 (_base): lr=0.0010 | momentum=0.9000\n",
      "103/300 * Epoch 103 (train): cmc05=-inf | loss=0.4069\n",
      "104/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.26it/s, loss=0.408]\n",
      "[2020-10-20 07:08:31,692] \n",
      "104/300 * Epoch 104 (_base): lr=0.0010 | momentum=0.9000\n",
      "104/300 * Epoch 104 (train): cmc05=-inf | loss=0.4069\n",
      "105/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.460]\n",
      "[2020-10-20 07:08:44,237] \n",
      "105/300 * Epoch 105 (_base): lr=0.0010 | momentum=0.9000\n",
      "105/300 * Epoch 105 (train): cmc05=-inf | loss=0.4085\n",
      "106/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.27it/s, loss=0.408]\n",
      "[2020-10-20 07:08:56,796] \n",
      "106/300 * Epoch 106 (_base): lr=0.0010 | momentum=0.9000\n",
      "106/300 * Epoch 106 (train): cmc05=-inf | loss=0.4097\n",
      "107/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.439]\n",
      "[2020-10-20 07:09:09,338] \n",
      "107/300 * Epoch 107 (_base): lr=0.0010 | momentum=0.9000\n",
      "107/300 * Epoch 107 (train): cmc05=-inf | loss=0.4079\n",
      "108/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.27it/s, loss=0.455]\n",
      "[2020-10-20 07:09:21,968] \n",
      "108/300 * Epoch 108 (_base): lr=0.0010 | momentum=0.9000\n",
      "108/300 * Epoch 108 (train): cmc05=-inf | loss=0.4048\n",
      "109/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.29it/s, loss=0.433]\n",
      "[2020-10-20 07:09:34,334] \n",
      "109/300 * Epoch 109 (_base): lr=0.0010 | momentum=0.9000\n",
      "109/300 * Epoch 109 (train): cmc05=-inf | loss=0.4081\n",
      "110/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.29it/s, loss=0.420]\n",
      "110/300 * Epoch (valid): 100% 52/52 [00:19<00:00,  2.67it/s]\n",
      "[2020-10-20 07:10:06,221] \n",
      "110/300 * Epoch 110 (_base): lr=0.0010 | momentum=0.9000\n",
      "110/300 * Epoch 110 (train): loss=0.4066\n",
      "110/300 * Epoch 110 (valid): cmc01=0.4742 | cmc05=0.7333 | cmc10=0.8266\n",
      "111/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.29it/s, loss=0.422]\n",
      "[2020-10-20 07:10:18,669] \n",
      "111/300 * Epoch 111 (_base): lr=0.0010 | momentum=0.9000\n",
      "111/300 * Epoch 111 (train): cmc05=-inf | loss=0.4037\n",
      "112/300 * Epoch (train): 100% 16/16 [00:13<00:00,  1.20it/s, loss=0.439]\n",
      "[2020-10-20 07:10:32,026] \n",
      "112/300 * Epoch 112 (_base): lr=0.0010 | momentum=0.9000\n",
      "112/300 * Epoch 112 (train): cmc05=-inf | loss=0.4075\n",
      "113/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.428]\n",
      "[2020-10-20 07:10:44,548] \n",
      "113/300 * Epoch 113 (_base): lr=0.0010 | momentum=0.9000\n",
      "113/300 * Epoch 113 (train): cmc05=-inf | loss=0.4061\n",
      "114/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.29it/s, loss=0.421]\n",
      "[2020-10-20 07:10:56,910] \n",
      "114/300 * Epoch 114 (_base): lr=0.0010 | momentum=0.9000\n",
      "114/300 * Epoch 114 (train): cmc05=-inf | loss=0.4042\n",
      "115/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.441]\n",
      "[2020-10-20 07:11:09,391] \n",
      "115/300 * Epoch 115 (_base): lr=0.0010 | momentum=0.9000\n",
      "115/300 * Epoch 115 (train): cmc05=-inf | loss=0.4059\n",
      "116/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.30it/s, loss=0.465]\n",
      "[2020-10-20 07:11:21,731] \n",
      "116/300 * Epoch 116 (_base): lr=0.0010 | momentum=0.9000\n",
      "116/300 * Epoch 116 (train): cmc05=-inf | loss=0.4076\n",
      "117/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.29it/s, loss=0.445]\n",
      "[2020-10-20 07:11:34,141] \n",
      "117/300 * Epoch 117 (_base): lr=0.0010 | momentum=0.9000\n",
      "117/300 * Epoch 117 (train): cmc05=-inf | loss=0.4053\n",
      "118/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.420]\n",
      "[2020-10-20 07:11:46,664] \n",
      "118/300 * Epoch 118 (_base): lr=0.0010 | momentum=0.9000\n",
      "118/300 * Epoch 118 (train): cmc05=-inf | loss=0.4082\n",
      "119/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.29it/s, loss=0.409]\n",
      "[2020-10-20 07:11:59,082] \n",
      "119/300 * Epoch 119 (_base): lr=0.0010 | momentum=0.9000\n",
      "119/300 * Epoch 119 (train): cmc05=-inf | loss=0.4064\n",
      "120/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.29it/s, loss=0.441]\n",
      "120/300 * Epoch (valid): 100% 52/52 [00:18<00:00,  2.77it/s]\n",
      "[2020-10-20 07:12:30,251] \n",
      "120/300 * Epoch 120 (_base): lr=0.0010 | momentum=0.9000\n",
      "120/300 * Epoch 120 (train): loss=0.4057\n",
      "120/300 * Epoch 120 (valid): cmc01=0.4609 | cmc05=0.7424 | cmc10=0.8418\n",
      "121/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.29it/s, loss=0.443]\n",
      "[2020-10-20 07:12:42,702] \n",
      "121/300 * Epoch 121 (_base): lr=0.0010 | momentum=0.9000\n",
      "121/300 * Epoch 121 (train): cmc05=-inf | loss=0.4061\n",
      "122/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.25it/s, loss=0.429]\n",
      "[2020-10-20 07:12:55,474] \n",
      "122/300 * Epoch 122 (_base): lr=0.0010 | momentum=0.9000\n",
      "122/300 * Epoch 122 (train): cmc05=-inf | loss=0.4065\n",
      "123/300 * Epoch (train): 100% 16/16 [00:13<00:00,  1.21it/s, loss=0.427]\n",
      "[2020-10-20 07:13:08,705] \n",
      "123/300 * Epoch 123 (_base): lr=0.0010 | momentum=0.9000\n",
      "123/300 * Epoch 123 (train): cmc05=-inf | loss=0.4052\n",
      "124/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.29it/s, loss=0.417]\n",
      "[2020-10-20 07:13:21,147] \n",
      "124/300 * Epoch 124 (_base): lr=0.0010 | momentum=0.9000\n",
      "124/300 * Epoch 124 (train): cmc05=-inf | loss=0.4057\n",
      "125/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.458]\n",
      "[2020-10-20 07:13:33,701] \n",
      "125/300 * Epoch 125 (_base): lr=0.0010 | momentum=0.9000\n",
      "125/300 * Epoch 125 (train): cmc05=-inf | loss=0.4044\n",
      "126/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.415]\n",
      "[2020-10-20 07:13:46,206] \n",
      "126/300 * Epoch 126 (_base): lr=0.0010 | momentum=0.9000\n",
      "126/300 * Epoch 126 (train): cmc05=-inf | loss=0.4036\n",
      "127/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.25it/s, loss=0.426]\n",
      "[2020-10-20 07:13:58,973] \n",
      "127/300 * Epoch 127 (_base): lr=0.0010 | momentum=0.9000\n",
      "127/300 * Epoch 127 (train): cmc05=-inf | loss=0.4058\n",
      "128/300 * Epoch (train): 100% 16/16 [00:13<00:00,  1.20it/s, loss=0.452]\n",
      "[2020-10-20 07:14:12,298] \n",
      "128/300 * Epoch 128 (_base): lr=0.0010 | momentum=0.9000\n",
      "128/300 * Epoch 128 (train): cmc05=-inf | loss=0.4052\n",
      "129/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.25it/s, loss=0.437]\n",
      "[2020-10-20 07:14:25,068] \n",
      "129/300 * Epoch 129 (_base): lr=0.0010 | momentum=0.9000\n",
      "129/300 * Epoch 129 (train): cmc05=-inf | loss=0.4044\n",
      "130/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.29it/s, loss=0.410]\n",
      "130/300 * Epoch (valid): 100% 52/52 [00:19<00:00,  2.64it/s]\n",
      "[2020-10-20 07:14:57,168] \n",
      "130/300 * Epoch 130 (_base): lr=0.0010 | momentum=0.9000\n",
      "130/300 * Epoch 130 (train): loss=0.4043\n",
      "130/300 * Epoch 130 (valid): cmc01=0.4704 | cmc05=0.7436 | cmc10=0.8327\n",
      "131/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.27it/s, loss=0.453]\n",
      "[2020-10-20 07:15:09,721] \n",
      "131/300 * Epoch 131 (_base): lr=0.0010 | momentum=0.9000\n",
      "131/300 * Epoch 131 (train): cmc05=-inf | loss=0.4075\n",
      "132/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.27it/s, loss=0.434]\n",
      "[2020-10-20 07:15:22,352] \n",
      "132/300 * Epoch 132 (_base): lr=0.0010 | momentum=0.9000\n",
      "132/300 * Epoch 132 (train): cmc05=-inf | loss=0.4043\n",
      "133/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.29it/s, loss=0.432]\n",
      "[2020-10-20 07:15:34,780] \n",
      "133/300 * Epoch 133 (_base): lr=0.0010 | momentum=0.9000\n",
      "133/300 * Epoch 133 (train): cmc05=-inf | loss=0.4040\n",
      "134/300 * Epoch (train): 100% 16/16 [00:13<00:00,  1.20it/s, loss=0.457]\n",
      "[2020-10-20 07:15:48,078] \n",
      "134/300 * Epoch 134 (_base): lr=0.0010 | momentum=0.9000\n",
      "134/300 * Epoch 134 (train): cmc05=-inf | loss=0.4061\n",
      "135/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.29it/s, loss=0.457]\n",
      "[2020-10-20 07:16:00,525] \n",
      "135/300 * Epoch 135 (_base): lr=0.0010 | momentum=0.9000\n",
      "135/300 * Epoch 135 (train): cmc05=-inf | loss=0.4055\n",
      "136/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.29it/s, loss=0.423]\n",
      "[2020-10-20 07:16:12,939] \n",
      "136/300 * Epoch 136 (_base): lr=0.0010 | momentum=0.9000\n",
      "136/300 * Epoch 136 (train): cmc05=-inf | loss=0.4068\n",
      "137/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.29it/s, loss=0.447]\n",
      "[2020-10-20 07:16:25,338] \n",
      "137/300 * Epoch 137 (_base): lr=0.0010 | momentum=0.9000\n",
      "137/300 * Epoch 137 (train): cmc05=-inf | loss=0.4049\n",
      "138/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.30it/s, loss=0.433]\n",
      "[2020-10-20 07:16:37,683] \n",
      "138/300 * Epoch 138 (_base): lr=0.0010 | momentum=0.9000\n",
      "138/300 * Epoch 138 (train): cmc05=-inf | loss=0.4051\n",
      "139/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.25it/s, loss=0.430]\n",
      "[2020-10-20 07:16:50,447] \n",
      "139/300 * Epoch 139 (_base): lr=0.0010 | momentum=0.9000\n",
      "139/300 * Epoch 139 (train): cmc05=-inf | loss=0.4033\n",
      "140/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.27it/s, loss=0.420]\n",
      "140/300 * Epoch (valid): 100% 52/52 [00:19<00:00,  2.61it/s]\n",
      "[2020-10-20 07:17:22,950] \n",
      "140/300 * Epoch 140 (_base): lr=0.0010 | momentum=0.9000\n",
      "140/300 * Epoch 140 (train): loss=0.4044\n",
      "140/300 * Epoch 140 (valid): cmc01=0.4829 | cmc05=0.7553 | cmc10=0.8407\n",
      "141/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.30it/s, loss=0.424]\n",
      "[2020-10-20 07:17:35,282] \n",
      "141/300 * Epoch 141 (_base): lr=0.0010 | momentum=0.9000\n",
      "141/300 * Epoch 141 (train): cmc05=-inf | loss=0.4046\n",
      "142/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.434]\n",
      "[2020-10-20 07:17:47,769] \n",
      "142/300 * Epoch 142 (_base): lr=0.0010 | momentum=0.9000\n",
      "142/300 * Epoch 142 (train): cmc05=-inf | loss=0.4025\n",
      "143/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.27it/s, loss=0.417]\n",
      "[2020-10-20 07:18:00,331] \n",
      "143/300 * Epoch 143 (_base): lr=0.0010 | momentum=0.9000\n",
      "143/300 * Epoch 143 (train): cmc05=-inf | loss=0.4049\n",
      "144/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.24it/s, loss=0.450]\n",
      "[2020-10-20 07:18:13,231] \n",
      "144/300 * Epoch 144 (_base): lr=0.0010 | momentum=0.9000\n",
      "144/300 * Epoch 144 (train): cmc05=-inf | loss=0.4056\n",
      "145/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.29it/s, loss=0.439]\n",
      "[2020-10-20 07:18:25,655] \n",
      "145/300 * Epoch 145 (_base): lr=0.0010 | momentum=0.9000\n",
      "145/300 * Epoch 145 (train): cmc05=-inf | loss=0.4051\n",
      "146/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.416]\n",
      "[2020-10-20 07:18:38,170] \n",
      "146/300 * Epoch 146 (_base): lr=0.0010 | momentum=0.9000\n",
      "146/300 * Epoch 146 (train): cmc05=-inf | loss=0.4060\n",
      "147/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.27it/s, loss=0.424]\n",
      "[2020-10-20 07:18:50,813] \n",
      "147/300 * Epoch 147 (_base): lr=0.0010 | momentum=0.9000\n",
      "147/300 * Epoch 147 (train): cmc05=-inf | loss=0.4027\n",
      "148/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.29it/s, loss=0.412]\n",
      "[2020-10-20 07:19:03,217] \n",
      "148/300 * Epoch 148 (_base): lr=0.0010 | momentum=0.9000\n",
      "148/300 * Epoch 148 (train): cmc05=-inf | loss=0.4041\n",
      "149/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.456]\n",
      "[2020-10-20 07:19:15,733] \n",
      "149/300 * Epoch 149 (_base): lr=0.0010 | momentum=0.9000\n",
      "149/300 * Epoch 149 (train): cmc05=-inf | loss=0.4067\n",
      "150/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.432]\n",
      "150/300 * Epoch (valid): 100% 52/52 [00:19<00:00,  2.61it/s]\n",
      "[2020-10-20 07:19:48,215] \n",
      "150/300 * Epoch 150 (_base): lr=0.0010 | momentum=0.9000\n",
      "150/300 * Epoch 150 (train): loss=0.4047\n",
      "150/300 * Epoch 150 (valid): cmc01=0.4753 | cmc05=0.7637 | cmc10=0.8452\n",
      "151/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.471]\n",
      "[2020-10-20 07:20:00,685] \n",
      "151/300 * Epoch 151 (_base): lr=0.0010 | momentum=0.9000\n",
      "151/300 * Epoch 151 (train): cmc05=-inf | loss=0.4042\n",
      "152/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.408]\n",
      "[2020-10-20 07:20:13,194] \n",
      "152/300 * Epoch 152 (_base): lr=0.0010 | momentum=0.9000\n",
      "152/300 * Epoch 152 (train): cmc05=-inf | loss=0.4041\n",
      "153/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.431]\n",
      "[2020-10-20 07:20:25,746] \n",
      "153/300 * Epoch 153 (_base): lr=0.0010 | momentum=0.9000\n",
      "153/300 * Epoch 153 (train): cmc05=-inf | loss=0.4064\n",
      "154/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.415]\n",
      "[2020-10-20 07:20:38,204] \n",
      "154/300 * Epoch 154 (_base): lr=0.0010 | momentum=0.9000\n",
      "154/300 * Epoch 154 (train): cmc05=-inf | loss=0.4065\n",
      "155/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.27it/s, loss=0.425]\n",
      "[2020-10-20 07:20:50,763] \n",
      "155/300 * Epoch 155 (_base): lr=0.0010 | momentum=0.9000\n",
      "155/300 * Epoch 155 (train): cmc05=-inf | loss=0.4043\n",
      "156/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.27it/s, loss=0.424]\n",
      "[2020-10-20 07:21:03,367] \n",
      "156/300 * Epoch 156 (_base): lr=0.0010 | momentum=0.9000\n",
      "156/300 * Epoch 156 (train): cmc05=-inf | loss=0.4028\n",
      "157/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.27it/s, loss=0.442]\n",
      "[2020-10-20 07:21:16,002] \n",
      "157/300 * Epoch 157 (_base): lr=0.0010 | momentum=0.9000\n",
      "157/300 * Epoch 157 (train): cmc05=-inf | loss=0.4040\n",
      "158/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.27it/s, loss=0.434]\n",
      "[2020-10-20 07:21:28,597] \n",
      "158/300 * Epoch 158 (_base): lr=0.0010 | momentum=0.9000\n",
      "158/300 * Epoch 158 (train): cmc05=-inf | loss=0.4065\n",
      "159/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.29it/s, loss=0.440]\n",
      "[2020-10-20 07:21:41,020] \n",
      "159/300 * Epoch 159 (_base): lr=0.0010 | momentum=0.9000\n",
      "159/300 * Epoch 159 (train): cmc05=-inf | loss=0.4040\n",
      "160/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.26it/s, loss=0.469]\n",
      "160/300 * Epoch (valid): 100% 52/52 [00:19<00:00,  2.66it/s]\n",
      "[2020-10-20 07:22:13,239] \n",
      "160/300 * Epoch 160 (_base): lr=0.0010 | momentum=0.9000\n",
      "160/300 * Epoch 160 (train): loss=0.4045\n",
      "160/300 * Epoch 160 (valid): cmc01=0.4939 | cmc05=0.7659 | cmc10=0.8467\n",
      "161/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.30it/s, loss=0.427]\n",
      "[2020-10-20 07:22:25,597] \n",
      "161/300 * Epoch 161 (_base): lr=0.0010 | momentum=0.9000\n",
      "161/300 * Epoch 161 (train): cmc05=-inf | loss=0.4049\n",
      "162/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.30it/s, loss=0.438]\n",
      "[2020-10-20 07:22:37,930] \n",
      "162/300 * Epoch 162 (_base): lr=0.0010 | momentum=0.9000\n",
      "162/300 * Epoch 162 (train): cmc05=-inf | loss=0.4043\n",
      "163/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.432]\n",
      "[2020-10-20 07:22:50,469] \n",
      "163/300 * Epoch 163 (_base): lr=0.0010 | momentum=0.9000\n",
      "163/300 * Epoch 163 (train): cmc05=-inf | loss=0.4035\n",
      "164/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.25it/s, loss=0.410]\n",
      "[2020-10-20 07:23:03,310] \n",
      "164/300 * Epoch 164 (_base): lr=0.0010 | momentum=0.9000\n",
      "164/300 * Epoch 164 (train): cmc05=-inf | loss=0.4038\n",
      "165/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.30it/s, loss=0.434]\n",
      "[2020-10-20 07:23:15,645] \n",
      "165/300 * Epoch 165 (_base): lr=0.0010 | momentum=0.9000\n",
      "165/300 * Epoch 165 (train): cmc05=-inf | loss=0.4050\n",
      "166/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.29it/s, loss=0.437]\n",
      "[2020-10-20 07:23:28,099] \n",
      "166/300 * Epoch 166 (_base): lr=0.0010 | momentum=0.9000\n",
      "166/300 * Epoch 166 (train): cmc05=-inf | loss=0.4048\n",
      "167/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.467]\n",
      "[2020-10-20 07:23:40,564] \n",
      "167/300 * Epoch 167 (_base): lr=0.0010 | momentum=0.9000\n",
      "167/300 * Epoch 167 (train): cmc05=-inf | loss=0.4031\n",
      "168/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.438]\n",
      "[2020-10-20 07:23:53,045] \n",
      "168/300 * Epoch 168 (_base): lr=0.0010 | momentum=0.9000\n",
      "168/300 * Epoch 168 (train): cmc05=-inf | loss=0.4063\n",
      "169/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.27it/s, loss=0.453]\n",
      "[2020-10-20 07:24:05,665] \n",
      "169/300 * Epoch 169 (_base): lr=0.0010 | momentum=0.9000\n",
      "169/300 * Epoch 169 (train): cmc05=-inf | loss=0.4048\n",
      "170/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.27it/s, loss=0.465]\n",
      "170/300 * Epoch (valid): 100% 52/52 [00:18<00:00,  2.81it/s]\n",
      "[2020-10-20 07:24:36,729] \n",
      "170/300 * Epoch 170 (_base): lr=0.0010 | momentum=0.9000\n",
      "170/300 * Epoch 170 (train): loss=0.4033\n",
      "170/300 * Epoch 170 (valid): cmc01=0.4765 | cmc05=0.7538 | cmc10=0.8380\n",
      "171/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.29it/s, loss=0.403]\n",
      "[2020-10-20 07:24:49,118] \n",
      "171/300 * Epoch 171 (_base): lr=0.0010 | momentum=0.9000\n",
      "171/300 * Epoch 171 (train): cmc05=-inf | loss=0.4037\n",
      "172/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.466]\n",
      "[2020-10-20 07:25:01,600] \n",
      "172/300 * Epoch 172 (_base): lr=0.0010 | momentum=0.9000\n",
      "172/300 * Epoch 172 (train): cmc05=-inf | loss=0.4036\n",
      "173/300 * Epoch (train): 100% 16/16 [00:13<00:00,  1.21it/s, loss=0.409]\n",
      "[2020-10-20 07:25:14,794] \n",
      "173/300 * Epoch 173 (_base): lr=0.0010 | momentum=0.9000\n",
      "173/300 * Epoch 173 (train): cmc05=-inf | loss=0.4047\n",
      "174/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.27it/s, loss=0.428]\n",
      "[2020-10-20 07:25:27,381] \n",
      "174/300 * Epoch 174 (_base): lr=0.0010 | momentum=0.9000\n",
      "174/300 * Epoch 174 (train): cmc05=-inf | loss=0.4038\n",
      "175/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.436]\n",
      "[2020-10-20 07:25:39,887] \n",
      "175/300 * Epoch 175 (_base): lr=0.0010 | momentum=0.9000\n",
      "175/300 * Epoch 175 (train): cmc05=-inf | loss=0.4031\n",
      "176/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.29it/s, loss=0.420]\n",
      "[2020-10-20 07:25:52,264] \n",
      "176/300 * Epoch 176 (_base): lr=0.0010 | momentum=0.9000\n",
      "176/300 * Epoch 176 (train): cmc05=-inf | loss=0.4019\n",
      "177/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.29it/s, loss=0.435]\n",
      "[2020-10-20 07:26:04,690] \n",
      "177/300 * Epoch 177 (_base): lr=0.0010 | momentum=0.9000\n",
      "177/300 * Epoch 177 (train): cmc05=-inf | loss=0.4045\n",
      "178/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.462]\n",
      "[2020-10-20 07:26:17,213] \n",
      "178/300 * Epoch 178 (_base): lr=0.0010 | momentum=0.9000\n",
      "178/300 * Epoch 178 (train): cmc05=-inf | loss=0.4060\n",
      "179/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.27it/s, loss=0.470]\n",
      "[2020-10-20 07:26:29,787] \n",
      "179/300 * Epoch 179 (_base): lr=0.0010 | momentum=0.9000\n",
      "179/300 * Epoch 179 (train): cmc05=-inf | loss=0.4041\n",
      "180/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.29it/s, loss=0.424]\n",
      "180/300 * Epoch (valid): 100% 52/52 [00:19<00:00,  2.72it/s]\n",
      "[2020-10-20 07:27:01,279] \n",
      "180/300 * Epoch 180 (_base): lr=0.0010 | momentum=0.9000\n",
      "180/300 * Epoch 180 (train): loss=0.4004\n",
      "180/300 * Epoch 180 (valid): cmc01=0.4772 | cmc05=0.7663 | cmc10=0.8452\n",
      "181/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.29it/s, loss=0.459]\n",
      "[2020-10-20 07:27:13,732] \n",
      "181/300 * Epoch 181 (_base): lr=0.0010 | momentum=0.9000\n",
      "181/300 * Epoch 181 (train): cmc05=-inf | loss=0.4056\n",
      "182/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.29it/s, loss=0.419]\n",
      "[2020-10-20 07:27:26,168] \n",
      "182/300 * Epoch 182 (_base): lr=0.0010 | momentum=0.9000\n",
      "182/300 * Epoch 182 (train): cmc05=-inf | loss=0.4033\n",
      "183/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.448]\n",
      "[2020-10-20 07:27:38,633] \n",
      "183/300 * Epoch 183 (_base): lr=0.0010 | momentum=0.9000\n",
      "183/300 * Epoch 183 (train): cmc05=-inf | loss=0.4059\n",
      "184/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.27it/s, loss=0.425]\n",
      "[2020-10-20 07:27:51,205] \n",
      "184/300 * Epoch 184 (_base): lr=0.0010 | momentum=0.9000\n",
      "184/300 * Epoch 184 (train): cmc05=-inf | loss=0.4027\n",
      "185/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.429]\n",
      "[2020-10-20 07:28:03,724] \n",
      "185/300 * Epoch 185 (_base): lr=0.0010 | momentum=0.9000\n",
      "185/300 * Epoch 185 (train): cmc05=-inf | loss=0.4034\n",
      "186/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.29it/s, loss=0.417]\n",
      "[2020-10-20 07:28:16,174] \n",
      "186/300 * Epoch 186 (_base): lr=0.0010 | momentum=0.9000\n",
      "186/300 * Epoch 186 (train): cmc05=-inf | loss=0.4059\n",
      "187/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.407]\n",
      "[2020-10-20 07:28:28,680] \n",
      "187/300 * Epoch 187 (_base): lr=0.0010 | momentum=0.9000\n",
      "187/300 * Epoch 187 (train): cmc05=-inf | loss=0.4029\n",
      "188/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.29it/s, loss=0.425]\n",
      "[2020-10-20 07:28:41,105] \n",
      "188/300 * Epoch 188 (_base): lr=0.0010 | momentum=0.9000\n",
      "188/300 * Epoch 188 (train): cmc05=-inf | loss=0.4022\n",
      "189/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.27it/s, loss=0.446]\n",
      "[2020-10-20 07:28:53,687] \n",
      "189/300 * Epoch 189 (_base): lr=0.0010 | momentum=0.9000\n",
      "189/300 * Epoch 189 (train): cmc05=-inf | loss=0.4046\n",
      "190/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.29it/s, loss=0.465]\n",
      "190/300 * Epoch (valid): 100% 52/52 [00:19<00:00,  2.70it/s]\n",
      "[2020-10-20 07:29:25,408] \n",
      "190/300 * Epoch 190 (_base): lr=0.0010 | momentum=0.9000\n",
      "190/300 * Epoch 190 (train): loss=0.4040\n",
      "190/300 * Epoch 190 (valid): cmc01=0.4886 | cmc05=0.7633 | cmc10=0.8418\n",
      "191/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.26it/s, loss=0.420]\n",
      "[2020-10-20 07:29:38,156] \n",
      "191/300 * Epoch 191 (_base): lr=0.0010 | momentum=0.9000\n",
      "191/300 * Epoch 191 (train): cmc05=-inf | loss=0.4019\n",
      "192/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.30it/s, loss=0.411]\n",
      "[2020-10-20 07:29:50,484] \n",
      "192/300 * Epoch 192 (_base): lr=0.0010 | momentum=0.9000\n",
      "192/300 * Epoch 192 (train): cmc05=-inf | loss=0.4034\n",
      "193/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.419]\n",
      "[2020-10-20 07:30:03,030] \n",
      "193/300 * Epoch 193 (_base): lr=0.0010 | momentum=0.9000\n",
      "193/300 * Epoch 193 (train): cmc05=-inf | loss=0.4035\n",
      "194/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.436]\n",
      "[2020-10-20 07:30:15,556] \n",
      "194/300 * Epoch 194 (_base): lr=0.0010 | momentum=0.9000\n",
      "194/300 * Epoch 194 (train): cmc05=-inf | loss=0.4023\n",
      "195/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.29it/s, loss=0.435]\n",
      "[2020-10-20 07:30:28,009] \n",
      "195/300 * Epoch 195 (_base): lr=0.0010 | momentum=0.9000\n",
      "195/300 * Epoch 195 (train): cmc05=-inf | loss=0.4008\n",
      "196/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.416]\n",
      "[2020-10-20 07:30:40,480] \n",
      "196/300 * Epoch 196 (_base): lr=0.0010 | momentum=0.9000\n",
      "196/300 * Epoch 196 (train): cmc05=-inf | loss=0.4020\n",
      "197/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.30it/s, loss=0.446]\n",
      "[2020-10-20 07:30:52,795] \n",
      "197/300 * Epoch 197 (_base): lr=0.0010 | momentum=0.9000\n",
      "197/300 * Epoch 197 (train): cmc05=-inf | loss=0.4033\n",
      "198/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.418]\n",
      "[2020-10-20 07:31:05,306] \n",
      "198/300 * Epoch 198 (_base): lr=0.0010 | momentum=0.9000\n",
      "198/300 * Epoch 198 (train): cmc05=-inf | loss=0.4033\n",
      "199/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.27it/s, loss=0.441]\n",
      "[2020-10-20 07:31:17,958] \n",
      "199/300 * Epoch 199 (_base): lr=0.0010 | momentum=0.9000\n",
      "199/300 * Epoch 199 (train): cmc05=-inf | loss=0.4018\n",
      "200/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.410]\n",
      "200/300 * Epoch (valid): 100% 52/52 [00:18<00:00,  2.77it/s]\n",
      "[2020-10-20 07:31:49,284] \n",
      "200/300 * Epoch 200 (_base): lr=0.0010 | momentum=0.9000\n",
      "200/300 * Epoch 200 (train): loss=0.4040\n",
      "200/300 * Epoch 200 (valid): cmc01=0.4898 | cmc05=0.7678 | cmc10=0.8505\n",
      "201/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.30it/s, loss=0.420]\n",
      "[2020-10-20 07:32:01,612] \n",
      "201/300 * Epoch 201 (_base): lr=0.0010 | momentum=0.9000\n",
      "201/300 * Epoch 201 (train): cmc05=-inf | loss=0.4027\n",
      "202/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.30it/s, loss=0.446]\n",
      "[2020-10-20 07:32:13,935] \n",
      "202/300 * Epoch 202 (_base): lr=0.0010 | momentum=0.9000\n",
      "202/300 * Epoch 202 (train): cmc05=-inf | loss=0.4022\n",
      "203/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.27it/s, loss=0.410]\n",
      "[2020-10-20 07:32:26,562] \n",
      "203/300 * Epoch 203 (_base): lr=0.0010 | momentum=0.9000\n",
      "203/300 * Epoch 203 (train): cmc05=-inf | loss=0.4028\n",
      "204/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.29it/s, loss=0.400]\n",
      "[2020-10-20 07:32:38,944] \n",
      "204/300 * Epoch 204 (_base): lr=0.0010 | momentum=0.9000\n",
      "204/300 * Epoch 204 (train): cmc05=-inf | loss=0.4028\n",
      "205/300 * Epoch (train): 100% 16/16 [00:13<00:00,  1.20it/s, loss=0.410]\n",
      "[2020-10-20 07:32:52,323] \n",
      "205/300 * Epoch 205 (_base): lr=0.0010 | momentum=0.9000\n",
      "205/300 * Epoch 205 (train): cmc05=-inf | loss=0.4045\n",
      "206/300 * Epoch (train): 100% 16/16 [00:13<00:00,  1.21it/s, loss=0.435]\n",
      "[2020-10-20 07:33:05,576] \n",
      "206/300 * Epoch 206 (_base): lr=0.0010 | momentum=0.9000\n",
      "206/300 * Epoch 206 (train): cmc05=-inf | loss=0.4054\n",
      "207/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.29it/s, loss=0.406]\n",
      "[2020-10-20 07:33:17,940] \n",
      "207/300 * Epoch 207 (_base): lr=0.0010 | momentum=0.9000\n",
      "207/300 * Epoch 207 (train): cmc05=-inf | loss=0.4036\n",
      "208/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.30it/s, loss=0.431]\n",
      "[2020-10-20 07:33:30,237] \n",
      "208/300 * Epoch 208 (_base): lr=0.0010 | momentum=0.9000\n",
      "208/300 * Epoch 208 (train): cmc05=-inf | loss=0.4013\n",
      "209/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.26it/s, loss=0.409]\n",
      "[2020-10-20 07:33:42,957] \n",
      "209/300 * Epoch 209 (_base): lr=0.0010 | momentum=0.9000\n",
      "209/300 * Epoch 209 (train): cmc05=-inf | loss=0.4050\n",
      "210/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.426]\n",
      "210/300 * Epoch (valid): 100% 52/52 [00:19<00:00,  2.60it/s]\n",
      "[2020-10-20 07:34:15,447] \n",
      "210/300 * Epoch 210 (_base): lr=0.0010 | momentum=0.9000\n",
      "210/300 * Epoch 210 (train): loss=0.4030\n",
      "210/300 * Epoch 210 (valid): cmc01=0.4954 | cmc05=0.7709 | cmc10=0.8520\n",
      "211/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.422]\n",
      "[2020-10-20 07:34:27,933] \n",
      "211/300 * Epoch 211 (_base): lr=0.0010 | momentum=0.9000\n",
      "211/300 * Epoch 211 (train): cmc05=-inf | loss=0.4024\n",
      "212/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.466]\n",
      "[2020-10-20 07:34:40,416] \n",
      "212/300 * Epoch 212 (_base): lr=0.0010 | momentum=0.9000\n",
      "212/300 * Epoch 212 (train): cmc05=-inf | loss=0.4060\n",
      "213/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.26it/s, loss=0.415]\n",
      "[2020-10-20 07:34:53,148] \n",
      "213/300 * Epoch 213 (_base): lr=0.0010 | momentum=0.9000\n",
      "213/300 * Epoch 213 (train): cmc05=-inf | loss=0.4038\n",
      "214/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.27it/s, loss=0.443]\n",
      "[2020-10-20 07:35:05,730] \n",
      "214/300 * Epoch 214 (_base): lr=0.0010 | momentum=0.9000\n",
      "214/300 * Epoch 214 (train): cmc05=-inf | loss=0.4039\n",
      "215/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.421]\n",
      "[2020-10-20 07:35:18,273] \n",
      "215/300 * Epoch 215 (_base): lr=0.0010 | momentum=0.9000\n",
      "215/300 * Epoch 215 (train): cmc05=-inf | loss=0.4027\n",
      "216/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.414]\n",
      "[2020-10-20 07:35:30,732] \n",
      "216/300 * Epoch 216 (_base): lr=0.0010 | momentum=0.9000\n",
      "216/300 * Epoch 216 (train): cmc05=-inf | loss=0.4038\n",
      "217/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.27it/s, loss=0.419]\n",
      "[2020-10-20 07:35:43,328] \n",
      "217/300 * Epoch 217 (_base): lr=0.0010 | momentum=0.9000\n",
      "217/300 * Epoch 217 (train): cmc05=-inf | loss=0.4028\n",
      "218/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.425]\n",
      "[2020-10-20 07:35:55,804] \n",
      "218/300 * Epoch 218 (_base): lr=0.0010 | momentum=0.9000\n",
      "218/300 * Epoch 218 (train): cmc05=-inf | loss=0.4053\n",
      "219/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.437]\n",
      "[2020-10-20 07:36:08,345] \n",
      "219/300 * Epoch 219 (_base): lr=0.0010 | momentum=0.9000\n",
      "219/300 * Epoch 219 (train): cmc05=-inf | loss=0.4038\n",
      "220/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.29it/s, loss=0.453]\n",
      "220/300 * Epoch (valid): 100% 52/52 [00:18<00:00,  2.80it/s]\n",
      "[2020-10-20 07:36:39,341] \n",
      "220/300 * Epoch 220 (_base): lr=0.0010 | momentum=0.9000\n",
      "220/300 * Epoch 220 (train): loss=0.3997\n",
      "220/300 * Epoch 220 (valid): cmc01=0.4852 | cmc05=0.7538 | cmc10=0.8422\n",
      "221/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.30it/s, loss=0.437]\n",
      "[2020-10-20 07:36:51,685] \n",
      "221/300 * Epoch 221 (_base): lr=0.0010 | momentum=0.9000\n",
      "221/300 * Epoch 221 (train): cmc05=-inf | loss=0.4001\n",
      "222/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.29it/s, loss=0.422]\n",
      "[2020-10-20 07:37:04,096] \n",
      "222/300 * Epoch 222 (_base): lr=0.0010 | momentum=0.9000\n",
      "222/300 * Epoch 222 (train): cmc05=-inf | loss=0.4022\n",
      "223/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.443]\n",
      "[2020-10-20 07:37:16,588] \n",
      "223/300 * Epoch 223 (_base): lr=0.0010 | momentum=0.9000\n",
      "223/300 * Epoch 223 (train): cmc05=-inf | loss=0.4035\n",
      "224/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.29it/s, loss=0.441]\n",
      "[2020-10-20 07:37:29,016] \n",
      "224/300 * Epoch 224 (_base): lr=0.0010 | momentum=0.9000\n",
      "224/300 * Epoch 224 (train): cmc05=-inf | loss=0.4035\n",
      "225/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.429]\n",
      "[2020-10-20 07:37:41,508] \n",
      "225/300 * Epoch 225 (_base): lr=0.0010 | momentum=0.9000\n",
      "225/300 * Epoch 225 (train): cmc05=-inf | loss=0.4012\n",
      "226/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.29it/s, loss=0.407]\n",
      "[2020-10-20 07:37:53,893] \n",
      "226/300 * Epoch 226 (_base): lr=0.0010 | momentum=0.9000\n",
      "226/300 * Epoch 226 (train): cmc05=-inf | loss=0.4030\n",
      "227/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.456]\n",
      "[2020-10-20 07:38:06,438] \n",
      "227/300 * Epoch 227 (_base): lr=0.0010 | momentum=0.9000\n",
      "227/300 * Epoch 227 (train): cmc05=-inf | loss=0.4035\n",
      "228/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.27it/s, loss=0.440]\n",
      "[2020-10-20 07:38:19,012] \n",
      "228/300 * Epoch 228 (_base): lr=0.0010 | momentum=0.9000\n",
      "228/300 * Epoch 228 (train): cmc05=-inf | loss=0.4042\n",
      "229/300 * Epoch (train): 100% 16/16 [00:13<00:00,  1.20it/s, loss=0.434]\n",
      "[2020-10-20 07:38:32,379] \n",
      "229/300 * Epoch 229 (_base): lr=0.0010 | momentum=0.9000\n",
      "229/300 * Epoch 229 (train): cmc05=-inf | loss=0.4032\n",
      "230/300 * Epoch (train): 100% 16/16 [00:13<00:00,  1.20it/s, loss=0.412]\n",
      "230/300 * Epoch (valid): 100% 52/52 [00:19<00:00,  2.63it/s]\n",
      "[2020-10-20 07:39:05,496] \n",
      "230/300 * Epoch 230 (_base): lr=0.0010 | momentum=0.9000\n",
      "230/300 * Epoch 230 (train): loss=0.4029\n",
      "230/300 * Epoch 230 (valid): cmc01=0.4920 | cmc05=0.7568 | cmc10=0.8414\n",
      "231/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.30it/s, loss=0.426]\n",
      "[2020-10-20 07:39:17,853] \n",
      "231/300 * Epoch 231 (_base): lr=0.0010 | momentum=0.9000\n",
      "231/300 * Epoch 231 (train): cmc05=-inf | loss=0.4031\n",
      "232/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.30it/s, loss=0.412]\n",
      "[2020-10-20 07:39:30,142] \n",
      "232/300 * Epoch 232 (_base): lr=0.0010 | momentum=0.9000\n",
      "232/300 * Epoch 232 (train): cmc05=-inf | loss=0.4026\n",
      "233/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.447]\n",
      "[2020-10-20 07:39:42,644] \n",
      "233/300 * Epoch 233 (_base): lr=0.0010 | momentum=0.9000\n",
      "233/300 * Epoch 233 (train): cmc05=-inf | loss=0.4019\n",
      "234/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.422]\n",
      "[2020-10-20 07:39:55,106] \n",
      "234/300 * Epoch 234 (_base): lr=0.0010 | momentum=0.9000\n",
      "234/300 * Epoch 234 (train): cmc05=-inf | loss=0.4032\n",
      "235/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.27it/s, loss=0.426]\n",
      "[2020-10-20 07:40:07,687] \n",
      "235/300 * Epoch 235 (_base): lr=0.0010 | momentum=0.9000\n",
      "235/300 * Epoch 235 (train): cmc05=-inf | loss=0.4000\n",
      "236/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.29it/s, loss=0.439]\n",
      "[2020-10-20 07:40:20,104] \n",
      "236/300 * Epoch 236 (_base): lr=0.0010 | momentum=0.9000\n",
      "236/300 * Epoch 236 (train): cmc05=-inf | loss=0.4005\n",
      "237/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.418]\n",
      "[2020-10-20 07:40:32,599] \n",
      "237/300 * Epoch 237 (_base): lr=0.0010 | momentum=0.9000\n",
      "237/300 * Epoch 237 (train): cmc05=-inf | loss=0.3997\n",
      "238/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.30it/s, loss=0.429]\n",
      "[2020-10-20 07:40:44,946] \n",
      "238/300 * Epoch 238 (_base): lr=0.0010 | momentum=0.9000\n",
      "238/300 * Epoch 238 (train): cmc05=-inf | loss=0.4003\n",
      "239/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.29it/s, loss=0.416]\n",
      "[2020-10-20 07:40:57,376] \n",
      "239/300 * Epoch 239 (_base): lr=0.0010 | momentum=0.9000\n",
      "239/300 * Epoch 239 (train): cmc05=-inf | loss=0.4006\n",
      "240/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.29it/s, loss=0.413]\n",
      "240/300 * Epoch (valid): 100% 52/52 [00:18<00:00,  2.80it/s]\n",
      "[2020-10-20 07:41:28,332] \n",
      "240/300 * Epoch 240 (_base): lr=0.0010 | momentum=0.9000\n",
      "240/300 * Epoch 240 (train): loss=0.4033\n",
      "240/300 * Epoch 240 (valid): cmc01=0.4844 | cmc05=0.7580 | cmc10=0.8475\n",
      "241/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.29it/s, loss=0.417]\n",
      "[2020-10-20 07:41:40,766] \n",
      "241/300 * Epoch 241 (_base): lr=0.0010 | momentum=0.9000\n",
      "241/300 * Epoch 241 (train): cmc05=-inf | loss=0.4020\n",
      "242/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.29it/s, loss=0.443]\n",
      "[2020-10-20 07:41:53,183] \n",
      "242/300 * Epoch 242 (_base): lr=0.0010 | momentum=0.9000\n",
      "242/300 * Epoch 242 (train): cmc05=-inf | loss=0.4019\n",
      "243/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.404]\n",
      "[2020-10-20 07:42:05,704] \n",
      "243/300 * Epoch 243 (_base): lr=0.0010 | momentum=0.9000\n",
      "243/300 * Epoch 243 (train): cmc05=-inf | loss=0.4029\n",
      "244/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.420]\n",
      "[2020-10-20 07:42:18,197] \n",
      "244/300 * Epoch 244 (_base): lr=0.0010 | momentum=0.9000\n",
      "244/300 * Epoch 244 (train): cmc05=-inf | loss=0.4012\n",
      "245/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.442]\n",
      "[2020-10-20 07:42:30,678] \n",
      "245/300 * Epoch 245 (_base): lr=0.0010 | momentum=0.9000\n",
      "245/300 * Epoch 245 (train): cmc05=-inf | loss=0.4021\n",
      "246/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.428]\n",
      "[2020-10-20 07:42:43,207] \n",
      "246/300 * Epoch 246 (_base): lr=0.0010 | momentum=0.9000\n",
      "246/300 * Epoch 246 (train): cmc05=-inf | loss=0.4042\n",
      "247/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.27it/s, loss=0.442]\n",
      "[2020-10-20 07:42:55,790] \n",
      "247/300 * Epoch 247 (_base): lr=0.0010 | momentum=0.9000\n",
      "247/300 * Epoch 247 (train): cmc05=-inf | loss=0.4044\n",
      "248/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.29it/s, loss=0.454]\n",
      "[2020-10-20 07:43:08,237] \n",
      "248/300 * Epoch 248 (_base): lr=0.0010 | momentum=0.9000\n",
      "248/300 * Epoch 248 (train): cmc05=-inf | loss=0.4031\n",
      "249/300 * Epoch (train): 100% 16/16 [00:13<00:00,  1.20it/s, loss=0.436]\n",
      "[2020-10-20 07:43:21,605] \n",
      "249/300 * Epoch 249 (_base): lr=0.0010 | momentum=0.9000\n",
      "249/300 * Epoch 249 (train): cmc05=-inf | loss=0.4024\n",
      "250/300 * Epoch (train): 100% 16/16 [00:13<00:00,  1.20it/s, loss=0.444]\n",
      "250/300 * Epoch (valid): 100% 52/52 [00:18<00:00,  2.79it/s]\n",
      "[2020-10-20 07:43:53,609] \n",
      "250/300 * Epoch 250 (_base): lr=0.0010 | momentum=0.9000\n",
      "250/300 * Epoch 250 (train): loss=0.4012\n",
      "250/300 * Epoch 250 (valid): cmc01=0.5015 | cmc05=0.7682 | cmc10=0.8441\n",
      "251/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.430]\n",
      "[2020-10-20 07:44:06,117] \n",
      "251/300 * Epoch 251 (_base): lr=0.0010 | momentum=0.9000\n",
      "251/300 * Epoch 251 (train): cmc05=-inf | loss=0.4004\n",
      "252/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.29it/s, loss=0.427]\n",
      "[2020-10-20 07:44:18,569] \n",
      "252/300 * Epoch 252 (_base): lr=0.0010 | momentum=0.9000\n",
      "252/300 * Epoch 252 (train): cmc05=-inf | loss=0.4010\n",
      "253/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.431]\n",
      "[2020-10-20 07:44:31,064] \n",
      "253/300 * Epoch 253 (_base): lr=0.0010 | momentum=0.9000\n",
      "253/300 * Epoch 253 (train): cmc05=-inf | loss=0.4030\n",
      "254/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.418]\n",
      "[2020-10-20 07:44:43,561] \n",
      "254/300 * Epoch 254 (_base): lr=0.0010 | momentum=0.9000\n",
      "254/300 * Epoch 254 (train): cmc05=-inf | loss=0.4021\n",
      "255/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.26it/s, loss=0.397]\n",
      "[2020-10-20 07:44:56,215] \n",
      "255/300 * Epoch 255 (_base): lr=0.0010 | momentum=0.9000\n",
      "255/300 * Epoch 255 (train): cmc05=-inf | loss=0.4015\n",
      "256/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.434]\n",
      "[2020-10-20 07:45:08,710] \n",
      "256/300 * Epoch 256 (_base): lr=0.0010 | momentum=0.9000\n",
      "256/300 * Epoch 256 (train): cmc05=-inf | loss=0.4041\n",
      "257/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.418]\n",
      "[2020-10-20 07:45:21,191] \n",
      "257/300 * Epoch 257 (_base): lr=0.0010 | momentum=0.9000\n",
      "257/300 * Epoch 257 (train): cmc05=-inf | loss=0.4016\n",
      "258/300 * Epoch (train): 100% 16/16 [00:13<00:00,  1.20it/s, loss=0.474]\n",
      "[2020-10-20 07:45:34,494] \n",
      "258/300 * Epoch 258 (_base): lr=0.0010 | momentum=0.9000\n",
      "258/300 * Epoch 258 (train): cmc05=-inf | loss=0.4030\n",
      "259/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.29it/s, loss=0.426]\n",
      "[2020-10-20 07:45:46,944] \n",
      "259/300 * Epoch 259 (_base): lr=0.0010 | momentum=0.9000\n",
      "259/300 * Epoch 259 (train): cmc05=-inf | loss=0.4023\n",
      "260/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.422]\n",
      "260/300 * Epoch (valid): 100% 52/52 [00:19<00:00,  2.63it/s]\n",
      "[2020-10-20 07:46:19,205] \n",
      "260/300 * Epoch 260 (_base): lr=0.0010 | momentum=0.9000\n",
      "260/300 * Epoch 260 (train): loss=0.4038\n",
      "260/300 * Epoch 260 (valid): cmc01=0.4932 | cmc05=0.7663 | cmc10=0.8494\n",
      "261/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.27it/s, loss=0.424]\n",
      "[2020-10-20 07:46:31,836] \n",
      "261/300 * Epoch 261 (_base): lr=0.0010 | momentum=0.9000\n",
      "261/300 * Epoch 261 (train): cmc05=-inf | loss=0.4022\n",
      "262/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.27it/s, loss=0.421]\n",
      "[2020-10-20 07:46:44,398] \n",
      "262/300 * Epoch 262 (_base): lr=0.0010 | momentum=0.9000\n",
      "262/300 * Epoch 262 (train): cmc05=-inf | loss=0.4012\n",
      "263/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.27it/s, loss=0.443]\n",
      "[2020-10-20 07:46:57,014] \n",
      "263/300 * Epoch 263 (_base): lr=0.0010 | momentum=0.9000\n",
      "263/300 * Epoch 263 (train): cmc05=-inf | loss=0.4020\n",
      "264/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.27it/s, loss=0.429]\n",
      "[2020-10-20 07:47:09,589] \n",
      "264/300 * Epoch 264 (_base): lr=0.0010 | momentum=0.9000\n",
      "264/300 * Epoch 264 (train): cmc05=-inf | loss=0.4002\n",
      "265/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.27it/s, loss=0.430]\n",
      "[2020-10-20 07:47:22,209] \n",
      "265/300 * Epoch 265 (_base): lr=0.0010 | momentum=0.9000\n",
      "265/300 * Epoch 265 (train): cmc05=-inf | loss=0.4021\n",
      "266/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.26it/s, loss=0.434]\n",
      "[2020-10-20 07:47:34,910] \n",
      "266/300 * Epoch 266 (_base): lr=0.0010 | momentum=0.9000\n",
      "266/300 * Epoch 266 (train): cmc05=-inf | loss=0.4001\n",
      "267/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.27it/s, loss=0.489]\n",
      "[2020-10-20 07:47:47,478] \n",
      "267/300 * Epoch 267 (_base): lr=0.0010 | momentum=0.9000\n",
      "267/300 * Epoch 267 (train): cmc05=-inf | loss=0.4025\n",
      "268/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.444]\n",
      "[2020-10-20 07:48:00,018] \n",
      "268/300 * Epoch 268 (_base): lr=0.0010 | momentum=0.9000\n",
      "268/300 * Epoch 268 (train): cmc05=-inf | loss=0.4032\n",
      "269/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.29it/s, loss=0.455]\n",
      "[2020-10-20 07:48:12,387] \n",
      "269/300 * Epoch 269 (_base): lr=0.0010 | momentum=0.9000\n",
      "269/300 * Epoch 269 (train): cmc05=-inf | loss=0.4007\n",
      "270/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.30it/s, loss=0.456]\n",
      "270/300 * Epoch (valid): 100% 52/52 [00:20<00:00,  2.58it/s]\n",
      "[2020-10-20 07:48:44,934] \n",
      "270/300 * Epoch 270 (_base): lr=0.0010 | momentum=0.9000\n",
      "270/300 * Epoch 270 (train): loss=0.4026\n",
      "270/300 * Epoch 270 (valid): cmc01=0.4936 | cmc05=0.7629 | cmc10=0.8490\n",
      "271/300 * Epoch (train): 100% 16/16 [00:13<00:00,  1.20it/s, loss=0.426]\n",
      "[2020-10-20 07:48:58,279] \n",
      "271/300 * Epoch 271 (_base): lr=0.0010 | momentum=0.9000\n",
      "271/300 * Epoch 271 (train): cmc05=-inf | loss=0.4036\n",
      "272/300 * Epoch (train): 100% 16/16 [00:13<00:00,  1.20it/s, loss=0.425]\n",
      "[2020-10-20 07:49:11,627] \n",
      "272/300 * Epoch 272 (_base): lr=0.0010 | momentum=0.9000\n",
      "272/300 * Epoch 272 (train): cmc05=-inf | loss=0.4016\n",
      "273/300 * Epoch (train): 100% 16/16 [00:13<00:00,  1.20it/s, loss=0.427]\n",
      "[2020-10-20 07:49:24,968] \n",
      "273/300 * Epoch 273 (_base): lr=0.0010 | momentum=0.9000\n",
      "273/300 * Epoch 273 (train): cmc05=-inf | loss=0.4012\n",
      "274/300 * Epoch (train): 100% 16/16 [00:13<00:00,  1.23it/s, loss=0.449]\n",
      "[2020-10-20 07:49:38,010] \n",
      "274/300 * Epoch 274 (_base): lr=0.0010 | momentum=0.9000\n",
      "274/300 * Epoch 274 (train): cmc05=-inf | loss=0.3994\n",
      "275/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.434]\n",
      "[2020-10-20 07:49:50,504] \n",
      "275/300 * Epoch 275 (_base): lr=0.0010 | momentum=0.9000\n",
      "275/300 * Epoch 275 (train): cmc05=-inf | loss=0.4018\n",
      "276/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.29it/s, loss=0.442]\n",
      "[2020-10-20 07:50:02,942] \n",
      "276/300 * Epoch 276 (_base): lr=0.0010 | momentum=0.9000\n",
      "276/300 * Epoch 276 (train): cmc05=-inf | loss=0.4005\n",
      "277/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.23it/s, loss=0.414]\n",
      "[2020-10-20 07:50:15,911] \n",
      "277/300 * Epoch 277 (_base): lr=0.0010 | momentum=0.9000\n",
      "277/300 * Epoch 277 (train): cmc05=-inf | loss=0.4004\n",
      "278/300 * Epoch (train): 100% 16/16 [00:13<00:00,  1.19it/s, loss=0.428]\n",
      "[2020-10-20 07:50:29,326] \n",
      "278/300 * Epoch 278 (_base): lr=0.0010 | momentum=0.9000\n",
      "278/300 * Epoch 278 (train): cmc05=-inf | loss=0.4031\n",
      "279/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.29it/s, loss=0.415]\n",
      "[2020-10-20 07:50:41,779] \n",
      "279/300 * Epoch 279 (_base): lr=0.0010 | momentum=0.9000\n",
      "279/300 * Epoch 279 (train): cmc05=-inf | loss=0.4005\n",
      "280/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.425]\n",
      "280/300 * Epoch (valid): 100% 52/52 [00:19<00:00,  2.60it/s]\n",
      "[2020-10-20 07:51:14,267] \n",
      "280/300 * Epoch 280 (_base): lr=0.0010 | momentum=0.9000\n",
      "280/300 * Epoch 280 (train): loss=0.4020\n",
      "280/300 * Epoch 280 (valid): cmc01=0.4905 | cmc05=0.7602 | cmc10=0.8316\n",
      "281/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.433]\n",
      "[2020-10-20 07:51:26,742] \n",
      "281/300 * Epoch 281 (_base): lr=0.0010 | momentum=0.9000\n",
      "281/300 * Epoch 281 (train): cmc05=-inf | loss=0.4011\n",
      "282/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.25it/s, loss=0.410]\n",
      "[2020-10-20 07:51:39,566] \n",
      "282/300 * Epoch 282 (_base): lr=0.0010 | momentum=0.9000\n",
      "282/300 * Epoch 282 (train): cmc05=-inf | loss=0.3991\n",
      "283/300 * Epoch (train): 100% 16/16 [00:13<00:00,  1.20it/s, loss=0.437]\n",
      "[2020-10-20 07:51:52,954] \n",
      "283/300 * Epoch 283 (_base): lr=0.0010 | momentum=0.9000\n",
      "283/300 * Epoch 283 (train): cmc05=-inf | loss=0.4044\n",
      "284/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.25it/s, loss=0.411]\n",
      "[2020-10-20 07:52:05,773] \n",
      "284/300 * Epoch 284 (_base): lr=0.0010 | momentum=0.9000\n",
      "284/300 * Epoch 284 (train): cmc05=-inf | loss=0.4018\n",
      "285/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.433]\n",
      "[2020-10-20 07:52:18,256] \n",
      "285/300 * Epoch 285 (_base): lr=0.0010 | momentum=0.9000\n",
      "285/300 * Epoch 285 (train): cmc05=-inf | loss=0.3992\n",
      "286/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.429]\n",
      "[2020-10-20 07:52:30,732] \n",
      "286/300 * Epoch 286 (_base): lr=0.0010 | momentum=0.9000\n",
      "286/300 * Epoch 286 (train): cmc05=-inf | loss=0.4011\n",
      "287/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.29it/s, loss=0.417]\n",
      "[2020-10-20 07:52:43,161] \n",
      "287/300 * Epoch 287 (_base): lr=0.0010 | momentum=0.9000\n",
      "287/300 * Epoch 287 (train): cmc05=-inf | loss=0.4014\n",
      "288/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.29it/s, loss=0.439]\n",
      "[2020-10-20 07:52:55,587] \n",
      "288/300 * Epoch 288 (_base): lr=0.0010 | momentum=0.9000\n",
      "288/300 * Epoch 288 (train): cmc05=-inf | loss=0.4021\n",
      "289/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.27it/s, loss=0.404]\n",
      "[2020-10-20 07:53:08,165] \n",
      "289/300 * Epoch 289 (_base): lr=0.0010 | momentum=0.9000\n",
      "289/300 * Epoch 289 (train): cmc05=-inf | loss=0.4006\n",
      "290/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.427]\n",
      "290/300 * Epoch (valid): 100% 52/52 [00:19<00:00,  2.65it/s]\n",
      "[2020-10-20 07:53:40,292] \n",
      "290/300 * Epoch 290 (_base): lr=0.0010 | momentum=0.9000\n",
      "290/300 * Epoch 290 (train): loss=0.3991\n",
      "290/300 * Epoch 290 (valid): cmc01=0.4685 | cmc05=0.7481 | cmc10=0.8373\n",
      "291/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.428]\n",
      "[2020-10-20 07:53:52,816] \n",
      "291/300 * Epoch 291 (_base): lr=0.0010 | momentum=0.9000\n",
      "291/300 * Epoch 291 (train): cmc05=-inf | loss=0.4016\n",
      "292/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.27it/s, loss=0.423]\n",
      "[2020-10-20 07:54:05,391] \n",
      "292/300 * Epoch 292 (_base): lr=0.0010 | momentum=0.9000\n",
      "292/300 * Epoch 292 (train): cmc05=-inf | loss=0.3994\n",
      "293/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.428]\n",
      "[2020-10-20 07:54:17,849] \n",
      "293/300 * Epoch 293 (_base): lr=0.0010 | momentum=0.9000\n",
      "293/300 * Epoch 293 (train): cmc05=-inf | loss=0.4010\n",
      "294/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.430]\n",
      "[2020-10-20 07:54:30,370] \n",
      "294/300 * Epoch 294 (_base): lr=0.0010 | momentum=0.9000\n",
      "294/300 * Epoch 294 (train): cmc05=-inf | loss=0.3996\n",
      "295/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.455]\n",
      "[2020-10-20 07:54:42,913] \n",
      "295/300 * Epoch 295 (_base): lr=0.0010 | momentum=0.9000\n",
      "295/300 * Epoch 295 (train): cmc05=-inf | loss=0.4024\n",
      "296/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.30it/s, loss=0.444]\n",
      "[2020-10-20 07:54:55,269] \n",
      "296/300 * Epoch 296 (_base): lr=0.0010 | momentum=0.9000\n",
      "296/300 * Epoch 296 (train): cmc05=-inf | loss=0.3995\n",
      "297/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.29it/s, loss=0.460]\n",
      "[2020-10-20 07:55:07,657] \n",
      "297/300 * Epoch 297 (_base): lr=0.0010 | momentum=0.9000\n",
      "297/300 * Epoch 297 (train): cmc05=-inf | loss=0.3998\n",
      "298/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.29it/s, loss=0.452]\n",
      "[2020-10-20 07:55:20,065] \n",
      "298/300 * Epoch 298 (_base): lr=0.0010 | momentum=0.9000\n",
      "298/300 * Epoch 298 (train): cmc05=-inf | loss=0.4000\n",
      "299/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.30it/s, loss=0.435]\n",
      "[2020-10-20 07:55:32,418] \n",
      "299/300 * Epoch 299 (_base): lr=0.0010 | momentum=0.9000\n",
      "299/300 * Epoch 299 (train): cmc05=-inf | loss=0.4020\n",
      "300/300 * Epoch (train): 100% 16/16 [00:12<00:00,  1.28it/s, loss=0.421]\n",
      "300/300 * Epoch (valid): 100% 52/52 [00:19<00:00,  2.67it/s]\n",
      "[2020-10-20 07:56:04,418] \n",
      "300/300 * Epoch 300 (_base): lr=0.0010 | momentum=0.9000\n",
      "300/300 * Epoch 300 (train): loss=0.4004\n",
      "300/300 * Epoch 300 (valid): cmc01=0.4920 | cmc05=0.7614 | cmc10=0.8448\n"
     ]
    }
   ],
   "source": [
    "runner = dl.SupervisedRunner(device=utils.get_device())\n",
    "runner.train(\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    callbacks=callbacks,\n",
    "    loaders={\"train\": train_loader, \"valid\": valid_loader},\n",
    "    minimize_metric=False,\n",
    "    verbose=True,\n",
    "    valid_loader=\"valid\",\n",
    "    num_epochs=num_epochs,\n",
    "    main_metric=\"cmc05\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now try to implement sampler and loss by yourself!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hard Cluster Triplet Sampler\n",
    "\n",
    "**tl;dr**\n",
    "\n",
    "The target is to minimise intra class variations and to maximize the inter class variations.\n",
    "\n",
    "First of all we counting \"centroids\" of a class:\n",
    "$$\n",
    "f_{i}^{m}=\\frac{\\sum^{K} f(x)}{K}\n",
    "$$\n",
    "\n",
    "then we are counting intra class loss:\n",
    "$$\n",
    "d_{i}^{i n t r a}=\\max _{K}\\left\\|f(x)-f_{i}^{m}\\right\\|_{2}^{2}\n",
    "$$\n",
    "and inter class loss:\n",
    "$$\n",
    "d_{i}^{\\text {inter}}=\\min _{\\forall i_{d} \\in P, i_{d} \\neq i}\\left\\|f_{i}^{m}-f_{i_{d}}^{m}\\right\\|_{2}^{2}\n",
    "$$\n",
    "\n",
    "The final loss is:\n",
    "$$\n",
    "L b_{c}=\\sum_{i}^{P} \\max \\left(\\left(d_{i}^{i n t r a}-d_{i}^{i n t e r}+\\alpha\\right), 0\\right)\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "[article](https://arxiv.org/abs/1812.10325)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catalyst.data import IInbatchTripletSampler\n",
    "\n",
    "class HardClusterTripletsSampler(IInbatchTripletSampler):\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Initialize everything you need\n",
    "        pass\n",
    "\n",
    "    def sample(self, features, labels):\n",
    "        # Sample object for Triplet Loss.\n",
    "        # May be you need mean vectors for each cluster(label)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 300\n",
    "lr = 1e-2\n",
    "\n",
    "model = nn.Sequential(\n",
    "    conv_block(1, 4),\n",
    "    conv_block(4, 8),\n",
    "    conv_block(8, 16),\n",
    "    conv_block(16, 32),\n",
    "    conv_block(32, 64),\n",
    "    nn.Flatten(),\n",
    "    Normalize()\n",
    ")\n",
    "optimizer = RAdam(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, [100,])\n",
    "\n",
    "sampler_inbatch = HardClusterTripletsSampler()\n",
    "criterion = TripletMarginLossWithSampler(margin=0.3, sampler_inbatch=sampler_inbatch)\n",
    "\n",
    "callbacks = [\n",
    "    dl.ControlFlowCallback(\n",
    "        dl.CriterionCallback(), \n",
    "        loaders=\"train\"\n",
    "    ),\n",
    "    dl.ControlFlowCallback(dl.CMCScoreCallback(topk_args=[1, 5, 10]), loaders=\"valid\"),\n",
    "    dl.PeriodicLoaderCallback(valid=10),\n",
    "    dl.SchedulerCallback(),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = dl.SupervisedRunner(device=utils.get_device())\n",
    "runner.train(\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    callbacks=callbacks,\n",
    "    loaders={\"train\": train_loader, \"valid\": valid_loader},\n",
    "    minimize_metric=False,\n",
    "    verbose=True,\n",
    "    valid_loader=\"valid\",\n",
    "    num_epochs=num_epochs,\n",
    "    main_metric=\"cmc05\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical Triplet Loss\n",
    "\n",
    "![](https://cdn.mathpix.com/snip/images/1TyIaVSJSOgWcwLS62bmsMFJTG5rDGKYjUVqRDdZi3w.original.fullsize.png)\n",
    "\n",
    "Here we will construct hierarchical structure of classes based on the computed interclass distances.\n",
    "\n",
    "So the algoruthm looks like:\n",
    "\n",
    "![](https://cdn.mathpix.com/snip/images/pYM4D0nkTjPxRpMWzOth3Duxnyj8sKdLpU4xXmeu7SQ.original.fullsize.png)\n",
    "\n",
    "You can try to build a tree in a way that every leaf represents a letter and every root of this leaf represents an alphabet.\n",
    "In this case, your tree has a depth of 3. Also, you can skip the step with updating the tree.\n",
    "\n",
    "\n",
    "[article](https://arxiv.org/pdf/1810.06951.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import triplet_margin_loss\n",
    "\n",
    "\n",
    "class HierarchicalTripletMarginLossWithSampler(nn.Module):\n",
    "    \"\"\"\n",
    "    This class combines in-batch sampling of triplets and\n",
    "    default TripletMargingLoss from PyTorch.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sampler_inbatch):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            margin: margin value\n",
    "            sampler_inbatch: sampler for forming triplets inside the batch\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self._sampler_inbatch = sampler_inbatch\n",
    "        self._triplet_margin_loss = triplet_margin_loss\n",
    "\n",
    "    def forward(self, features, labels):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            features: features with the shape of [batch_size, features_dim]\n",
    "            labels: labels of samples having batch_size elements\n",
    "        Returns: loss value\n",
    "        \"\"\"\n",
    "        labels_list = convert_labels2list(labels)\n",
    "\n",
    "        (\n",
    "            features_anchor,\n",
    "            features_positive,\n",
    "            features_negative,\n",
    "        ) = self._sampler_inbatch.sample(features=features, labels=labels_list)\n",
    "        \n",
    "        margin = ... # Calculate margin based on label\n",
    "\n",
    "        loss = self._triplet_margin_loss(\n",
    "            anchor=features_anchor,\n",
    "            positive=features_positive,\n",
    "            negative=features_negative,\n",
    "            margin=margin\n",
    "        )\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 300\n",
    "lr = 1e-2\n",
    "\n",
    "model = nn.Sequential(\n",
    "    conv_block(1, 4),\n",
    "    conv_block(4, 8),\n",
    "    conv_block(8, 16),\n",
    "    conv_block(16, 32),\n",
    "    conv_block(32, 64),\n",
    "    nn.Flatten(),\n",
    "    Normalize()\n",
    ")\n",
    "optimizer = RAdam(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, [100,])\n",
    "\n",
    "sampler_inbatch = HardTripletsSampler()\n",
    "criterion = HierarchicalTripletMarginLossWithSampler(sampler_inbatch=sampler_inbatch)\n",
    "\n",
    "callbacks = [\n",
    "    dl.ControlFlowCallback(\n",
    "        dl.CriterionCallback(), \n",
    "        loaders=\"train\"\n",
    "    ),\n",
    "    dl.ControlFlowCallback(dl.CMCScoreCallback(topk_args=[1, 5, 10]), loaders=\"valid\"),\n",
    "    dl.PeriodicLoaderCallback(valid=10),\n",
    "    dl.SchedulerCallback(),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = dl.SupervisedRunner(device=utils.get_device())\n",
    "runner.train(\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    callbacks=callbacks,\n",
    "    loaders={\"train\": train_loader, \"valid\": valid_loader},\n",
    "    minimize_metric=False,\n",
    "    verbose=True,\n",
    "    valid_loader=\"valid\",\n",
    "    num_epochs=num_epochs,\n",
    "    main_metric=\"cmc05\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional Task\n",
    "If you implemented all methods quickly and sure about correctness, you can try to compare three methods.\n",
    "But it takes time and resources to compare the methods properly.\n",
    "\n",
    "< results >"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "5 Seminar",
   "private_outputs": true,
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}