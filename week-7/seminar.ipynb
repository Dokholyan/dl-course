{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U torch catalyst tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Models\n",
    "\n",
    "Hi! Today we are going to learn about generative models. We'll continue to work with handwritten numbers, but we will generate with different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catalyst.utils import set_global_seed, get_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_global_seed(42)\n",
    "# device = get_device()\n",
    "device = \"cuda:1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll work with `MNIST` dataset. Download it, show examples of the writting and prepare the dataset to be loaded into models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catalyst.contrib.datasets import mnist\n",
    "\n",
    "\n",
    "train = mnist.MNIST(\".\", train=True, download=True)\n",
    "valid = mnist.MNIST(\".\", train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "_, axs = plt.subplots(4, 4, figsize=(10, 10))\n",
    "\n",
    "for i in range(16):\n",
    "    axs[i // 4][i % 4].imshow(train[100 * i + i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catalyst.utils import get_loader\n",
    "\n",
    "\n",
    "batch_size = 1024\n",
    "num_workers = 4\n",
    "\n",
    "def transform(x):\n",
    "    image = torch.FloatTensor(x[\"image\"])\n",
    "    image = torch.where(image > 127, torch.ones(image.shape), torch.zeros(image.shape))\n",
    "    return {'image': image, \"targets\": x[\"targets\"]}\n",
    "\n",
    "\n",
    "train_data_loader = get_loader(\n",
    "    train,\n",
    "    open_fn=lambda x : {'image': x[0].reshape(1, 28, 28), 'targets': x[1]},\n",
    "    dict_transform=transform,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    shuffle=True,\n",
    "    sampler=None,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "valid_data_loader = get_loader(\n",
    "    valid,\n",
    "    open_fn=lambda x : {'image': x[0].reshape(1, 28, 28), 'targets': x[1]},\n",
    "    dict_transform=transform,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    shuffle=False,\n",
    "    sampler=None,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN\n",
    "\n",
    "For GAN model, we need a Discriminator and a Generator. The Discriminator will judge generated images, how do they like real one. The Generator tries to fool the Discriminator.\n",
    "\n",
    "Notice that Generator is similar to Decoder in AE/VAE perspective. It will required later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.feature_extractor = ... # from image to feature vector\n",
    "        self.clf = ... # classify vectors\n",
    "        \n",
    "    def forward(self, images):\n",
    "        features = self.feature_extractor(images)\n",
    "        return self.clf(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catalyst.contrib.nn.modules import Lambda\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, image_size=(28, 28), latent_size=10):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.image_size = image_size\n",
    "        self.latent_size = latent_size\n",
    "        \n",
    "        self.map_generator = nn.Sequential(\n",
    "            nn.Linear(latent_size, 64 * 49),\n",
    "            Lambda(lambda x: x.view(x.size(0), 64, 7, 7)),\n",
    "        )\n",
    "        self.deconv = nn.Sequential(\n",
    "            self.make_up_layer_(64, 16), # 7 -> 14\n",
    "            self.make_up_layer_(16, 4), # 14 -> 28\n",
    "        )\n",
    "            \n",
    "        self.output = nn.Sequential(\n",
    "            nn.Conv2d(4, 1, 3, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "            \n",
    "    def forward(self, points):\n",
    "        feature_map = self.map_generator(points)\n",
    "        feature_map = self.deconv(feature_map)\n",
    "        return self.output(feature_map)\n",
    "            \n",
    "    def make_up_layer_(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                    in_channels,\n",
    "                    out_channels,\n",
    "                    kernel_size=3,\n",
    "                    stride=2,\n",
    "                    padding=1,\n",
    "                    output_padding=1,\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(\n",
    "                    out_channels,\n",
    "                    out_channels,\n",
    "                    kernel_size=3,\n",
    "                    padding=1,\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To monitor decoded images, we have to write a new callback function. It will log image into the tensorboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catalyst.core import Callback, CallbackOrder\n",
    "\n",
    "\n",
    "class LogFigureCallback(Callback):\n",
    "    def __init__(self):\n",
    "        super().__init__(CallbackOrder.External)\n",
    "\n",
    "    def on_epoch_end(self, runner):\n",
    "        tb_callback = runner.callbacks[\"_tensorboard\"]\n",
    "        logger = tb_callback.loggers[runner.loader_name]\n",
    "        logger.add_images(\n",
    "            \"image/epoch\", \n",
    "            runner.output[\"generated_images\"][:64], \n",
    "            global_step=runner.epoch\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create model, criterion, optimizer. Train model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catalyst.contrib.nn.optimizers import RAdam\n",
    "\n",
    "\n",
    "generator_1 = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "model = {\"generator\": ..., \"discriminator\": ...} # set models\n",
    "optimizer = {\n",
    "    \"generator\": ...\n",
    "    \"discriminator\": ...\n",
    "} # set optimizers\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "loaders = {\n",
    "    \"train\": ..., # set loaders\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catalyst import dl\n",
    "\n",
    "\n",
    "callbacks = [\n",
    "    dl.OptimizerCallback(\n",
    "        optimizer_key=\"generator\", \n",
    "        metric_key=\"loss_generator\"\n",
    "    ),\n",
    "    dl.OptimizerCallback(\n",
    "        optimizer_key=\"discriminator\", \n",
    "        metric_key=\"loss_discriminator\"\n",
    "    ),\n",
    "    LogFigureCallback()\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training process consists in two phases: discriminator and generator parts. The discriminator is differential metrics of \"fakeness\". So, it's trained to discriminate objects by `BinaryCrossEntropyLoss`. Because the discriminator is differential, we can pass knowledge about real images by backpropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANRunner(dl.Runner):\n",
    "\n",
    "    def _handle_batch(self, batch):\n",
    "        real_images = batch[\"image\"]\n",
    "        batch_metrics = {}\n",
    "        latent_size = self.model[\"generator\"].latent_size\n",
    "        \n",
    "        # Sample random points in the latent space\n",
    "        batch_size = real_images.shape[0]\n",
    "        random_latent_vectors = torch.randn(batch_size, latent_size).to(self.device)\n",
    "        \n",
    "        # Generate fake images by random points\n",
    "        generated_images = ... # don't forget about .detach()\n",
    "        # Combine them with real images\n",
    "        combined_images = torch.cat([generated_images, real_images])\n",
    "        \n",
    "        # Assemble labels discriminating real from fake images\n",
    "        labels = torch.cat([\n",
    "            torch.ones((batch_size, 1)), torch.zeros((batch_size, 1))\n",
    "        ]).to(self.device)\n",
    "        \n",
    "        # Train the discriminator\n",
    "        predictions = ... # get predicitons from discriminator\n",
    "        batch_metrics[\"loss_discriminator\"] = ... # calculate loss\n",
    "        \n",
    "        # Sample random points in the latent space\n",
    "        random_latent_vectors = torch.randn(batch_size, latent_size).to(self.device)\n",
    "        # Assemble labels that say \"all real images\"\n",
    "        misleading_labels = torch.zeros((batch_size, 1)).to(self.device)\n",
    "        \n",
    "        # Train the generator\n",
    "        generated_images = ... # generate fake images\n",
    "        self.output = {\"generated_images\": generated_images}\n",
    "        predictions = self.model[\"discriminator\"](generated_images)\n",
    "        batch_metrics[\"loss_generator\"] = ... # calculate loss for generator\n",
    "        \n",
    "        self.batch_metrics.update(**batch_metrics)\n",
    "\n",
    "\n",
    "runner = GANRunner(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "logdir = Path(\"logs\") / datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "# %reload_ext tensorboard\n",
    "# %tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner.train(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    loaders=loaders,\n",
    "    callbacks=callbacks,\n",
    "    num_epochs=10,\n",
    "    verbose=True,\n",
    "    logdir=logdir,\n",
    "    main_metric=\"loss_generator\",\n",
    "    minimize_metric=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAE-GAN\n",
    "\n",
    "Remember that the Discriminator is a Decoder? Let's add an Encoder in our training rutin:\n",
    "\n",
    "![](https://habrastorage.org/web/7a1/8db/d39/7a18dbd3969048c2b085cc707e539f0c.png)\n",
    "\n",
    "It will make latent space meaningfull.\n",
    "\n",
    "To train all these models, we need new loss function for encoder model. We need to compare results from the Discriminator with the real images. Instead from comparing images in the original sizes, we can compare feature maps from the Discriminator.\n",
    "\n",
    "\n",
    "https://arxiv.org/pdf/1512.09300.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_size=10):\n",
    "        super().__init__()\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(1, 4, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(4, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(16, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveMaxPool2d((1, 1)),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        self.latent_space = nn.Linear(64, 2 * latent_size)\n",
    "        \n",
    "        self.latent_size = latent_size\n",
    "        \n",
    "    def forward(self, images):\n",
    "        features = self.feature_extractor(images)\n",
    "        latent = self.latent_space(features)\n",
    "        return latent[:, :self.latent_size], latent[:, self.latent_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator_v2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.feature_extractor = ... # from image to feature vector\n",
    "        self.clf = ... # classify vectors\n",
    "        \n",
    "    def forward(self, images):\n",
    "        features = self.feature_extractor(images)\n",
    "        return self.clf(features), features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KLVAELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, loc, log_scale):\n",
    "        return (-0.5 * torch.sum(log_scale - loc.pow(2) - log_scale.exp(), dim=1)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder()\n",
    "generator_2 = Generator()\n",
    "discriminator = Discriminator_v2().to(device)\n",
    "\n",
    "model = {\"generator\": ..., \"discriminator\": ..., \"encoder\": ...}# set models\n",
    "optimizer = {\n",
    "    \"generator\": ...,\n",
    "    \"discriminator\": ...,\n",
    "    \"encoder\": ...,\n",
    "} # set optimizers\n",
    "criterion = {\n",
    "    \"bce\": nn.BCEWithLogitsLoss(),\n",
    "    \"mse\": nn.MSELoss(),\n",
    "    \"vae\": KLVAELoss()\n",
    "}\n",
    "loaders = {\n",
    "    \"train\": ..., # set loaders\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    LogFigureCallback(),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look the architecture and parameter update rutine:\n",
    "\n",
    "Model Architecture:\n",
    "![image](https://habrastorage.org/web/701/bbb/212/701bbb21273045fc9ed4aab7e0529764.png)\n",
    "\n",
    "Parameter Updates:\n",
    "![image](https://habrastorage.org/getpro/habr/post_images/07a/d0b/dc0/07ad0bdc0524f17cd4ae6c6e1be3c36d.svg)\n",
    "\n",
    "What we need to code?\n",
    "\n",
    "- Encoding training: compact latent space (KL Loss) and object reconstruction\n",
    "- Discriminator training: discriminate real from fake and reconstructed\n",
    "- Generator/decoder training: object reconstruction and fake object generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_SCALE_MAX = 2\n",
    "LOG_SCALE_MIN = -10\n",
    "\n",
    "\n",
    "def normal_sample(loc, log_scale):\n",
    "    scale = torch.exp(0.5 * log_scale)\n",
    "    return loc + scale * torch.randn_like(scale)\n",
    "\n",
    "\n",
    "class VAEGANRunner(dl.Runner):\n",
    "    def _zero_grad(self):\n",
    "        for optimizer in self.optimizer.values():\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "    def _handle_batch(self, batch):\n",
    "        real_images = batch[\"image\"]\n",
    "        batch_metrics = {}\n",
    "        latent_size = self.model[\"generator\"].latent_size\n",
    "        \n",
    "        # encoder-decoder part\n",
    "        latent_loc, latent_log_scale = self.model[\"encoder\"](real_images)\n",
    "        loss_prior = self.criterion[\"vae\"](latent_loc, latent_log_scale)\n",
    "            \n",
    "        latent_log_scale = torch.clamp(latent_log_scale, LOG_SCALE_MIN, LOG_SCALE_MAX)\n",
    "        latent_vectors = normal_sample(latent_loc, latent_log_scale)\n",
    "        \n",
    "        decoded_images = self.model[\"generator\"](latent_vectors)\n",
    "        \n",
    "        _, predictions_decoded = self.model[\"discriminator\"](decoded_images)\n",
    "        _, predictions_real = self.model[\"discriminator\"](real_images)\n",
    "        loss_dislike = ... # calculate dislike\n",
    "        \n",
    "        # generator part\n",
    "        \n",
    "        batch_size = real_images.shape[0]\n",
    "        random_latent_vectors = torch.randn(batch_size, latent_size).to(self.device)\n",
    "        \n",
    "        generated_images = ... # generate images\n",
    "        \n",
    "        combined_images = torch.cat([generated_images, decoded_images])\n",
    "        labels = torch.zeros((2 * batch_size, 1)).to(self.device)\n",
    "        \n",
    "        self.output = {\"generated_images\": generated_images}\n",
    "        predictions, _ = self.model[\"discriminator\"](combined_images)\n",
    "        loss_generator = ... # calculate loss for generator\n",
    "        \n",
    "        # discriminator part\n",
    "        \n",
    "        latent_vectors = normal_sample(latent_loc, latent_log_scale)\n",
    "        random_latent_vectors = torch.randn(batch_size, latent_size).to(self.device)\n",
    "        \n",
    "        decoded_images = ... # decode images\n",
    "        generated_images = ... # generate images\n",
    "        \n",
    "        combined_images = torch.cat([generated_images, decoded_images, real_images]).detach()\n",
    "        labels = torch.cat([\n",
    "            torch.ones((2 * batch_size, 1)), torch.zeros((batch_size, 1))\n",
    "        ]).to(self.device)\n",
    "        predictions, _ = self.model[\"discriminator\"](combined_images)\n",
    "        loss_discriminator = ... # caalculate loos for discriminator\n",
    "        \n",
    "        # closely look at the picture above and sum up losses for all part of VAE-GAN\n",
    "        batch_metrics[\"loss_encoder\"] = ...\n",
    "        batch_metrics[\"loss_generator\"] = ...\n",
    "        batch_metrics[\"loss_discriminator\"] = ...\n",
    "        if self.is_train_loader:\n",
    "            batch_metrics[\"loss_encoder\"].backward(retain_graph=True)\n",
    "            optimizer[\"encoder\"].step()\n",
    "            self._zero_grad()\n",
    "            \n",
    "            batch_metrics[\"loss_generator\"].backward(retain_graph=True)\n",
    "            optimizer[\"generator\"].step()\n",
    "            self._zero_grad()\n",
    "            \n",
    "            batch_metrics[\"loss_discriminator\"].backward()\n",
    "            optimizer[\"discriminator\"].step()\n",
    "            self._zero_grad()\n",
    "        \n",
    "        self.batch_metrics.update(**batch_metrics)\n",
    "\n",
    "\n",
    "runner = VAEGANRunner(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = Path(\"logs\") / datetime.now().strftime(\"%Y%m%d-%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner.train(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    loaders=loaders,\n",
    "    callbacks=callbacks,\n",
    "    num_epochs=10,\n",
    "    verbose=True,\n",
    "    logdir=logdir,\n",
    "    main_metric=\"loss_generator\",\n",
    "    minimize_metric=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to compare models? Usually reseacher just closely look at the pictures. But they can use computer brains and eyes to compare generative models. Let's look at the one of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inception score\n",
    "\n",
    "Wait, wat? We can create numerical metric for generative models? Yes, we can. The metric called Inception score. To calculate it, we need the image classificator and generated images. Let's do it.\n",
    "\n",
    "\\*Inception score usually calculates for generators, trained on ImageNet/CIFAR. But we have no time to train GAN on these datasets. So, we will work with MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_model = nn.Sequential(...).to(device) # create simple classification model\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = RAdam(clf_model.parameters(), lr=1e-2)\n",
    "\n",
    "runner = dl.SupervisedRunner(\n",
    "    device=device,\n",
    "    input_key=\"image\",\n",
    "    output_key=\"logits\",\n",
    "    input_target_key=\"targets\", \n",
    ")\n",
    "runner.train(\n",
    "    model=clf_model, \n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    callbacks=[\n",
    "        dl.AccuracyCallback()\n",
    "    ],\n",
    "    loaders={\n",
    "        \"train\": train_data_loader,\n",
    "        \"valid\": valid_data_loader\n",
    "    },\n",
    "    num_epochs=5,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inception Score fomulating by this:\n",
    "\n",
    "![](https://www.oreilly.com/library/view/generative-adversarial-networks/9781789136678/assets/0d33c46a-0a5f-4027-919c-30b910e6d93b.png)\n",
    "\n",
    "where $p(y)$ – is probability of class in a dataset, $p(y|x)$ – is probability of class of object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import trange\n",
    "\n",
    "\n",
    "def inception_score(model):\n",
    "    p_y = torch.ones(10).to(device) / 10\n",
    "    log_is = 0\n",
    "    num_images = 50000\n",
    "    batch_size = 100\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for _ in trange(num_images // batch_size):\n",
    "            latent_size = model.latent_size\n",
    "            random_latent_points = torch.randn((batch_size, latent_size)).to(device)\n",
    "            generated = ... # generate images\n",
    "            logits = ... # classify images \n",
    "            p_y_x = ... # get probabilities\n",
    "            log_is += (torch.log(p_y_x) * p_y_x - torch.log(p_y) * p_y_x).sum(1)\n",
    "\n",
    "    log_is /= num_images\n",
    "    return torch.exp(log_is.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_score(generator_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_score(generator_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Additional) Another point in VAE - GAN: AAE\n",
    "\n",
    "AAE stands for Adversarial Autoencoders. It is like a inverted VAE-GAN. A main model become AE, but we will use Discriminator to compare points in a latent space. Let's code it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Disciriminator_v3(nn.Module):\n",
    "    def __init__(self, latent_size=4):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.latent_size = latent_size\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_size, 100),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, z):\n",
    "        return self.model(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_size=10):\n",
    "        super().__init__()\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(1, 4, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(4, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(16, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveMaxPool2d((1, 1)),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        self.latent_space = nn.Linear(64, latent_size)\n",
    "        \n",
    "        self.latent_size = latent_size\n",
    "        \n",
    "    def forward(self, images):\n",
    "        features = self.feature_extractor(images)\n",
    "        latent = self.latent_space(features)\n",
    "        # Instead of VAE, AAE use simple encoder\n",
    "        # because it can be trained by samples, not distributions.\n",
    "        return latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, image_size=(28, 28), latent_size=10):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.image_size = image_size\n",
    "        self.latent_size = latent_size\n",
    "        \n",
    "        self.map_generator = nn.Sequential(\n",
    "            nn.Linear(latent_size, 64 * 49),\n",
    "            Lambda(lambda x: x.view(x.size(0), 64, 7, 7)),\n",
    "        )\n",
    "        self.deconv = nn.Sequential(\n",
    "            self.make_up_layer_(64, 16), # 7 -> 14\n",
    "            self.make_up_layer_(16, 4), # 14 -> 28\n",
    "        )\n",
    "            \n",
    "        self.output = nn.Sequential(\n",
    "            nn.Conv2d(4, 1, 3, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "            \n",
    "    def forward(self, points):\n",
    "        feature_map = self.map_generator(points)\n",
    "        feature_map = self.deconv(feature_map)\n",
    "        return self.output(feature_map)\n",
    "            \n",
    "    def make_up_layer_(self, in_channels, out_channels):\n",
    "        return nn.Sequential(nn.ConvTranspose2d(\n",
    "                    in_channels,\n",
    "                    out_channels,\n",
    "                    kernel_size=3,\n",
    "                    stride=2,\n",
    "                    padding=1,\n",
    "                    output_padding=1,\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AE(nn.Module):\n",
    "    def __init__(self, image_size=(28, 28), latent_size=4):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = Encoder(latent_size)\n",
    "        self.decoder = Decoder(image_size, latent_size)\n",
    "        \n",
    "    def forward(self, images):\n",
    "        latent = self.encoder(images)\n",
    "        x_ = self.decoder(latent)\n",
    "\n",
    "        return {\n",
    "            \"decoder_result\": x_,\n",
    "            \"latent\": latent\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = AE()\n",
    "discriminator = Disciriminator_v3()\n",
    "model = {\"autoencoder\": autoencoder, \"discriminator\": discriminator}\n",
    "optimizer = {\n",
    "    \"autoencoder\": RAdam(autoencoder.parameters(), lr=1e-3), \n",
    "    \"discriminator\": RAdam(discriminator.parameters(), lr=1e-3),\n",
    "}\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    LogFigureCallback(),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AAERunner(dl.Runner):\n",
    "    def _zero_grad(self):\n",
    "        for optimizer in self.optimizer.values():\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "    def _handle_batch(self, batch):\n",
    "        real_images = batch[\"image\"]\n",
    "        batch_metrics = {}\n",
    "        latent_size = self.model[\"discriminator\"].latent_size\n",
    "        batch_size = real_images.size(0)\n",
    "        \n",
    "        output = self.model[\"autoencoder\"](real_images)\n",
    "        fake_latent = output[\"latent\"]\n",
    "        decoded_images = output[\"decoder_result\"]\n",
    "        \n",
    "        self.output = {\"generated_images\": decoded_images}\n",
    "        normal_latent = torch.randn(fake_latent.size()).to(self.device)\n",
    "        \n",
    "        loss_ae = self.criterion(\n",
    "            decoded_images.reshape(batch_size, -1), \n",
    "            real_images.reshape(batch_size, -1)\n",
    "        )\n",
    "        \n",
    "        concat_latent = torch.cat([normal_latent, fake_latent]).detach()\n",
    "        target = torch.cat(\n",
    "            [torch.ones(batch_size), torch.zeros(batch_size)]\n",
    "        ).to(self.device)\n",
    "        pred = self.model[\"discriminator\"](concat_latent)\n",
    "        batch_metrics[\"loss_discriminator\"] = self.criterion(\n",
    "            pred, target\n",
    "        )\n",
    "        \n",
    "        fake_pred = self.model[\"discriminator\"](fake_latent)\n",
    "        fake_target = torch.ones(batch_size).to(self.device)\n",
    "        loss_fake_latent = self.criterion(\n",
    "            fake_pred, fake_target\n",
    "        )\n",
    "        \n",
    "        batch_metrics[\"loss_autoencoder\"] = loss_ae + loss_fake_latent\n",
    "        \n",
    "        if self.is_train_loader:\n",
    "            optimizer[\"discriminator\"].zero_grad()\n",
    "            batch_metrics[\"loss_discriminator\"].backward(retain_graph=True)\n",
    "            optimizer[\"discriminator\"].step()\n",
    "            \n",
    "            optimizer[\"autoencoder\"].zero_grad()\n",
    "            batch_metrics[\"loss_autoencoder\"].backward()\n",
    "            optimizer[\"autoencoder\"].step()\n",
    "        \n",
    "        self.batch_metrics.update(**batch_metrics)\n",
    "\n",
    "\n",
    "runner = AAERunner(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = Path(\"logs\") / datetime.now().strftime(\"%Y%m%d-%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.64it/s, loss_autoencoder=1.386, loss_discriminator=0.701]\n",
      "[2020-10-29 06:01:36,696] \n",
      "1/1000 * Epoch 1 (train): loss_autoencoder=1.4332 | loss_discriminator=0.6939\n",
      "2/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.60it/s, loss_autoencoder=1.312, loss_discriminator=0.699]\n",
      "[2020-10-29 06:01:43,509] \n",
      "2/1000 * Epoch 2 (train): loss_autoencoder=1.3466 | loss_discriminator=0.7018\n",
      "3/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.83it/s, loss_autoencoder=1.243, loss_discriminator=0.698]\n",
      "[2020-10-29 06:01:50,224] \n",
      "3/1000 * Epoch 3 (train): loss_autoencoder=1.2759 | loss_discriminator=0.6979\n",
      "4/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.63it/s, loss_autoencoder=1.173, loss_discriminator=0.697]\n",
      "[2020-10-29 06:01:57,117] \n",
      "4/1000 * Epoch 4 (train): loss_autoencoder=1.2055 | loss_discriminator=0.6957\n",
      "5/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.63it/s, loss_autoencoder=1.112, loss_discriminator=0.695]\n",
      "[2020-10-29 06:02:03,962] \n",
      "5/1000 * Epoch 5 (train): loss_autoencoder=1.1402 | loss_discriminator=0.6950\n",
      "6/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.75it/s, loss_autoencoder=1.063, loss_discriminator=0.695]\n",
      "[2020-10-29 06:02:10,723] \n",
      "6/1000 * Epoch 6 (train): loss_autoencoder=1.0864 | loss_discriminator=0.6950\n",
      "7/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.79it/s, loss_autoencoder=1.029, loss_discriminator=0.694]\n",
      "[2020-10-29 06:02:17,425] \n",
      "7/1000 * Epoch 7 (train): loss_autoencoder=1.0448 | loss_discriminator=0.6942\n",
      "8/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.67it/s, loss_autoencoder=1.004, loss_discriminator=0.694]\n",
      "[2020-10-29 06:02:24,217] \n",
      "8/1000 * Epoch 8 (train): loss_autoencoder=1.0156 | loss_discriminator=0.6938\n",
      "9/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.65it/s, loss_autoencoder=0.989, loss_discriminator=0.693]\n",
      "[2020-10-29 06:02:31,032] \n",
      "9/1000 * Epoch 9 (train): loss_autoencoder=0.9966 | loss_discriminator=0.6935\n",
      "10/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.74it/s, loss_autoencoder=0.979, loss_discriminator=0.694]\n",
      "[2020-10-29 06:02:37,779] \n",
      "10/1000 * Epoch 10 (train): loss_autoencoder=0.9845 | loss_discriminator=0.6934\n",
      "11/1000 * Epoch (train): 100% 58/58 [00:05<00:00,  9.67it/s, loss_autoencoder=0.974, loss_discriminator=0.694]\n",
      "[2020-10-29 06:02:43,882] \n",
      "11/1000 * Epoch 11 (train): loss_autoencoder=0.9767 | loss_discriminator=0.6933\n",
      "12/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.80it/s, loss_autoencoder=0.973, loss_discriminator=0.693]\n",
      "[2020-10-29 06:02:50,575] \n",
      "12/1000 * Epoch 12 (train): loss_autoencoder=0.9718 | loss_discriminator=0.6932\n",
      "13/1000 * Epoch (train): 100% 58/58 [00:07<00:00,  7.74it/s, loss_autoencoder=0.967, loss_discriminator=0.693]\n",
      "[2020-10-29 06:02:58,172] \n",
      "13/1000 * Epoch 13 (train): loss_autoencoder=0.9683 | loss_discriminator=0.6932\n",
      "14/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.75it/s, loss_autoencoder=0.967, loss_discriminator=0.693]\n",
      "[2020-10-29 06:03:04,944] \n",
      "14/1000 * Epoch 14 (train): loss_autoencoder=0.9660 | loss_discriminator=0.6932\n",
      "15/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.80it/s, loss_autoencoder=0.968, loss_discriminator=0.694]\n",
      "[2020-10-29 06:03:11,635] \n",
      "15/1000 * Epoch 15 (train): loss_autoencoder=0.9702 | loss_discriminator=0.6938\n",
      "16/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.94it/s, loss_autoencoder=0.963, loss_discriminator=0.694]\n",
      "[2020-10-29 06:03:18,253] \n",
      "16/1000 * Epoch 16 (train): loss_autoencoder=0.9637 | loss_discriminator=0.6937\n",
      "17/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.88it/s, loss_autoencoder=0.961, loss_discriminator=0.694]\n",
      "[2020-10-29 06:03:24,922] \n",
      "17/1000 * Epoch 17 (train): loss_autoencoder=0.9608 | loss_discriminator=0.6936\n",
      "18/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.46it/s, loss_autoencoder=0.959, loss_discriminator=0.693]\n",
      "[2020-10-29 06:03:31,924] \n",
      "18/1000 * Epoch 18 (train): loss_autoencoder=0.9594 | loss_discriminator=0.6935\n",
      "19/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.73it/s, loss_autoencoder=0.956, loss_discriminator=0.693]\n",
      "[2020-10-29 06:03:38,697] \n",
      "19/1000 * Epoch 19 (train): loss_autoencoder=0.9589 | loss_discriminator=0.6934\n",
      "20/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.93it/s, loss_autoencoder=0.959, loss_discriminator=0.693]\n",
      "[2020-10-29 06:03:45,322] \n",
      "20/1000 * Epoch 20 (train): loss_autoencoder=0.9578 | loss_discriminator=0.6933\n",
      "21/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.77it/s, loss_autoencoder=0.952, loss_discriminator=0.693]\n",
      "[2020-10-29 06:03:52,070] \n",
      "21/1000 * Epoch 21 (train): loss_autoencoder=0.9559 | loss_discriminator=0.6933\n",
      "22/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.41it/s, loss_autoencoder=0.953, loss_discriminator=0.693]\n",
      "[2020-10-29 06:03:59,102] \n",
      "22/1000 * Epoch 22 (train): loss_autoencoder=0.9523 | loss_discriminator=0.6933\n",
      "23/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  9.08it/s, loss_autoencoder=0.943, loss_discriminator=0.693]\n",
      "[2020-10-29 06:04:05,624] \n",
      "23/1000 * Epoch 23 (train): loss_autoencoder=0.9470 | loss_discriminator=0.6932\n",
      "24/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.81it/s, loss_autoencoder=0.941, loss_discriminator=0.693]\n",
      "[2020-10-29 06:04:12,335] \n",
      "24/1000 * Epoch 24 (train): loss_autoencoder=0.9420 | loss_discriminator=0.6932\n",
      "25/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.73it/s, loss_autoencoder=0.934, loss_discriminator=0.693]\n",
      "[2020-10-29 06:04:19,137] \n",
      "25/1000 * Epoch 25 (train): loss_autoencoder=0.9373 | loss_discriminator=0.6932\n",
      "26/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.92it/s, loss_autoencoder=0.936, loss_discriminator=0.693]\n",
      "[2020-10-29 06:04:25,738] \n",
      "26/1000 * Epoch 26 (train): loss_autoencoder=0.9332 | loss_discriminator=0.6932\n",
      "27/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.40it/s, loss_autoencoder=0.926, loss_discriminator=0.693]\n",
      "[2020-10-29 06:04:32,751] \n",
      "27/1000 * Epoch 27 (train): loss_autoencoder=0.9296 | loss_discriminator=0.6932\n",
      "28/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.47it/s, loss_autoencoder=0.926, loss_discriminator=0.693]\n",
      "[2020-10-29 06:04:39,712] \n",
      "28/1000 * Epoch 28 (train): loss_autoencoder=0.9269 | loss_discriminator=0.6932\n",
      "29/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.63it/s, loss_autoencoder=0.920, loss_discriminator=0.693]\n",
      "[2020-10-29 06:04:46,532] \n",
      "29/1000 * Epoch 29 (train): loss_autoencoder=0.9240 | loss_discriminator=0.6932\n",
      "30/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.71it/s, loss_autoencoder=0.921, loss_discriminator=0.693]\n",
      "[2020-10-29 06:04:53,333] \n",
      "30/1000 * Epoch 30 (train): loss_autoencoder=0.9218 | loss_discriminator=0.6932\n",
      "31/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.61it/s, loss_autoencoder=0.913, loss_discriminator=0.693]\n",
      "[2020-10-29 06:05:00,196] \n",
      "31/1000 * Epoch 31 (train): loss_autoencoder=0.9176 | loss_discriminator=0.6932\n",
      "32/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.75it/s, loss_autoencoder=0.911, loss_discriminator=0.693]\n",
      "[2020-10-29 06:05:06,953] \n",
      "32/1000 * Epoch 32 (train): loss_autoencoder=0.9129 | loss_discriminator=0.6932\n",
      "33/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.64it/s, loss_autoencoder=0.904, loss_discriminator=0.693]\n",
      "[2020-10-29 06:05:13,776] \n",
      "33/1000 * Epoch 33 (train): loss_autoencoder=0.9088 | loss_discriminator=0.6932\n",
      "34/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.79it/s, loss_autoencoder=0.904, loss_discriminator=0.693]\n",
      "[2020-10-29 06:05:20,489] \n",
      "34/1000 * Epoch 34 (train): loss_autoencoder=0.9054 | loss_discriminator=0.6932\n",
      "35/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.89it/s, loss_autoencoder=0.902, loss_discriminator=0.693]\n",
      "[2020-10-29 06:05:27,152] \n",
      "35/1000 * Epoch 35 (train): loss_autoencoder=0.9027 | loss_discriminator=0.6932\n",
      "36/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.81it/s, loss_autoencoder=0.902, loss_discriminator=0.693]\n",
      "[2020-10-29 06:05:33,853] \n",
      "36/1000 * Epoch 36 (train): loss_autoencoder=0.9004 | loss_discriminator=0.6932\n",
      "37/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.81it/s, loss_autoencoder=0.898, loss_discriminator=0.693]\n",
      "[2020-10-29 06:05:40,535] \n",
      "37/1000 * Epoch 37 (train): loss_autoencoder=0.8984 | loss_discriminator=0.6931\n",
      "38/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.79it/s, loss_autoencoder=0.892, loss_discriminator=0.693]\n",
      "[2020-10-29 06:05:47,263] \n",
      "38/1000 * Epoch 38 (train): loss_autoencoder=0.8965 | loss_discriminator=0.6932\n",
      "39/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.76it/s, loss_autoencoder=0.892, loss_discriminator=0.693]\n",
      "[2020-10-29 06:05:54,017] \n",
      "39/1000 * Epoch 39 (train): loss_autoencoder=0.8946 | loss_discriminator=0.6931\n",
      "40/1000 * Epoch (train): 100% 58/58 [00:07<00:00,  8.14it/s, loss_autoencoder=0.892, loss_discriminator=0.693]\n",
      "[2020-10-29 06:06:01,244] \n",
      "40/1000 * Epoch 40 (train): loss_autoencoder=0.8930 | loss_discriminator=0.6931\n",
      "41/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.65it/s, loss_autoencoder=0.891, loss_discriminator=0.693]\n",
      "[2020-10-29 06:06:08,099] \n",
      "41/1000 * Epoch 41 (train): loss_autoencoder=0.8912 | loss_discriminator=0.6931\n",
      "42/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.73it/s, loss_autoencoder=0.886, loss_discriminator=0.693]\n",
      "[2020-10-29 06:06:14,866] \n",
      "42/1000 * Epoch 42 (train): loss_autoencoder=0.8895 | loss_discriminator=0.6931\n",
      "43/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.77it/s, loss_autoencoder=0.889, loss_discriminator=0.693]\n",
      "[2020-10-29 06:06:21,576] \n",
      "43/1000 * Epoch 43 (train): loss_autoencoder=0.8882 | loss_discriminator=0.6931\n",
      "44/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.64it/s, loss_autoencoder=0.884, loss_discriminator=0.693]\n",
      "[2020-10-29 06:06:28,385] \n",
      "44/1000 * Epoch 44 (train): loss_autoencoder=0.8869 | loss_discriminator=0.6931\n",
      "45/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.59it/s, loss_autoencoder=0.884, loss_discriminator=0.693]\n",
      "[2020-10-29 06:06:35,266] \n",
      "45/1000 * Epoch 45 (train): loss_autoencoder=0.8858 | loss_discriminator=0.6931\n",
      "46/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.84it/s, loss_autoencoder=0.882, loss_discriminator=0.693]\n",
      "[2020-10-29 06:06:41,924] \n",
      "46/1000 * Epoch 46 (train): loss_autoencoder=0.8844 | loss_discriminator=0.6931\n",
      "47/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.79it/s, loss_autoencoder=0.881, loss_discriminator=0.693]\n",
      "[2020-10-29 06:06:48,640] \n",
      "47/1000 * Epoch 47 (train): loss_autoencoder=0.8834 | loss_discriminator=0.6931\n",
      "48/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.81it/s, loss_autoencoder=0.883, loss_discriminator=0.693]\n",
      "[2020-10-29 06:06:55,316] \n",
      "48/1000 * Epoch 48 (train): loss_autoencoder=0.8824 | loss_discriminator=0.6931\n",
      "49/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.75it/s, loss_autoencoder=0.886, loss_discriminator=0.693]\n",
      "[2020-10-29 06:07:02,046] \n",
      "49/1000 * Epoch 49 (train): loss_autoencoder=0.8814 | loss_discriminator=0.6931\n",
      "50/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.87it/s, loss_autoencoder=0.879, loss_discriminator=0.693]\n",
      "[2020-10-29 06:07:08,678] \n",
      "50/1000 * Epoch 50 (train): loss_autoencoder=0.8808 | loss_discriminator=0.6931\n",
      "51/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.91it/s, loss_autoencoder=0.876, loss_discriminator=0.693]\n",
      "[2020-10-29 06:07:15,321] \n",
      "51/1000 * Epoch 51 (train): loss_autoencoder=0.8798 | loss_discriminator=0.6931\n",
      "52/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.70it/s, loss_autoencoder=0.882, loss_discriminator=0.693]\n",
      "[2020-10-29 06:07:22,119] \n",
      "52/1000 * Epoch 52 (train): loss_autoencoder=0.8791 | loss_discriminator=0.6931\n",
      "53/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.66it/s, loss_autoencoder=0.876, loss_discriminator=0.693]\n",
      "[2020-10-29 06:07:28,942] \n",
      "53/1000 * Epoch 53 (train): loss_autoencoder=0.8784 | loss_discriminator=0.6931\n",
      "54/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.75it/s, loss_autoencoder=0.876, loss_discriminator=0.693]\n",
      "[2020-10-29 06:07:35,683] \n",
      "54/1000 * Epoch 54 (train): loss_autoencoder=0.8776 | loss_discriminator=0.6931\n",
      "55/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.85it/s, loss_autoencoder=0.876, loss_discriminator=0.693]\n",
      "[2020-10-29 06:07:42,341] \n",
      "55/1000 * Epoch 55 (train): loss_autoencoder=0.8769 | loss_discriminator=0.6931\n",
      "56/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.55it/s, loss_autoencoder=0.874, loss_discriminator=0.693]\n",
      "[2020-10-29 06:07:49,230] \n",
      "56/1000 * Epoch 56 (train): loss_autoencoder=0.8762 | loss_discriminator=0.6931\n",
      "57/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.86it/s, loss_autoencoder=0.875, loss_discriminator=0.693]\n",
      "[2020-10-29 06:07:55,879] \n",
      "57/1000 * Epoch 57 (train): loss_autoencoder=0.8756 | loss_discriminator=0.6931\n",
      "58/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.81it/s, loss_autoencoder=0.877, loss_discriminator=0.693]\n",
      "[2020-10-29 06:08:02,607] \n",
      "58/1000 * Epoch 58 (train): loss_autoencoder=0.8750 | loss_discriminator=0.6931\n",
      "59/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.85it/s, loss_autoencoder=0.874, loss_discriminator=0.693]\n",
      "[2020-10-29 06:08:09,266] \n",
      "59/1000 * Epoch 59 (train): loss_autoencoder=0.8744 | loss_discriminator=0.6931\n",
      "60/1000 * Epoch (train): 100% 58/58 [00:07<00:00,  7.98it/s, loss_autoencoder=0.878, loss_discriminator=0.693]\n",
      "[2020-10-29 06:08:16,635] \n",
      "60/1000 * Epoch 60 (train): loss_autoencoder=0.8739 | loss_discriminator=0.6931\n",
      "61/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.75it/s, loss_autoencoder=0.875, loss_discriminator=0.693]\n",
      "[2020-10-29 06:08:23,385] \n",
      "61/1000 * Epoch 61 (train): loss_autoencoder=0.8733 | loss_discriminator=0.6931\n",
      "62/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.84it/s, loss_autoencoder=0.873, loss_discriminator=0.693]\n",
      "[2020-10-29 06:08:30,079] \n",
      "62/1000 * Epoch 62 (train): loss_autoencoder=0.8728 | loss_discriminator=0.6931\n",
      "63/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.83it/s, loss_autoencoder=0.872, loss_discriminator=0.693]\n",
      "[2020-10-29 06:08:36,776] \n",
      "63/1000 * Epoch 63 (train): loss_autoencoder=0.8722 | loss_discriminator=0.6931\n",
      "64/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.82it/s, loss_autoencoder=0.871, loss_discriminator=0.693]\n",
      "[2020-10-29 06:08:43,468] \n",
      "64/1000 * Epoch 64 (train): loss_autoencoder=0.8717 | loss_discriminator=0.6931\n",
      "65/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.77it/s, loss_autoencoder=0.871, loss_discriminator=0.693]\n",
      "[2020-10-29 06:08:50,183] \n",
      "65/1000 * Epoch 65 (train): loss_autoencoder=0.8712 | loss_discriminator=0.6931\n",
      "66/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.56it/s, loss_autoencoder=0.872, loss_discriminator=0.693]\n",
      "[2020-10-29 06:08:57,054] \n",
      "66/1000 * Epoch 66 (train): loss_autoencoder=0.8707 | loss_discriminator=0.6931\n",
      "67/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.92it/s, loss_autoencoder=0.869, loss_discriminator=0.693]\n",
      "[2020-10-29 06:09:03,687] \n",
      "67/1000 * Epoch 67 (train): loss_autoencoder=0.8702 | loss_discriminator=0.6931\n",
      "68/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.74it/s, loss_autoencoder=0.871, loss_discriminator=0.693]\n",
      "[2020-10-29 06:09:10,439] \n",
      "68/1000 * Epoch 68 (train): loss_autoencoder=0.8697 | loss_discriminator=0.6931\n",
      "69/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.82it/s, loss_autoencoder=0.871, loss_discriminator=0.693]\n",
      "[2020-10-29 06:09:17,102] \n",
      "69/1000 * Epoch 69 (train): loss_autoencoder=0.8693 | loss_discriminator=0.6931\n",
      "70/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.33it/s, loss_autoencoder=0.870, loss_discriminator=0.693]\n",
      "[2020-10-29 06:09:24,184] \n",
      "70/1000 * Epoch 70 (train): loss_autoencoder=0.8689 | loss_discriminator=0.6931\n",
      "71/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.82it/s, loss_autoencoder=0.868, loss_discriminator=0.693]\n",
      "[2020-10-29 06:09:30,856] \n",
      "71/1000 * Epoch 71 (train): loss_autoencoder=0.8685 | loss_discriminator=0.6931\n",
      "72/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.73it/s, loss_autoencoder=0.871, loss_discriminator=0.693]\n",
      "[2020-10-29 06:09:37,604] \n",
      "72/1000 * Epoch 72 (train): loss_autoencoder=0.8680 | loss_discriminator=0.6931\n",
      "73/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.70it/s, loss_autoencoder=0.871, loss_discriminator=0.693]\n",
      "[2020-10-29 06:09:44,351] \n",
      "73/1000 * Epoch 73 (train): loss_autoencoder=0.8677 | loss_discriminator=0.6931\n",
      "74/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.92it/s, loss_autoencoder=0.871, loss_discriminator=0.693]\n",
      "[2020-10-29 06:09:50,974] \n",
      "74/1000 * Epoch 74 (train): loss_autoencoder=0.8674 | loss_discriminator=0.6931\n",
      "75/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.77it/s, loss_autoencoder=0.864, loss_discriminator=0.693]\n",
      "[2020-10-29 06:09:57,689] \n",
      "75/1000 * Epoch 75 (train): loss_autoencoder=0.8670 | loss_discriminator=0.6931\n",
      "76/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.77it/s, loss_autoencoder=0.867, loss_discriminator=0.693]\n",
      "[2020-10-29 06:10:04,425] \n",
      "76/1000 * Epoch 76 (train): loss_autoencoder=0.8666 | loss_discriminator=0.6931\n",
      "77/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.84it/s, loss_autoencoder=0.869, loss_discriminator=0.693]\n",
      "[2020-10-29 06:10:11,112] \n",
      "77/1000 * Epoch 77 (train): loss_autoencoder=0.8663 | loss_discriminator=0.6931\n",
      "78/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.85it/s, loss_autoencoder=0.867, loss_discriminator=0.693]\n",
      "[2020-10-29 06:10:17,767] \n",
      "78/1000 * Epoch 78 (train): loss_autoencoder=0.8660 | loss_discriminator=0.6931\n",
      "79/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.73it/s, loss_autoencoder=0.863, loss_discriminator=0.693]\n",
      "[2020-10-29 06:10:24,501] \n",
      "79/1000 * Epoch 79 (train): loss_autoencoder=0.8657 | loss_discriminator=0.6931\n",
      "80/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.83it/s, loss_autoencoder=0.866, loss_discriminator=0.693]\n",
      "[2020-10-29 06:10:31,158] \n",
      "80/1000 * Epoch 80 (train): loss_autoencoder=0.8654 | loss_discriminator=0.6931\n",
      "81/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.71it/s, loss_autoencoder=0.861, loss_discriminator=0.693]\n",
      "[2020-10-29 06:10:37,908] \n",
      "81/1000 * Epoch 81 (train): loss_autoencoder=0.8651 | loss_discriminator=0.6931\n",
      "82/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.55it/s, loss_autoencoder=0.866, loss_discriminator=0.693]\n",
      "[2020-10-29 06:10:44,794] \n",
      "82/1000 * Epoch 82 (train): loss_autoencoder=0.8647 | loss_discriminator=0.6931\n",
      "83/1000 * Epoch (train): 100% 58/58 [00:07<00:00,  8.24it/s, loss_autoencoder=0.867, loss_discriminator=0.693]\n",
      "[2020-10-29 06:10:51,929] \n",
      "83/1000 * Epoch 83 (train): loss_autoencoder=0.8646 | loss_discriminator=0.6931\n",
      "84/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.81it/s, loss_autoencoder=0.862, loss_discriminator=0.693]\n",
      "[2020-10-29 06:10:58,615] \n",
      "84/1000 * Epoch 84 (train): loss_autoencoder=0.8643 | loss_discriminator=0.6931\n",
      "85/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.79it/s, loss_autoencoder=0.860, loss_discriminator=0.693]\n",
      "[2020-10-29 06:11:05,334] \n",
      "85/1000 * Epoch 85 (train): loss_autoencoder=0.8641 | loss_discriminator=0.6931\n",
      "86/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.70it/s, loss_autoencoder=0.866, loss_discriminator=0.693]\n",
      "[2020-10-29 06:11:12,090] \n",
      "86/1000 * Epoch 86 (train): loss_autoencoder=0.8638 | loss_discriminator=0.6931\n",
      "87/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.89it/s, loss_autoencoder=0.861, loss_discriminator=0.693]\n",
      "[2020-10-29 06:11:18,744] \n",
      "87/1000 * Epoch 87 (train): loss_autoencoder=0.8636 | loss_discriminator=0.6931\n",
      "88/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.82it/s, loss_autoencoder=0.863, loss_discriminator=0.693]\n",
      "[2020-10-29 06:11:25,411] \n",
      "88/1000 * Epoch 88 (train): loss_autoencoder=0.8632 | loss_discriminator=0.6931\n",
      "89/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.86it/s, loss_autoencoder=0.862, loss_discriminator=0.693]\n",
      "[2020-10-29 06:11:32,075] \n",
      "89/1000 * Epoch 89 (train): loss_autoencoder=0.8631 | loss_discriminator=0.6931\n",
      "90/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.84it/s, loss_autoencoder=0.861, loss_discriminator=0.693]\n",
      "[2020-10-29 06:11:38,758] \n",
      "90/1000 * Epoch 90 (train): loss_autoencoder=0.8628 | loss_discriminator=0.6931\n",
      "91/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.63it/s, loss_autoencoder=0.861, loss_discriminator=0.693]\n",
      "[2020-10-29 06:11:45,573] \n",
      "91/1000 * Epoch 91 (train): loss_autoencoder=0.8627 | loss_discriminator=0.6931\n",
      "92/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.77it/s, loss_autoencoder=0.863, loss_discriminator=0.693]\n",
      "[2020-10-29 06:11:52,334] \n",
      "92/1000 * Epoch 92 (train): loss_autoencoder=0.8624 | loss_discriminator=0.6931\n",
      "93/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.79it/s, loss_autoencoder=0.862, loss_discriminator=0.693]\n",
      "[2020-10-29 06:11:59,030] \n",
      "93/1000 * Epoch 93 (train): loss_autoencoder=0.8622 | loss_discriminator=0.6931\n",
      "94/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.80it/s, loss_autoencoder=0.862, loss_discriminator=0.693]\n",
      "[2020-10-29 06:12:05,716] \n",
      "94/1000 * Epoch 94 (train): loss_autoencoder=0.8620 | loss_discriminator=0.6931\n",
      "95/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.69it/s, loss_autoencoder=0.860, loss_discriminator=0.693]\n",
      "[2020-10-29 06:12:12,501] \n",
      "95/1000 * Epoch 95 (train): loss_autoencoder=0.8618 | loss_discriminator=0.6931\n",
      "96/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.64it/s, loss_autoencoder=0.862, loss_discriminator=0.693]\n",
      "[2020-10-29 06:12:19,358] \n",
      "96/1000 * Epoch 96 (train): loss_autoencoder=0.8617 | loss_discriminator=0.6931\n",
      "97/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.48it/s, loss_autoencoder=0.859, loss_discriminator=0.693]\n",
      "[2020-10-29 06:12:26,290] \n",
      "97/1000 * Epoch 97 (train): loss_autoencoder=0.8614 | loss_discriminator=0.6931\n",
      "98/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.70it/s, loss_autoencoder=0.860, loss_discriminator=0.693]\n",
      "[2020-10-29 06:12:33,085] \n",
      "98/1000 * Epoch 98 (train): loss_autoencoder=0.8612 | loss_discriminator=0.6931\n",
      "99/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.89it/s, loss_autoencoder=0.859, loss_discriminator=0.693]\n",
      "[2020-10-29 06:12:39,723] \n",
      "99/1000 * Epoch 99 (train): loss_autoencoder=0.8610 | loss_discriminator=0.6931\n",
      "100/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.54it/s, loss_autoencoder=0.861, loss_discriminator=0.693]\n",
      "[2020-10-29 06:12:46,640] \n",
      "100/1000 * Epoch 100 (train): loss_autoencoder=0.8608 | loss_discriminator=0.6931\n",
      "101/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.80it/s, loss_autoencoder=0.858, loss_discriminator=0.693]\n",
      "[2020-10-29 06:12:53,349] \n",
      "101/1000 * Epoch 101 (train): loss_autoencoder=0.8606 | loss_discriminator=0.6931\n",
      "102/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.55it/s, loss_autoencoder=0.862, loss_discriminator=0.693]\n",
      "[2020-10-29 06:13:00,265] \n",
      "102/1000 * Epoch 102 (train): loss_autoencoder=0.8605 | loss_discriminator=0.6931\n",
      "103/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.83it/s, loss_autoencoder=0.859, loss_discriminator=0.693]\n",
      "[2020-10-29 06:13:06,972] \n",
      "103/1000 * Epoch 103 (train): loss_autoencoder=0.8605 | loss_discriminator=0.6931\n",
      "104/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.91it/s, loss_autoencoder=0.861, loss_discriminator=0.693]\n",
      "[2020-10-29 06:13:13,603] \n",
      "104/1000 * Epoch 104 (train): loss_autoencoder=0.8602 | loss_discriminator=0.6931\n",
      "105/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.86it/s, loss_autoencoder=0.863, loss_discriminator=0.693]\n",
      "[2020-10-29 06:13:20,254] \n",
      "105/1000 * Epoch 105 (train): loss_autoencoder=0.8600 | loss_discriminator=0.6931\n",
      "106/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.85it/s, loss_autoencoder=0.858, loss_discriminator=0.693]\n",
      "[2020-10-29 06:13:26,917] \n",
      "106/1000 * Epoch 106 (train): loss_autoencoder=0.8598 | loss_discriminator=0.6931\n",
      "107/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  9.02it/s, loss_autoencoder=0.858, loss_discriminator=0.693]\n",
      "[2020-10-29 06:13:33,470] \n",
      "107/1000 * Epoch 107 (train): loss_autoencoder=0.8597 | loss_discriminator=0.6931\n",
      "108/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.87it/s, loss_autoencoder=0.860, loss_discriminator=0.693]\n",
      "[2020-10-29 06:13:40,139] \n",
      "108/1000 * Epoch 108 (train): loss_autoencoder=0.8596 | loss_discriminator=0.6931\n",
      "109/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.74it/s, loss_autoencoder=0.858, loss_discriminator=0.693]\n",
      "[2020-10-29 06:13:46,901] \n",
      "109/1000 * Epoch 109 (train): loss_autoencoder=0.8595 | loss_discriminator=0.6931\n",
      "110/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.78it/s, loss_autoencoder=0.858, loss_discriminator=0.693]\n",
      "[2020-10-29 06:13:53,648] \n",
      "110/1000 * Epoch 110 (train): loss_autoencoder=0.8592 | loss_discriminator=0.6931\n",
      "111/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.79it/s, loss_autoencoder=0.858, loss_discriminator=0.693]\n",
      "[2020-10-29 06:14:00,368] \n",
      "111/1000 * Epoch 111 (train): loss_autoencoder=0.8591 | loss_discriminator=0.6931\n",
      "112/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.80it/s, loss_autoencoder=0.859, loss_discriminator=0.693]\n",
      "[2020-10-29 06:14:07,085] \n",
      "112/1000 * Epoch 112 (train): loss_autoencoder=0.8591 | loss_discriminator=0.6931\n",
      "113/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.88it/s, loss_autoencoder=0.855, loss_discriminator=0.693]\n",
      "[2020-10-29 06:14:13,750] \n",
      "113/1000 * Epoch 113 (train): loss_autoencoder=0.8588 | loss_discriminator=0.6931\n",
      "114/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.70it/s, loss_autoencoder=0.857, loss_discriminator=0.693]\n",
      "[2020-10-29 06:14:20,536] \n",
      "114/1000 * Epoch 114 (train): loss_autoencoder=0.8587 | loss_discriminator=0.6931\n",
      "115/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.72it/s, loss_autoencoder=0.860, loss_discriminator=0.693]\n",
      "[2020-10-29 06:14:27,320] \n",
      "115/1000 * Epoch 115 (train): loss_autoencoder=0.8585 | loss_discriminator=0.6931\n",
      "116/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.76it/s, loss_autoencoder=0.858, loss_discriminator=0.693]\n",
      "[2020-10-29 06:14:34,063] \n",
      "116/1000 * Epoch 116 (train): loss_autoencoder=0.8584 | loss_discriminator=0.6931\n",
      "117/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.93it/s, loss_autoencoder=0.859, loss_discriminator=0.693]\n",
      "[2020-10-29 06:14:40,649] \n",
      "117/1000 * Epoch 117 (train): loss_autoencoder=0.8584 | loss_discriminator=0.6931\n",
      "118/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.72it/s, loss_autoencoder=0.858, loss_discriminator=0.693]\n",
      "[2020-10-29 06:14:47,390] \n",
      "118/1000 * Epoch 118 (train): loss_autoencoder=0.8582 | loss_discriminator=0.6931\n",
      "119/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.98it/s, loss_autoencoder=0.858, loss_discriminator=0.693]\n",
      "[2020-10-29 06:14:53,960] \n",
      "119/1000 * Epoch 119 (train): loss_autoencoder=0.8580 | loss_discriminator=0.6931\n",
      "120/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.35it/s, loss_autoencoder=0.858, loss_discriminator=0.693]\n",
      "[2020-10-29 06:15:01,002] \n",
      "120/1000 * Epoch 120 (train): loss_autoencoder=0.8579 | loss_discriminator=0.6931\n",
      "121/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.81it/s, loss_autoencoder=0.858, loss_discriminator=0.693]\n",
      "[2020-10-29 06:15:07,689] \n",
      "121/1000 * Epoch 121 (train): loss_autoencoder=0.8578 | loss_discriminator=0.6931\n",
      "122/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.70it/s, loss_autoencoder=0.858, loss_discriminator=0.693]\n",
      "[2020-10-29 06:15:14,484] \n",
      "122/1000 * Epoch 122 (train): loss_autoencoder=0.8577 | loss_discriminator=0.6931\n",
      "123/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.79it/s, loss_autoencoder=0.858, loss_discriminator=0.693]\n",
      "[2020-10-29 06:15:21,197] \n",
      "123/1000 * Epoch 123 (train): loss_autoencoder=0.8577 | loss_discriminator=0.6931\n",
      "124/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.76it/s, loss_autoencoder=0.858, loss_discriminator=0.693]\n",
      "[2020-10-29 06:15:27,911] \n",
      "124/1000 * Epoch 124 (train): loss_autoencoder=0.8575 | loss_discriminator=0.6931\n",
      "125/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.77it/s, loss_autoencoder=0.860, loss_discriminator=0.693]\n",
      "[2020-10-29 06:15:34,609] \n",
      "125/1000 * Epoch 125 (train): loss_autoencoder=0.8574 | loss_discriminator=0.6931\n",
      "126/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.84it/s, loss_autoencoder=0.856, loss_discriminator=0.693]\n",
      "[2020-10-29 06:15:41,293] \n",
      "126/1000 * Epoch 126 (train): loss_autoencoder=0.8571 | loss_discriminator=0.6931\n",
      "127/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.88it/s, loss_autoencoder=0.858, loss_discriminator=0.693]\n",
      "[2020-10-29 06:15:47,963] \n",
      "127/1000 * Epoch 127 (train): loss_autoencoder=0.8572 | loss_discriminator=0.6931\n",
      "128/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.65it/s, loss_autoencoder=0.853, loss_discriminator=0.693]\n",
      "[2020-10-29 06:15:54,773] \n",
      "128/1000 * Epoch 128 (train): loss_autoencoder=0.8570 | loss_discriminator=0.6931\n",
      "129/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.77it/s, loss_autoencoder=0.856, loss_discriminator=0.693]\n",
      "[2020-10-29 06:16:01,500] \n",
      "129/1000 * Epoch 129 (train): loss_autoencoder=0.8568 | loss_discriminator=0.6931\n",
      "130/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.80it/s, loss_autoencoder=0.858, loss_discriminator=0.693]\n",
      "[2020-10-29 06:16:08,206] \n",
      "130/1000 * Epoch 130 (train): loss_autoencoder=0.8568 | loss_discriminator=0.6931\n",
      "131/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.70it/s, loss_autoencoder=0.852, loss_discriminator=0.693]\n",
      "[2020-10-29 06:16:14,997] \n",
      "131/1000 * Epoch 131 (train): loss_autoencoder=0.8567 | loss_discriminator=0.6931\n",
      "132/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.81it/s, loss_autoencoder=0.854, loss_discriminator=0.693]\n",
      "[2020-10-29 06:16:21,679] \n",
      "132/1000 * Epoch 132 (train): loss_autoencoder=0.8566 | loss_discriminator=0.6931\n",
      "133/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.74it/s, loss_autoencoder=0.859, loss_discriminator=0.693]\n",
      "[2020-10-29 06:16:28,436] \n",
      "133/1000 * Epoch 133 (train): loss_autoencoder=0.8565 | loss_discriminator=0.6931\n",
      "134/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.62it/s, loss_autoencoder=0.857, loss_discriminator=0.693]\n",
      "[2020-10-29 06:16:35,285] \n",
      "134/1000 * Epoch 134 (train): loss_autoencoder=0.8565 | loss_discriminator=0.6931\n",
      "135/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.70it/s, loss_autoencoder=0.857, loss_discriminator=0.693]\n",
      "[2020-10-29 06:16:42,046] \n",
      "135/1000 * Epoch 135 (train): loss_autoencoder=0.8562 | loss_discriminator=0.6931\n",
      "136/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.87it/s, loss_autoencoder=0.857, loss_discriminator=0.693]\n",
      "[2020-10-29 06:16:48,696] \n",
      "136/1000 * Epoch 136 (train): loss_autoencoder=0.8562 | loss_discriminator=0.6931\n",
      "137/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.76it/s, loss_autoencoder=0.855, loss_discriminator=0.693]\n",
      "[2020-10-29 06:16:55,426] \n",
      "137/1000 * Epoch 137 (train): loss_autoencoder=0.8561 | loss_discriminator=0.6931\n",
      "138/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.93it/s, loss_autoencoder=0.858, loss_discriminator=0.693]\n",
      "[2020-10-29 06:17:02,029] \n",
      "138/1000 * Epoch 138 (train): loss_autoencoder=0.8560 | loss_discriminator=0.6931\n",
      "139/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.79it/s, loss_autoencoder=0.856, loss_discriminator=0.693]\n",
      "[2020-10-29 06:17:08,736] \n",
      "139/1000 * Epoch 139 (train): loss_autoencoder=0.8558 | loss_discriminator=0.6931\n",
      "140/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.86it/s, loss_autoencoder=0.857, loss_discriminator=0.693]\n",
      "[2020-10-29 06:17:15,401] \n",
      "140/1000 * Epoch 140 (train): loss_autoencoder=0.8558 | loss_discriminator=0.6931\n",
      "141/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.98it/s, loss_autoencoder=0.857, loss_discriminator=0.693]\n",
      "[2020-10-29 06:17:21,919] \n",
      "141/1000 * Epoch 141 (train): loss_autoencoder=0.8557 | loss_discriminator=0.6931\n",
      "142/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  9.02it/s, loss_autoencoder=0.853, loss_discriminator=0.693]\n",
      "[2020-10-29 06:17:28,433] \n",
      "142/1000 * Epoch 142 (train): loss_autoencoder=0.8556 | loss_discriminator=0.6931\n",
      "143/1000 * Epoch (train): 100% 58/58 [00:07<00:00,  7.72it/s, loss_autoencoder=0.857, loss_discriminator=0.693]\n",
      "[2020-10-29 06:17:36,037] \n",
      "143/1000 * Epoch 143 (train): loss_autoencoder=0.8556 | loss_discriminator=0.6931\n",
      "144/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.36it/s, loss_autoencoder=0.857, loss_discriminator=0.693]\n",
      "[2020-10-29 06:17:43,115] \n",
      "144/1000 * Epoch 144 (train): loss_autoencoder=0.8554 | loss_discriminator=0.6931\n",
      "145/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.74it/s, loss_autoencoder=0.853, loss_discriminator=0.693]\n",
      "[2020-10-29 06:17:49,840] \n",
      "145/1000 * Epoch 145 (train): loss_autoencoder=0.8554 | loss_discriminator=0.6931\n",
      "146/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.81it/s, loss_autoencoder=0.854, loss_discriminator=0.693]\n",
      "[2020-10-29 06:17:56,519] \n",
      "146/1000 * Epoch 146 (train): loss_autoencoder=0.8552 | loss_discriminator=0.6931\n",
      "147/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.71it/s, loss_autoencoder=0.855, loss_discriminator=0.693]\n",
      "[2020-10-29 06:18:03,345] \n",
      "147/1000 * Epoch 147 (train): loss_autoencoder=0.8552 | loss_discriminator=0.6931\n",
      "148/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.71it/s, loss_autoencoder=0.854, loss_discriminator=0.693]\n",
      "[2020-10-29 06:18:10,106] \n",
      "148/1000 * Epoch 148 (train): loss_autoencoder=0.8550 | loss_discriminator=0.6931\n",
      "149/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.76it/s, loss_autoencoder=0.852, loss_discriminator=0.693]\n",
      "[2020-10-29 06:18:16,825] \n",
      "149/1000 * Epoch 149 (train): loss_autoencoder=0.8550 | loss_discriminator=0.6931\n",
      "150/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.69it/s, loss_autoencoder=0.855, loss_discriminator=0.693]\n",
      "[2020-10-29 06:18:23,631] \n",
      "150/1000 * Epoch 150 (train): loss_autoencoder=0.8551 | loss_discriminator=0.6931\n",
      "151/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.90it/s, loss_autoencoder=0.854, loss_discriminator=0.693]\n",
      "[2020-10-29 06:18:30,259] \n",
      "151/1000 * Epoch 151 (train): loss_autoencoder=0.8548 | loss_discriminator=0.6931\n",
      "152/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.60it/s, loss_autoencoder=0.857, loss_discriminator=0.693]\n",
      "[2020-10-29 06:18:37,093] \n",
      "152/1000 * Epoch 152 (train): loss_autoencoder=0.8547 | loss_discriminator=0.6931\n",
      "153/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.74it/s, loss_autoencoder=0.857, loss_discriminator=0.693]\n",
      "[2020-10-29 06:18:43,843] \n",
      "153/1000 * Epoch 153 (train): loss_autoencoder=0.8547 | loss_discriminator=0.6931\n",
      "154/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.70it/s, loss_autoencoder=0.857, loss_discriminator=0.693]\n",
      "[2020-10-29 06:18:50,624] \n",
      "154/1000 * Epoch 154 (train): loss_autoencoder=0.8546 | loss_discriminator=0.6931\n",
      "155/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.81it/s, loss_autoencoder=0.853, loss_discriminator=0.693]\n",
      "[2020-10-29 06:18:57,325] \n",
      "155/1000 * Epoch 155 (train): loss_autoencoder=0.8546 | loss_discriminator=0.6931\n",
      "156/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.77it/s, loss_autoencoder=0.855, loss_discriminator=0.693]\n",
      "[2020-10-29 06:19:04,053] \n",
      "156/1000 * Epoch 156 (train): loss_autoencoder=0.8543 | loss_discriminator=0.6931\n",
      "157/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.85it/s, loss_autoencoder=0.851, loss_discriminator=0.693]\n",
      "[2020-10-29 06:19:10,699] \n",
      "157/1000 * Epoch 157 (train): loss_autoencoder=0.8543 | loss_discriminator=0.6931\n",
      "158/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.92it/s, loss_autoencoder=0.854, loss_discriminator=0.693]\n",
      "[2020-10-29 06:19:17,300] \n",
      "158/1000 * Epoch 158 (train): loss_autoencoder=0.8543 | loss_discriminator=0.6931\n",
      "159/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.90it/s, loss_autoencoder=0.856, loss_discriminator=0.693]\n",
      "[2020-10-29 06:19:23,906] \n",
      "159/1000 * Epoch 159 (train): loss_autoencoder=0.8541 | loss_discriminator=0.6931\n",
      "160/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.87it/s, loss_autoencoder=0.853, loss_discriminator=0.693]\n",
      "[2020-10-29 06:19:30,551] \n",
      "160/1000 * Epoch 160 (train): loss_autoencoder=0.8541 | loss_discriminator=0.6931\n",
      "161/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.70it/s, loss_autoencoder=0.854, loss_discriminator=0.693]\n",
      "[2020-10-29 06:19:37,379] \n",
      "161/1000 * Epoch 161 (train): loss_autoencoder=0.8541 | loss_discriminator=0.6931\n",
      "162/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.92it/s, loss_autoencoder=0.851, loss_discriminator=0.693]\n",
      "[2020-10-29 06:19:43,963] \n",
      "162/1000 * Epoch 162 (train): loss_autoencoder=0.8540 | loss_discriminator=0.6931\n",
      "163/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.49it/s, loss_autoencoder=0.853, loss_discriminator=0.693]\n",
      "[2020-10-29 06:19:50,847] \n",
      "163/1000 * Epoch 163 (train): loss_autoencoder=0.8540 | loss_discriminator=0.6931\n",
      "164/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.85it/s, loss_autoencoder=0.856, loss_discriminator=0.693]\n",
      "[2020-10-29 06:19:57,539] \n",
      "164/1000 * Epoch 164 (train): loss_autoencoder=0.8539 | loss_discriminator=0.6931\n",
      "165/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.67it/s, loss_autoencoder=0.856, loss_discriminator=0.693]\n",
      "[2020-10-29 06:20:04,330] \n",
      "165/1000 * Epoch 165 (train): loss_autoencoder=0.8536 | loss_discriminator=0.6931\n",
      "166/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.74it/s, loss_autoencoder=1.130, loss_discriminator=0.691]\n",
      "[2020-10-29 06:20:11,060] \n",
      "166/1000 * Epoch 166 (train): loss_autoencoder=0.8853 | loss_discriminator=0.6932\n",
      "167/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.68it/s, loss_autoencoder=0.951, loss_discriminator=0.693]\n",
      "[2020-10-29 06:20:17,867] \n",
      "167/1000 * Epoch 167 (train): loss_autoencoder=0.9698 | loss_discriminator=0.6931\n",
      "168/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.86it/s, loss_autoencoder=0.941, loss_discriminator=0.693]\n",
      "[2020-10-29 06:20:24,525] \n",
      "168/1000 * Epoch 168 (train): loss_autoencoder=0.9474 | loss_discriminator=0.6932\n",
      "169/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.80it/s, loss_autoencoder=0.918, loss_discriminator=0.693]\n",
      "[2020-10-29 06:20:31,238] \n",
      "169/1000 * Epoch 169 (train): loss_autoencoder=0.9274 | loss_discriminator=0.6932\n",
      "170/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.84it/s, loss_autoencoder=0.902, loss_discriminator=0.693]\n",
      "[2020-10-29 06:20:37,883] \n",
      "170/1000 * Epoch 170 (train): loss_autoencoder=0.9085 | loss_discriminator=0.6931\n",
      "171/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.50it/s, loss_autoencoder=0.897, loss_discriminator=0.693]\n",
      "[2020-10-29 06:20:44,805] \n",
      "171/1000 * Epoch 171 (train): loss_autoencoder=0.8994 | loss_discriminator=0.6931\n",
      "172/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.85it/s, loss_autoencoder=0.890, loss_discriminator=0.693]\n",
      "[2020-10-29 06:20:51,443] \n",
      "172/1000 * Epoch 172 (train): loss_autoencoder=0.8937 | loss_discriminator=0.6931\n",
      "173/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.89it/s, loss_autoencoder=0.884, loss_discriminator=0.693]\n",
      "[2020-10-29 06:20:58,093] \n",
      "173/1000 * Epoch 173 (train): loss_autoencoder=0.8892 | loss_discriminator=0.6931\n",
      "174/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.79it/s, loss_autoencoder=0.886, loss_discriminator=0.693]\n",
      "[2020-10-29 06:21:04,791] \n",
      "174/1000 * Epoch 174 (train): loss_autoencoder=0.8854 | loss_discriminator=0.6931\n",
      "175/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.85it/s, loss_autoencoder=0.881, loss_discriminator=0.693]\n",
      "[2020-10-29 06:21:11,455] \n",
      "175/1000 * Epoch 175 (train): loss_autoencoder=0.8821 | loss_discriminator=0.6931\n",
      "176/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.76it/s, loss_autoencoder=0.879, loss_discriminator=0.693]\n",
      "[2020-10-29 06:21:18,172] \n",
      "176/1000 * Epoch 176 (train): loss_autoencoder=0.8792 | loss_discriminator=0.6931\n",
      "177/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.57it/s, loss_autoencoder=0.875, loss_discriminator=0.693]\n",
      "[2020-10-29 06:21:25,061] \n",
      "177/1000 * Epoch 177 (train): loss_autoencoder=0.8764 | loss_discriminator=0.6931\n",
      "178/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.83it/s, loss_autoencoder=0.872, loss_discriminator=0.693]\n",
      "[2020-10-29 06:21:31,753] \n",
      "178/1000 * Epoch 178 (train): loss_autoencoder=0.8741 | loss_discriminator=0.6931\n",
      "179/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.84it/s, loss_autoencoder=0.870, loss_discriminator=0.693]\n",
      "[2020-10-29 06:21:38,424] \n",
      "179/1000 * Epoch 179 (train): loss_autoencoder=0.8721 | loss_discriminator=0.6931\n",
      "180/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.49it/s, loss_autoencoder=0.869, loss_discriminator=0.693]\n",
      "[2020-10-29 06:21:45,359] \n",
      "180/1000 * Epoch 180 (train): loss_autoencoder=0.8703 | loss_discriminator=0.6931\n",
      "181/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.58it/s, loss_autoencoder=0.870, loss_discriminator=0.693]\n",
      "[2020-10-29 06:21:52,218] \n",
      "181/1000 * Epoch 181 (train): loss_autoencoder=0.8689 | loss_discriminator=0.6931\n",
      "182/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.78it/s, loss_autoencoder=0.866, loss_discriminator=0.693]\n",
      "[2020-10-29 06:21:58,868] \n",
      "182/1000 * Epoch 182 (train): loss_autoencoder=0.8677 | loss_discriminator=0.6931\n",
      "183/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.81it/s, loss_autoencoder=0.867, loss_discriminator=0.693]\n",
      "[2020-10-29 06:22:05,552] \n",
      "183/1000 * Epoch 183 (train): loss_autoencoder=0.8667 | loss_discriminator=0.6931\n",
      "184/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.81it/s, loss_autoencoder=0.865, loss_discriminator=0.693]\n",
      "[2020-10-29 06:22:12,228] \n",
      "184/1000 * Epoch 184 (train): loss_autoencoder=0.8657 | loss_discriminator=0.6931\n",
      "185/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.90it/s, loss_autoencoder=0.861, loss_discriminator=0.693]\n",
      "[2020-10-29 06:22:18,858] \n",
      "185/1000 * Epoch 185 (train): loss_autoencoder=0.8648 | loss_discriminator=0.6931\n",
      "186/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.85it/s, loss_autoencoder=0.863, loss_discriminator=0.693]\n",
      "[2020-10-29 06:22:25,529] \n",
      "186/1000 * Epoch 186 (train): loss_autoencoder=0.8640 | loss_discriminator=0.6931\n",
      "187/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.65it/s, loss_autoencoder=0.863, loss_discriminator=0.693]\n",
      "[2020-10-29 06:22:32,317] \n",
      "187/1000 * Epoch 187 (train): loss_autoencoder=0.8633 | loss_discriminator=0.6931\n",
      "188/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.83it/s, loss_autoencoder=0.860, loss_discriminator=0.693]\n",
      "[2020-10-29 06:22:39,009] \n",
      "188/1000 * Epoch 188 (train): loss_autoencoder=0.8627 | loss_discriminator=0.6931\n",
      "189/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.67it/s, loss_autoencoder=0.863, loss_discriminator=0.693]\n",
      "[2020-10-29 06:22:45,789] \n",
      "189/1000 * Epoch 189 (train): loss_autoencoder=0.8620 | loss_discriminator=0.6931\n",
      "190/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.84it/s, loss_autoencoder=0.862, loss_discriminator=0.693]\n",
      "[2020-10-29 06:22:52,444] \n",
      "190/1000 * Epoch 190 (train): loss_autoencoder=0.8616 | loss_discriminator=0.6931\n",
      "191/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.67it/s, loss_autoencoder=0.860, loss_discriminator=0.693]\n",
      "[2020-10-29 06:22:59,249] \n",
      "191/1000 * Epoch 191 (train): loss_autoencoder=0.8609 | loss_discriminator=0.6931\n",
      "192/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.49it/s, loss_autoencoder=0.861, loss_discriminator=0.693]\n",
      "[2020-10-29 06:23:06,190] \n",
      "192/1000 * Epoch 192 (train): loss_autoencoder=0.8605 | loss_discriminator=0.6931\n",
      "193/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.77it/s, loss_autoencoder=0.860, loss_discriminator=0.693]\n",
      "[2020-10-29 06:23:12,924] \n",
      "193/1000 * Epoch 193 (train): loss_autoencoder=0.8600 | loss_discriminator=0.6931\n",
      "194/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.66it/s, loss_autoencoder=0.861, loss_discriminator=0.693]\n",
      "[2020-10-29 06:23:19,745] \n",
      "194/1000 * Epoch 194 (train): loss_autoencoder=0.8594 | loss_discriminator=0.6931\n",
      "195/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.78it/s, loss_autoencoder=0.862, loss_discriminator=0.693]\n",
      "[2020-10-29 06:23:26,485] \n",
      "195/1000 * Epoch 195 (train): loss_autoencoder=0.8591 | loss_discriminator=0.6931\n",
      "196/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.79it/s, loss_autoencoder=0.856, loss_discriminator=0.693]\n",
      "[2020-10-29 06:23:33,176] \n",
      "196/1000 * Epoch 196 (train): loss_autoencoder=0.8587 | loss_discriminator=0.6931\n",
      "197/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.74it/s, loss_autoencoder=0.860, loss_discriminator=0.693]\n",
      "[2020-10-29 06:23:39,907] \n",
      "197/1000 * Epoch 197 (train): loss_autoencoder=0.8583 | loss_discriminator=0.6931\n",
      "198/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.64it/s, loss_autoencoder=0.860, loss_discriminator=0.693]\n",
      "[2020-10-29 06:23:46,714] \n",
      "198/1000 * Epoch 198 (train): loss_autoencoder=0.8580 | loss_discriminator=0.6931\n",
      "199/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.79it/s, loss_autoencoder=0.856, loss_discriminator=0.693]\n",
      "[2020-10-29 06:23:53,432] \n",
      "199/1000 * Epoch 199 (train): loss_autoencoder=0.8576 | loss_discriminator=0.6931\n",
      "200/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.80it/s, loss_autoencoder=0.860, loss_discriminator=0.693]\n",
      "[2020-10-29 06:24:00,120] \n",
      "200/1000 * Epoch 200 (train): loss_autoencoder=0.8573 | loss_discriminator=0.6931\n",
      "201/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.82it/s, loss_autoencoder=0.857, loss_discriminator=0.693]\n",
      "[2020-10-29 06:24:06,789] \n",
      "201/1000 * Epoch 201 (train): loss_autoencoder=0.8571 | loss_discriminator=0.6931\n",
      "202/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.78it/s, loss_autoencoder=0.858, loss_discriminator=0.693]\n",
      "[2020-10-29 06:24:13,525] \n",
      "202/1000 * Epoch 202 (train): loss_autoencoder=0.8568 | loss_discriminator=0.6931\n",
      "203/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.77it/s, loss_autoencoder=0.857, loss_discriminator=0.693]\n",
      "[2020-10-29 06:24:20,235] \n",
      "203/1000 * Epoch 203 (train): loss_autoencoder=0.8565 | loss_discriminator=0.6931\n",
      "204/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.78it/s, loss_autoencoder=0.855, loss_discriminator=0.693]\n",
      "[2020-10-29 06:24:26,931] \n",
      "204/1000 * Epoch 204 (train): loss_autoencoder=0.8564 | loss_discriminator=0.6931\n",
      "205/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.49it/s, loss_autoencoder=0.854, loss_discriminator=0.693]\n",
      "[2020-10-29 06:24:33,864] \n",
      "205/1000 * Epoch 205 (train): loss_autoencoder=0.8561 | loss_discriminator=0.6931\n",
      "206/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.81it/s, loss_autoencoder=0.855, loss_discriminator=0.693]\n",
      "[2020-10-29 06:24:40,564] \n",
      "206/1000 * Epoch 206 (train): loss_autoencoder=0.8560 | loss_discriminator=0.6931\n",
      "207/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.85it/s, loss_autoencoder=0.855, loss_discriminator=0.693]\n",
      "[2020-10-29 06:24:47,222] \n",
      "207/1000 * Epoch 207 (train): loss_autoencoder=0.8558 | loss_discriminator=0.6931\n",
      "208/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.81it/s, loss_autoencoder=0.851, loss_discriminator=0.693]\n",
      "[2020-10-29 06:24:53,925] \n",
      "208/1000 * Epoch 208 (train): loss_autoencoder=0.8556 | loss_discriminator=0.6931\n",
      "209/1000 * Epoch (train): 100% 58/58 [00:07<00:00,  8.25it/s, loss_autoencoder=0.860, loss_discriminator=0.693]\n",
      "[2020-10-29 06:25:01,051] \n",
      "209/1000 * Epoch 209 (train): loss_autoencoder=0.8554 | loss_discriminator=0.6931\n",
      "210/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.41it/s, loss_autoencoder=0.854, loss_discriminator=0.693]\n",
      "[2020-10-29 06:25:08,077] \n",
      "210/1000 * Epoch 210 (train): loss_autoencoder=0.8552 | loss_discriminator=0.6931\n",
      "211/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.67it/s, loss_autoencoder=0.856, loss_discriminator=0.693]\n",
      "[2020-10-29 06:25:14,883] \n",
      "211/1000 * Epoch 211 (train): loss_autoencoder=0.8551 | loss_discriminator=0.6931\n",
      "212/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.79it/s, loss_autoencoder=0.854, loss_discriminator=0.693]\n",
      "[2020-10-29 06:25:21,580] \n",
      "212/1000 * Epoch 212 (train): loss_autoencoder=0.8549 | loss_discriminator=0.6931\n",
      "213/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.87it/s, loss_autoencoder=0.852, loss_discriminator=0.693]\n",
      "[2020-10-29 06:25:28,218] \n",
      "213/1000 * Epoch 213 (train): loss_autoencoder=0.8547 | loss_discriminator=0.6931\n",
      "214/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.84it/s, loss_autoencoder=0.852, loss_discriminator=0.693]\n",
      "[2020-10-29 06:25:34,895] \n",
      "214/1000 * Epoch 214 (train): loss_autoencoder=0.8546 | loss_discriminator=0.6931\n",
      "215/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.76it/s, loss_autoencoder=0.854, loss_discriminator=0.693]\n",
      "[2020-10-29 06:25:41,603] \n",
      "215/1000 * Epoch 215 (train): loss_autoencoder=0.8545 | loss_discriminator=0.6931\n",
      "216/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.74it/s, loss_autoencoder=0.854, loss_discriminator=0.693]\n",
      "[2020-10-29 06:25:48,356] \n",
      "216/1000 * Epoch 216 (train): loss_autoencoder=0.8544 | loss_discriminator=0.6931\n",
      "217/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.79it/s, loss_autoencoder=0.855, loss_discriminator=0.693]\n",
      "[2020-10-29 06:25:55,056] \n",
      "217/1000 * Epoch 217 (train): loss_autoencoder=0.8542 | loss_discriminator=0.6931\n",
      "218/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.72it/s, loss_autoencoder=0.856, loss_discriminator=0.693]\n",
      "[2020-10-29 06:26:01,825] \n",
      "218/1000 * Epoch 218 (train): loss_autoencoder=0.8541 | loss_discriminator=0.6931\n",
      "219/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.38it/s, loss_autoencoder=0.853, loss_discriminator=0.693]\n",
      "[2020-10-29 06:26:08,865] \n",
      "219/1000 * Epoch 219 (train): loss_autoencoder=0.8539 | loss_discriminator=0.6931\n",
      "220/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.73it/s, loss_autoencoder=0.850, loss_discriminator=0.693]\n",
      "[2020-10-29 06:26:15,582] \n",
      "220/1000 * Epoch 220 (train): loss_autoencoder=0.8538 | loss_discriminator=0.6931\n",
      "221/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.93it/s, loss_autoencoder=0.852, loss_discriminator=0.693]\n",
      "[2020-10-29 06:26:22,187] \n",
      "221/1000 * Epoch 221 (train): loss_autoencoder=0.8536 | loss_discriminator=0.6931\n",
      "222/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.86it/s, loss_autoencoder=0.855, loss_discriminator=0.693]\n",
      "[2020-10-29 06:26:28,856] \n",
      "222/1000 * Epoch 222 (train): loss_autoencoder=0.8537 | loss_discriminator=0.6931\n",
      "223/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.59it/s, loss_autoencoder=0.855, loss_discriminator=0.693]\n",
      "[2020-10-29 06:26:35,666] \n",
      "223/1000 * Epoch 223 (train): loss_autoencoder=0.8536 | loss_discriminator=0.6931\n",
      "224/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.68it/s, loss_autoencoder=0.853, loss_discriminator=0.693]\n",
      "[2020-10-29 06:26:42,456] \n",
      "224/1000 * Epoch 224 (train): loss_autoencoder=0.8534 | loss_discriminator=0.6931\n",
      "225/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.57it/s, loss_autoencoder=0.855, loss_discriminator=0.693]\n",
      "[2020-10-29 06:26:49,349] \n",
      "225/1000 * Epoch 225 (train): loss_autoencoder=0.8534 | loss_discriminator=0.6931\n",
      "226/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.91it/s, loss_autoencoder=0.852, loss_discriminator=0.693]\n",
      "[2020-10-29 06:26:55,915] \n",
      "226/1000 * Epoch 226 (train): loss_autoencoder=0.8532 | loss_discriminator=0.6931\n",
      "227/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.76it/s, loss_autoencoder=0.853, loss_discriminator=0.693]\n",
      "[2020-10-29 06:27:02,631] \n",
      "227/1000 * Epoch 227 (train): loss_autoencoder=0.8530 | loss_discriminator=0.6931\n",
      "228/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.74it/s, loss_autoencoder=0.851, loss_discriminator=0.693]\n",
      "[2020-10-29 06:27:09,399] \n",
      "228/1000 * Epoch 228 (train): loss_autoencoder=0.8531 | loss_discriminator=0.6931\n",
      "229/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.86it/s, loss_autoencoder=0.852, loss_discriminator=0.693]\n",
      "[2020-10-29 06:27:16,059] \n",
      "229/1000 * Epoch 229 (train): loss_autoencoder=0.8529 | loss_discriminator=0.6931\n",
      "230/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.69it/s, loss_autoencoder=0.851, loss_discriminator=0.693]\n",
      "[2020-10-29 06:27:22,817] \n",
      "230/1000 * Epoch 230 (train): loss_autoencoder=0.8528 | loss_discriminator=0.6931\n",
      "231/1000 * Epoch (train): 100% 58/58 [00:07<00:00,  7.97it/s, loss_autoencoder=0.851, loss_discriminator=0.693]\n",
      "[2020-10-29 06:27:30,199] \n",
      "231/1000 * Epoch 231 (train): loss_autoencoder=0.8528 | loss_discriminator=0.6931\n",
      "232/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.80it/s, loss_autoencoder=0.853, loss_discriminator=0.693]\n",
      "[2020-10-29 06:27:36,906] \n",
      "232/1000 * Epoch 232 (train): loss_autoencoder=0.8527 | loss_discriminator=0.6931\n",
      "233/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.88it/s, loss_autoencoder=0.853, loss_discriminator=0.693]\n",
      "[2020-10-29 06:27:43,530] \n",
      "233/1000 * Epoch 233 (train): loss_autoencoder=0.8526 | loss_discriminator=0.6931\n",
      "234/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.72it/s, loss_autoencoder=0.855, loss_discriminator=0.693]\n",
      "[2020-10-29 06:27:50,290] \n",
      "234/1000 * Epoch 234 (train): loss_autoencoder=0.8525 | loss_discriminator=0.6931\n",
      "235/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.66it/s, loss_autoencoder=0.850, loss_discriminator=0.693]\n",
      "[2020-10-29 06:27:57,105] \n",
      "235/1000 * Epoch 235 (train): loss_autoencoder=0.8525 | loss_discriminator=0.6931\n",
      "236/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.29it/s, loss_autoencoder=0.851, loss_discriminator=0.693]\n",
      "[2020-10-29 06:28:04,212] \n",
      "236/1000 * Epoch 236 (train): loss_autoencoder=0.8524 | loss_discriminator=0.6931\n",
      "237/1000 * Epoch (train): 100% 58/58 [00:07<00:00,  8.22it/s, loss_autoencoder=0.850, loss_discriminator=0.693]\n",
      "[2020-10-29 06:28:11,372] \n",
      "237/1000 * Epoch 237 (train): loss_autoencoder=0.8523 | loss_discriminator=0.6931\n",
      "238/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.61it/s, loss_autoencoder=0.851, loss_discriminator=0.693]\n",
      "[2020-10-29 06:28:18,207] \n",
      "238/1000 * Epoch 238 (train): loss_autoencoder=0.8522 | loss_discriminator=0.6931\n",
      "239/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.52it/s, loss_autoencoder=0.854, loss_discriminator=0.693]\n",
      "[2020-10-29 06:28:25,137] \n",
      "239/1000 * Epoch 239 (train): loss_autoencoder=0.8521 | loss_discriminator=0.6931\n",
      "240/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.81it/s, loss_autoencoder=0.853, loss_discriminator=0.693]\n",
      "[2020-10-29 06:28:31,832] \n",
      "240/1000 * Epoch 240 (train): loss_autoencoder=0.8521 | loss_discriminator=0.6931\n",
      "241/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.78it/s, loss_autoencoder=0.853, loss_discriminator=0.693]\n",
      "[2020-10-29 06:28:38,539] \n",
      "241/1000 * Epoch 241 (train): loss_autoencoder=0.8521 | loss_discriminator=0.6931\n",
      "242/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.88it/s, loss_autoencoder=0.854, loss_discriminator=0.693]\n",
      "[2020-10-29 06:28:45,182] \n",
      "242/1000 * Epoch 242 (train): loss_autoencoder=0.8519 | loss_discriminator=0.6931\n",
      "243/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.71it/s, loss_autoencoder=0.855, loss_discriminator=0.693]\n",
      "[2020-10-29 06:28:51,958] \n",
      "243/1000 * Epoch 243 (train): loss_autoencoder=0.8519 | loss_discriminator=0.6931\n",
      "244/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.94it/s, loss_autoencoder=0.850, loss_discriminator=0.693]\n",
      "[2020-10-29 06:28:58,572] \n",
      "244/1000 * Epoch 244 (train): loss_autoencoder=0.8518 | loss_discriminator=0.6931\n",
      "245/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.68it/s, loss_autoencoder=0.851, loss_discriminator=0.693]\n",
      "[2020-10-29 06:29:05,345] \n",
      "245/1000 * Epoch 245 (train): loss_autoencoder=0.8518 | loss_discriminator=0.6931\n",
      "246/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.94it/s, loss_autoencoder=0.854, loss_discriminator=0.693]\n",
      "[2020-10-29 06:29:11,953] \n",
      "246/1000 * Epoch 246 (train): loss_autoencoder=0.8517 | loss_discriminator=0.6931\n",
      "247/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.88it/s, loss_autoencoder=0.854, loss_discriminator=0.693]\n",
      "[2020-10-29 06:29:18,604] \n",
      "247/1000 * Epoch 247 (train): loss_autoencoder=0.8517 | loss_discriminator=0.6931\n",
      "248/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.70it/s, loss_autoencoder=0.851, loss_discriminator=0.693]\n",
      "[2020-10-29 06:29:25,371] \n",
      "248/1000 * Epoch 248 (train): loss_autoencoder=0.8517 | loss_discriminator=0.6931\n",
      "249/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.61it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 06:29:32,219] \n",
      "249/1000 * Epoch 249 (train): loss_autoencoder=0.8516 | loss_discriminator=0.6931\n",
      "250/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.73it/s, loss_autoencoder=0.852, loss_discriminator=0.693]\n",
      "[2020-10-29 06:29:38,946] \n",
      "250/1000 * Epoch 250 (train): loss_autoencoder=0.8514 | loss_discriminator=0.6931\n",
      "251/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.72it/s, loss_autoencoder=0.851, loss_discriminator=0.693]\n",
      "[2020-10-29 06:29:45,715] \n",
      "251/1000 * Epoch 251 (train): loss_autoencoder=0.8514 | loss_discriminator=0.6931\n",
      "252/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.85it/s, loss_autoencoder=0.857, loss_discriminator=0.693]\n",
      "[2020-10-29 06:29:52,387] \n",
      "252/1000 * Epoch 252 (train): loss_autoencoder=0.8513 | loss_discriminator=0.6931\n",
      "253/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.70it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 06:29:59,189] \n",
      "253/1000 * Epoch 253 (train): loss_autoencoder=0.8513 | loss_discriminator=0.6931\n",
      "254/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.80it/s, loss_autoencoder=0.851, loss_discriminator=0.693]\n",
      "[2020-10-29 06:30:05,896] \n",
      "254/1000 * Epoch 254 (train): loss_autoencoder=0.8513 | loss_discriminator=0.6931\n",
      "255/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.71it/s, loss_autoencoder=0.854, loss_discriminator=0.693]\n",
      "[2020-10-29 06:30:12,659] \n",
      "255/1000 * Epoch 255 (train): loss_autoencoder=0.8513 | loss_discriminator=0.6931\n",
      "256/1000 * Epoch (train): 100% 58/58 [00:07<00:00,  8.01it/s, loss_autoencoder=0.851, loss_discriminator=0.693]\n",
      "[2020-10-29 06:30:20,018] \n",
      "256/1000 * Epoch 256 (train): loss_autoencoder=0.8512 | loss_discriminator=0.6931\n",
      "257/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.71it/s, loss_autoencoder=0.851, loss_discriminator=0.693]\n",
      "[2020-10-29 06:30:26,776] \n",
      "257/1000 * Epoch 257 (train): loss_autoencoder=0.8511 | loss_discriminator=0.6931\n",
      "258/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.77it/s, loss_autoencoder=0.850, loss_discriminator=0.693]\n",
      "[2020-10-29 06:30:33,505] \n",
      "258/1000 * Epoch 258 (train): loss_autoencoder=0.8511 | loss_discriminator=0.6931\n",
      "259/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.65it/s, loss_autoencoder=0.850, loss_discriminator=0.693]\n",
      "[2020-10-29 06:30:40,311] \n",
      "259/1000 * Epoch 259 (train): loss_autoencoder=0.8510 | loss_discriminator=0.6931\n",
      "260/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.88it/s, loss_autoencoder=0.851, loss_discriminator=0.693]\n",
      "[2020-10-29 06:30:46,935] \n",
      "260/1000 * Epoch 260 (train): loss_autoencoder=0.8509 | loss_discriminator=0.6931\n",
      "261/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.76it/s, loss_autoencoder=0.853, loss_discriminator=0.693]\n",
      "[2020-10-29 06:30:53,683] \n",
      "261/1000 * Epoch 261 (train): loss_autoencoder=0.8508 | loss_discriminator=0.6931\n",
      "262/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.84it/s, loss_autoencoder=0.853, loss_discriminator=0.693]\n",
      "[2020-10-29 06:31:00,341] \n",
      "262/1000 * Epoch 262 (train): loss_autoencoder=0.8507 | loss_discriminator=0.6931\n",
      "263/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.77it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 06:31:07,052] \n",
      "263/1000 * Epoch 263 (train): loss_autoencoder=0.8507 | loss_discriminator=0.6931\n",
      "264/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.61it/s, loss_autoencoder=0.853, loss_discriminator=0.693]\n",
      "[2020-10-29 06:31:13,893] \n",
      "264/1000 * Epoch 264 (train): loss_autoencoder=0.8507 | loss_discriminator=0.6931\n",
      "265/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.61it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 06:31:20,749] \n",
      "265/1000 * Epoch 265 (train): loss_autoencoder=0.8508 | loss_discriminator=0.6931\n",
      "266/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.87it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 06:31:27,344] \n",
      "266/1000 * Epoch 266 (train): loss_autoencoder=0.8506 | loss_discriminator=0.6931\n",
      "267/1000 * Epoch (train): 100% 58/58 [00:07<00:00,  8.17it/s, loss_autoencoder=0.852, loss_discriminator=0.693]\n",
      "[2020-10-29 06:31:34,546] \n",
      "267/1000 * Epoch 267 (train): loss_autoencoder=0.8506 | loss_discriminator=0.6931\n",
      "268/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.82it/s, loss_autoencoder=0.854, loss_discriminator=0.693]\n",
      "[2020-10-29 06:31:41,242] \n",
      "268/1000 * Epoch 268 (train): loss_autoencoder=0.8505 | loss_discriminator=0.6931\n",
      "269/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.82it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 06:31:47,922] \n",
      "269/1000 * Epoch 269 (train): loss_autoencoder=0.8506 | loss_discriminator=0.6931\n",
      "270/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.88it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 06:31:54,568] \n",
      "270/1000 * Epoch 270 (train): loss_autoencoder=0.8504 | loss_discriminator=0.6931\n",
      "271/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.85it/s, loss_autoencoder=0.854, loss_discriminator=0.693]\n",
      "[2020-10-29 06:32:01,215] \n",
      "271/1000 * Epoch 271 (train): loss_autoencoder=0.8503 | loss_discriminator=0.6931\n",
      "272/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.87it/s, loss_autoencoder=0.850, loss_discriminator=0.693]\n",
      "[2020-10-29 06:32:07,837] \n",
      "272/1000 * Epoch 272 (train): loss_autoencoder=0.8503 | loss_discriminator=0.6931\n",
      "273/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.75it/s, loss_autoencoder=0.851, loss_discriminator=0.693]\n",
      "[2020-10-29 06:32:14,571] \n",
      "273/1000 * Epoch 273 (train): loss_autoencoder=0.8502 | loss_discriminator=0.6931\n",
      "274/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.89it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 06:32:21,204] \n",
      "274/1000 * Epoch 274 (train): loss_autoencoder=0.8503 | loss_discriminator=0.6931\n",
      "275/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.85it/s, loss_autoencoder=0.851, loss_discriminator=0.693]\n",
      "[2020-10-29 06:32:27,853] \n",
      "275/1000 * Epoch 275 (train): loss_autoencoder=0.8502 | loss_discriminator=0.6931\n",
      "276/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.83it/s, loss_autoencoder=0.850, loss_discriminator=0.693]\n",
      "[2020-10-29 06:32:34,518] \n",
      "276/1000 * Epoch 276 (train): loss_autoencoder=0.8502 | loss_discriminator=0.6931\n",
      "277/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.84it/s, loss_autoencoder=0.850, loss_discriminator=0.693]\n",
      "[2020-10-29 06:32:41,222] \n",
      "277/1000 * Epoch 277 (train): loss_autoencoder=0.8501 | loss_discriminator=0.6931\n",
      "278/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.76it/s, loss_autoencoder=0.852, loss_discriminator=0.693]\n",
      "[2020-10-29 06:32:47,950] \n",
      "278/1000 * Epoch 278 (train): loss_autoencoder=0.8501 | loss_discriminator=0.6931\n",
      "279/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.90it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 06:32:54,565] \n",
      "279/1000 * Epoch 279 (train): loss_autoencoder=0.8500 | loss_discriminator=0.6931\n",
      "280/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.88it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 06:33:01,217] \n",
      "280/1000 * Epoch 280 (train): loss_autoencoder=0.8500 | loss_discriminator=0.6931\n",
      "281/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.78it/s, loss_autoencoder=0.851, loss_discriminator=0.693]\n",
      "[2020-10-29 06:33:07,935] \n",
      "281/1000 * Epoch 281 (train): loss_autoencoder=0.8500 | loss_discriminator=0.6931\n",
      "282/1000 * Epoch (train): 100% 58/58 [00:07<00:00,  8.04it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 06:33:15,247] \n",
      "282/1000 * Epoch 282 (train): loss_autoencoder=0.8499 | loss_discriminator=0.6931\n",
      "283/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.80it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 06:33:21,987] \n",
      "283/1000 * Epoch 283 (train): loss_autoencoder=0.8499 | loss_discriminator=0.6931\n",
      "284/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.66it/s, loss_autoencoder=0.851, loss_discriminator=0.693]\n",
      "[2020-10-29 06:33:28,771] \n",
      "284/1000 * Epoch 284 (train): loss_autoencoder=0.8498 | loss_discriminator=0.6931\n",
      "285/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.81it/s, loss_autoencoder=0.850, loss_discriminator=0.693]\n",
      "[2020-10-29 06:33:35,481] \n",
      "285/1000 * Epoch 285 (train): loss_autoencoder=0.8499 | loss_discriminator=0.6931\n",
      "286/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.66it/s, loss_autoencoder=0.850, loss_discriminator=0.693]\n",
      "[2020-10-29 06:33:42,321] \n",
      "286/1000 * Epoch 286 (train): loss_autoencoder=0.8498 | loss_discriminator=0.6931\n",
      "287/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.85it/s, loss_autoencoder=0.850, loss_discriminator=0.693]\n",
      "[2020-10-29 06:33:48,968] \n",
      "287/1000 * Epoch 287 (train): loss_autoencoder=0.8498 | loss_discriminator=0.6931\n",
      "288/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.76it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 06:33:55,695] \n",
      "288/1000 * Epoch 288 (train): loss_autoencoder=0.8497 | loss_discriminator=0.6931\n",
      "289/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.74it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 06:34:02,462] \n",
      "289/1000 * Epoch 289 (train): loss_autoencoder=0.8497 | loss_discriminator=0.6931\n",
      "290/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.64it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 06:34:09,254] \n",
      "290/1000 * Epoch 290 (train): loss_autoencoder=0.8497 | loss_discriminator=0.6931\n",
      "291/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.88it/s, loss_autoencoder=0.852, loss_discriminator=0.693]\n",
      "[2020-10-29 06:34:15,886] \n",
      "291/1000 * Epoch 291 (train): loss_autoencoder=0.8495 | loss_discriminator=0.6931\n",
      "292/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.67it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 06:34:22,672] \n",
      "292/1000 * Epoch 292 (train): loss_autoencoder=0.8496 | loss_discriminator=0.6931\n",
      "293/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.81it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 06:34:29,335] \n",
      "293/1000 * Epoch 293 (train): loss_autoencoder=0.8494 | loss_discriminator=0.6931\n",
      "294/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.91it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 06:34:35,938] \n",
      "294/1000 * Epoch 294 (train): loss_autoencoder=0.8495 | loss_discriminator=0.6931\n",
      "295/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.89it/s, loss_autoencoder=0.852, loss_discriminator=0.693]\n",
      "[2020-10-29 06:34:42,551] \n",
      "295/1000 * Epoch 295 (train): loss_autoencoder=0.8495 | loss_discriminator=0.6931\n",
      "296/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.81it/s, loss_autoencoder=0.850, loss_discriminator=0.693]\n",
      "[2020-10-29 06:34:49,241] \n",
      "296/1000 * Epoch 296 (train): loss_autoencoder=0.8494 | loss_discriminator=0.6931\n",
      "297/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.40it/s, loss_autoencoder=0.851, loss_discriminator=0.693]\n",
      "[2020-10-29 06:34:56,251] \n",
      "297/1000 * Epoch 297 (train): loss_autoencoder=0.8494 | loss_discriminator=0.6931\n",
      "298/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.72it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 06:35:03,012] \n",
      "298/1000 * Epoch 298 (train): loss_autoencoder=0.8494 | loss_discriminator=0.6931\n",
      "299/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.92it/s, loss_autoencoder=0.850, loss_discriminator=0.693]\n",
      "[2020-10-29 06:35:09,614] \n",
      "299/1000 * Epoch 299 (train): loss_autoencoder=0.8493 | loss_discriminator=0.6931\n",
      "300/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.76it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 06:35:16,341] \n",
      "300/1000 * Epoch 300 (train): loss_autoencoder=0.8493 | loss_discriminator=0.6931\n",
      "301/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.81it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 06:35:23,001] \n",
      "301/1000 * Epoch 301 (train): loss_autoencoder=0.8493 | loss_discriminator=0.6931\n",
      "302/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.68it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 06:35:29,790] \n",
      "302/1000 * Epoch 302 (train): loss_autoencoder=0.8493 | loss_discriminator=0.6931\n",
      "303/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.66it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 06:35:36,544] \n",
      "303/1000 * Epoch 303 (train): loss_autoencoder=0.8493 | loss_discriminator=0.6931\n",
      "304/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.88it/s, loss_autoencoder=0.941, loss_discriminator=0.693]\n",
      "[2020-10-29 06:35:43,181] \n",
      "304/1000 * Epoch 304 (train): loss_autoencoder=0.9507 | loss_discriminator=0.6931\n",
      "305/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.56it/s, loss_autoencoder=0.910, loss_discriminator=0.693]\n",
      "[2020-10-29 06:35:50,057] \n",
      "305/1000 * Epoch 305 (train): loss_autoencoder=0.9231 | loss_discriminator=0.6932\n",
      "306/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.72it/s, loss_autoencoder=0.898, loss_discriminator=0.693]\n",
      "[2020-10-29 06:35:56,829] \n",
      "306/1000 * Epoch 306 (train): loss_autoencoder=0.9009 | loss_discriminator=0.6932\n",
      "307/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.95it/s, loss_autoencoder=0.887, loss_discriminator=0.693]\n",
      "[2020-10-29 06:36:03,412] \n",
      "307/1000 * Epoch 307 (train): loss_autoencoder=0.8924 | loss_discriminator=0.6931\n",
      "308/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.79it/s, loss_autoencoder=0.884, loss_discriminator=0.693]\n",
      "[2020-10-29 06:36:10,125] \n",
      "308/1000 * Epoch 308 (train): loss_autoencoder=0.8858 | loss_discriminator=0.6931\n",
      "309/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.82it/s, loss_autoencoder=0.877, loss_discriminator=0.693]\n",
      "[2020-10-29 06:36:16,816] \n",
      "309/1000 * Epoch 309 (train): loss_autoencoder=0.8810 | loss_discriminator=0.6931\n",
      "310/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.76it/s, loss_autoencoder=0.877, loss_discriminator=0.693]\n",
      "[2020-10-29 06:36:23,536] \n",
      "310/1000 * Epoch 310 (train): loss_autoencoder=0.8774 | loss_discriminator=0.6931\n",
      "311/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.68it/s, loss_autoencoder=0.873, loss_discriminator=0.693]\n",
      "[2020-10-29 06:36:30,328] \n",
      "311/1000 * Epoch 311 (train): loss_autoencoder=0.8747 | loss_discriminator=0.6931\n",
      "312/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.78it/s, loss_autoencoder=0.874, loss_discriminator=0.693]\n",
      "[2020-10-29 06:36:37,040] \n",
      "312/1000 * Epoch 312 (train): loss_autoencoder=0.8722 | loss_discriminator=0.6931\n",
      "313/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.62it/s, loss_autoencoder=0.868, loss_discriminator=0.693]\n",
      "[2020-10-29 06:36:43,866] \n",
      "313/1000 * Epoch 313 (train): loss_autoencoder=0.8701 | loss_discriminator=0.6931\n",
      "314/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.61it/s, loss_autoencoder=0.866, loss_discriminator=0.693]\n",
      "[2020-10-29 06:36:50,701] \n",
      "314/1000 * Epoch 314 (train): loss_autoencoder=0.8682 | loss_discriminator=0.6931\n",
      "315/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.55it/s, loss_autoencoder=0.865, loss_discriminator=0.693]\n",
      "[2020-10-29 06:36:57,597] \n",
      "315/1000 * Epoch 315 (train): loss_autoencoder=0.8668 | loss_discriminator=0.6931\n",
      "316/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.47it/s, loss_autoencoder=0.866, loss_discriminator=0.693]\n",
      "[2020-10-29 06:37:04,554] \n",
      "316/1000 * Epoch 316 (train): loss_autoencoder=0.8655 | loss_discriminator=0.6931\n",
      "317/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.35it/s, loss_autoencoder=0.866, loss_discriminator=0.693]\n",
      "[2020-10-29 06:37:11,597] \n",
      "317/1000 * Epoch 317 (train): loss_autoencoder=0.8643 | loss_discriminator=0.6931\n",
      "318/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.90it/s, loss_autoencoder=0.865, loss_discriminator=0.693]\n",
      "[2020-10-29 06:37:18,214] \n",
      "318/1000 * Epoch 318 (train): loss_autoencoder=0.8633 | loss_discriminator=0.6931\n",
      "319/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.83it/s, loss_autoencoder=0.864, loss_discriminator=0.693]\n",
      "[2020-10-29 06:37:24,888] \n",
      "319/1000 * Epoch 319 (train): loss_autoencoder=0.8624 | loss_discriminator=0.6931\n",
      "320/1000 * Epoch (train): 100% 58/58 [00:07<00:00,  8.04it/s, loss_autoencoder=0.863, loss_discriminator=0.693]\n",
      "[2020-10-29 06:37:32,205] \n",
      "320/1000 * Epoch 320 (train): loss_autoencoder=0.8617 | loss_discriminator=0.6931\n",
      "321/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.82it/s, loss_autoencoder=0.863, loss_discriminator=0.693]\n",
      "[2020-10-29 06:37:38,875] \n",
      "321/1000 * Epoch 321 (train): loss_autoencoder=0.8609 | loss_discriminator=0.6931\n",
      "322/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.77it/s, loss_autoencoder=0.863, loss_discriminator=0.693]\n",
      "[2020-10-29 06:37:45,587] \n",
      "322/1000 * Epoch 322 (train): loss_autoencoder=0.8602 | loss_discriminator=0.6931\n",
      "323/1000 * Epoch (train): 100% 58/58 [00:07<00:00,  8.18it/s, loss_autoencoder=0.859, loss_discriminator=0.693]\n",
      "[2020-10-29 06:37:52,768] \n",
      "323/1000 * Epoch 323 (train): loss_autoencoder=0.8596 | loss_discriminator=0.6931\n",
      "324/1000 * Epoch (train): 100% 58/58 [00:07<00:00,  8.13it/s, loss_autoencoder=0.863, loss_discriminator=0.693]\n",
      "[2020-10-29 06:38:00,003] \n",
      "324/1000 * Epoch 324 (train): loss_autoencoder=0.8590 | loss_discriminator=0.6931\n",
      "325/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.97it/s, loss_autoencoder=0.858, loss_discriminator=0.693]\n",
      "[2020-10-29 06:38:06,563] \n",
      "325/1000 * Epoch 325 (train): loss_autoencoder=0.8585 | loss_discriminator=0.6931\n",
      "326/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.42it/s, loss_autoencoder=0.857, loss_discriminator=0.693]\n",
      "[2020-10-29 06:38:13,507] \n",
      "326/1000 * Epoch 326 (train): loss_autoencoder=0.8579 | loss_discriminator=0.6931\n",
      "327/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.43it/s, loss_autoencoder=0.857, loss_discriminator=0.693]\n",
      "[2020-10-29 06:38:20,479] \n",
      "327/1000 * Epoch 327 (train): loss_autoencoder=0.8575 | loss_discriminator=0.6931\n",
      "328/1000 * Epoch (train): 100% 58/58 [00:07<00:00,  8.15it/s, loss_autoencoder=0.856, loss_discriminator=0.693]\n",
      "[2020-10-29 06:38:27,696] \n",
      "328/1000 * Epoch 328 (train): loss_autoencoder=0.8571 | loss_discriminator=0.6931\n",
      "329/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.84it/s, loss_autoencoder=0.856, loss_discriminator=0.693]\n",
      "[2020-10-29 06:38:34,360] \n",
      "329/1000 * Epoch 329 (train): loss_autoencoder=0.8566 | loss_discriminator=0.6931\n",
      "330/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.72it/s, loss_autoencoder=0.855, loss_discriminator=0.693]\n",
      "[2020-10-29 06:38:41,114] \n",
      "330/1000 * Epoch 330 (train): loss_autoencoder=0.8563 | loss_discriminator=0.6931\n",
      "331/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.79it/s, loss_autoencoder=0.854, loss_discriminator=0.693]\n",
      "[2020-10-29 06:38:47,807] \n",
      "331/1000 * Epoch 331 (train): loss_autoencoder=0.8559 | loss_discriminator=0.6931\n",
      "332/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.81it/s, loss_autoencoder=0.857, loss_discriminator=0.693]\n",
      "[2020-10-29 06:38:54,491] \n",
      "332/1000 * Epoch 332 (train): loss_autoencoder=0.8556 | loss_discriminator=0.6931\n",
      "333/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.83it/s, loss_autoencoder=0.851, loss_discriminator=0.693]\n",
      "[2020-10-29 06:39:01,160] \n",
      "333/1000 * Epoch 333 (train): loss_autoencoder=0.8554 | loss_discriminator=0.6931\n",
      "334/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.65it/s, loss_autoencoder=0.851, loss_discriminator=0.693]\n",
      "[2020-10-29 06:39:07,969] \n",
      "334/1000 * Epoch 334 (train): loss_autoencoder=0.8551 | loss_discriminator=0.6931\n",
      "335/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.80it/s, loss_autoencoder=0.856, loss_discriminator=0.693]\n",
      "[2020-10-29 06:39:14,661] \n",
      "335/1000 * Epoch 335 (train): loss_autoencoder=0.8549 | loss_discriminator=0.6931\n",
      "336/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.72it/s, loss_autoencoder=0.854, loss_discriminator=0.693]\n",
      "[2020-10-29 06:39:21,399] \n",
      "336/1000 * Epoch 336 (train): loss_autoencoder=0.8545 | loss_discriminator=0.6931\n",
      "337/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.75it/s, loss_autoencoder=0.852, loss_discriminator=0.693]\n",
      "[2020-10-29 06:39:28,073] \n",
      "337/1000 * Epoch 337 (train): loss_autoencoder=0.8543 | loss_discriminator=0.6931\n",
      "338/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.83it/s, loss_autoencoder=0.853, loss_discriminator=0.693]\n",
      "[2020-10-29 06:39:34,727] \n",
      "338/1000 * Epoch 338 (train): loss_autoencoder=0.8540 | loss_discriminator=0.6931\n",
      "339/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.88it/s, loss_autoencoder=0.852, loss_discriminator=0.693]\n",
      "[2020-10-29 06:39:41,355] \n",
      "339/1000 * Epoch 339 (train): loss_autoencoder=0.8539 | loss_discriminator=0.6931\n",
      "340/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.79it/s, loss_autoencoder=0.853, loss_discriminator=0.693]\n",
      "[2020-10-29 06:39:48,056] \n",
      "340/1000 * Epoch 340 (train): loss_autoencoder=0.8537 | loss_discriminator=0.6931\n",
      "341/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.88it/s, loss_autoencoder=0.855, loss_discriminator=0.693]\n",
      "[2020-10-29 06:39:54,681] \n",
      "341/1000 * Epoch 341 (train): loss_autoencoder=0.8535 | loss_discriminator=0.6931\n",
      "342/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.84it/s, loss_autoencoder=0.850, loss_discriminator=0.693]\n",
      "[2020-10-29 06:40:01,342] \n",
      "342/1000 * Epoch 342 (train): loss_autoencoder=0.8532 | loss_discriminator=0.6931\n",
      "343/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.70it/s, loss_autoencoder=0.853, loss_discriminator=0.693]\n",
      "[2020-10-29 06:40:08,102] \n",
      "343/1000 * Epoch 343 (train): loss_autoencoder=0.8532 | loss_discriminator=0.6931\n",
      "344/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.86it/s, loss_autoencoder=0.852, loss_discriminator=0.693]\n",
      "[2020-10-29 06:40:14,737] \n",
      "344/1000 * Epoch 344 (train): loss_autoencoder=0.8530 | loss_discriminator=0.6931\n",
      "345/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.64it/s, loss_autoencoder=0.850, loss_discriminator=0.693]\n",
      "[2020-10-29 06:40:21,550] \n",
      "345/1000 * Epoch 345 (train): loss_autoencoder=0.8529 | loss_discriminator=0.6931\n",
      "346/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.80it/s, loss_autoencoder=0.854, loss_discriminator=0.693]\n",
      "[2020-10-29 06:40:28,239] \n",
      "346/1000 * Epoch 346 (train): loss_autoencoder=0.8526 | loss_discriminator=0.6931\n",
      "347/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.86it/s, loss_autoencoder=0.853, loss_discriminator=0.693]\n",
      "[2020-10-29 06:40:34,908] \n",
      "347/1000 * Epoch 347 (train): loss_autoencoder=0.8525 | loss_discriminator=0.6931\n",
      "348/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.88it/s, loss_autoencoder=0.852, loss_discriminator=0.693]\n",
      "[2020-10-29 06:40:41,538] \n",
      "348/1000 * Epoch 348 (train): loss_autoencoder=0.8523 | loss_discriminator=0.6931\n",
      "349/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.83it/s, loss_autoencoder=0.852, loss_discriminator=0.693]\n",
      "[2020-10-29 06:40:48,205] \n",
      "349/1000 * Epoch 349 (train): loss_autoencoder=0.8522 | loss_discriminator=0.6931\n",
      "350/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.80it/s, loss_autoencoder=0.852, loss_discriminator=0.693]\n",
      "[2020-10-29 06:40:54,898] \n",
      "350/1000 * Epoch 350 (train): loss_autoencoder=0.8521 | loss_discriminator=0.6931\n",
      "351/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.69it/s, loss_autoencoder=0.851, loss_discriminator=0.693]\n",
      "[2020-10-29 06:41:01,670] \n",
      "351/1000 * Epoch 351 (train): loss_autoencoder=0.8519 | loss_discriminator=0.6931\n",
      "352/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.83it/s, loss_autoencoder=0.855, loss_discriminator=0.693]\n",
      "[2020-10-29 06:41:08,341] \n",
      "352/1000 * Epoch 352 (train): loss_autoencoder=0.8519 | loss_discriminator=0.6931\n",
      "353/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.64it/s, loss_autoencoder=0.852, loss_discriminator=0.693]\n",
      "[2020-10-29 06:41:15,146] \n",
      "353/1000 * Epoch 353 (train): loss_autoencoder=0.8517 | loss_discriminator=0.6931\n",
      "354/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.75it/s, loss_autoencoder=0.852, loss_discriminator=0.693]\n",
      "[2020-10-29 06:41:21,877] \n",
      "354/1000 * Epoch 354 (train): loss_autoencoder=0.8516 | loss_discriminator=0.6931\n",
      "355/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.76it/s, loss_autoencoder=0.853, loss_discriminator=0.693]\n",
      "[2020-10-29 06:41:28,595] \n",
      "355/1000 * Epoch 355 (train): loss_autoencoder=0.8515 | loss_discriminator=0.6931\n",
      "356/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.88it/s, loss_autoencoder=0.851, loss_discriminator=0.693]\n",
      "[2020-10-29 06:41:35,230] \n",
      "356/1000 * Epoch 356 (train): loss_autoencoder=0.8514 | loss_discriminator=0.6931\n",
      "357/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.83it/s, loss_autoencoder=0.850, loss_discriminator=0.693]\n",
      "[2020-10-29 06:41:41,904] \n",
      "357/1000 * Epoch 357 (train): loss_autoencoder=0.8514 | loss_discriminator=0.6931\n",
      "358/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.90it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 06:41:48,515] \n",
      "358/1000 * Epoch 358 (train): loss_autoencoder=0.8512 | loss_discriminator=0.6931\n",
      "359/1000 * Epoch (train): 100% 58/58 [00:07<00:00,  8.18it/s, loss_autoencoder=0.850, loss_discriminator=0.693]\n",
      "[2020-10-29 06:41:55,708] \n",
      "359/1000 * Epoch 359 (train): loss_autoencoder=0.8512 | loss_discriminator=0.6931\n",
      "360/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.90it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 06:42:02,337] \n",
      "360/1000 * Epoch 360 (train): loss_autoencoder=0.8511 | loss_discriminator=0.6931\n",
      "361/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.90it/s, loss_autoencoder=0.851, loss_discriminator=0.693]\n",
      "[2020-10-29 06:42:08,948] \n",
      "361/1000 * Epoch 361 (train): loss_autoencoder=0.8510 | loss_discriminator=0.6931\n",
      "362/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.65it/s, loss_autoencoder=0.851, loss_discriminator=0.693]\n",
      "[2020-10-29 06:42:15,749] \n",
      "362/1000 * Epoch 362 (train): loss_autoencoder=0.8509 | loss_discriminator=0.6931\n",
      "363/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.56it/s, loss_autoencoder=0.851, loss_discriminator=0.693]\n",
      "[2020-10-29 06:42:22,589] \n",
      "363/1000 * Epoch 363 (train): loss_autoencoder=0.8509 | loss_discriminator=0.6931\n",
      "364/1000 * Epoch (train): 100% 58/58 [00:07<00:00,  8.19it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 06:42:29,784] \n",
      "364/1000 * Epoch 364 (train): loss_autoencoder=0.8507 | loss_discriminator=0.6931\n",
      "365/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.71it/s, loss_autoencoder=0.853, loss_discriminator=0.693]\n",
      "[2020-10-29 06:42:36,543] \n",
      "365/1000 * Epoch 365 (train): loss_autoencoder=0.8507 | loss_discriminator=0.6931\n",
      "366/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.88it/s, loss_autoencoder=0.850, loss_discriminator=0.693]\n",
      "[2020-10-29 06:42:43,189] \n",
      "366/1000 * Epoch 366 (train): loss_autoencoder=0.8506 | loss_discriminator=0.6931\n",
      "367/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.82it/s, loss_autoencoder=0.850, loss_discriminator=0.693]\n",
      "[2020-10-29 06:42:49,852] \n",
      "367/1000 * Epoch 367 (train): loss_autoencoder=0.8506 | loss_discriminator=0.6931\n",
      "368/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.66it/s, loss_autoencoder=0.851, loss_discriminator=0.693]\n",
      "[2020-10-29 06:42:56,658] \n",
      "368/1000 * Epoch 368 (train): loss_autoencoder=0.8504 | loss_discriminator=0.6931\n",
      "369/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.80it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 06:43:03,306] \n",
      "369/1000 * Epoch 369 (train): loss_autoencoder=0.8504 | loss_discriminator=0.6931\n",
      "370/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.70it/s, loss_autoencoder=0.853, loss_discriminator=0.693]\n",
      "[2020-10-29 06:43:10,064] \n",
      "370/1000 * Epoch 370 (train): loss_autoencoder=0.8503 | loss_discriminator=0.6931\n",
      "371/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.71it/s, loss_autoencoder=0.850, loss_discriminator=0.693]\n",
      "[2020-10-29 06:43:16,821] \n",
      "371/1000 * Epoch 371 (train): loss_autoencoder=0.8503 | loss_discriminator=0.6931\n",
      "372/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.90it/s, loss_autoencoder=0.851, loss_discriminator=0.693]\n",
      "[2020-10-29 06:43:23,429] \n",
      "372/1000 * Epoch 372 (train): loss_autoencoder=0.8502 | loss_discriminator=0.6931\n",
      "373/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.77it/s, loss_autoencoder=0.852, loss_discriminator=0.693]\n",
      "[2020-10-29 06:43:30,161] \n",
      "373/1000 * Epoch 373 (train): loss_autoencoder=0.8501 | loss_discriminator=0.6931\n",
      "374/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.57it/s, loss_autoencoder=0.851, loss_discriminator=0.693]\n",
      "[2020-10-29 06:43:37,030] \n",
      "374/1000 * Epoch 374 (train): loss_autoencoder=0.8501 | loss_discriminator=0.6931\n",
      "375/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.73it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 06:43:43,774] \n",
      "375/1000 * Epoch 375 (train): loss_autoencoder=0.8501 | loss_discriminator=0.6931\n",
      "376/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.84it/s, loss_autoencoder=0.851, loss_discriminator=0.693]\n",
      "[2020-10-29 06:43:50,391] \n",
      "376/1000 * Epoch 376 (train): loss_autoencoder=0.8500 | loss_discriminator=0.6931\n",
      "377/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.90it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 06:43:57,008] \n",
      "377/1000 * Epoch 377 (train): loss_autoencoder=0.8499 | loss_discriminator=0.6931\n",
      "378/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.75it/s, loss_autoencoder=0.853, loss_discriminator=0.693]\n",
      "[2020-10-29 06:44:03,728] \n",
      "378/1000 * Epoch 378 (train): loss_autoencoder=0.8499 | loss_discriminator=0.6931\n",
      "379/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.80it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 06:44:10,413] \n",
      "379/1000 * Epoch 379 (train): loss_autoencoder=0.8498 | loss_discriminator=0.6931\n",
      "380/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.79it/s, loss_autoencoder=0.851, loss_discriminator=0.693]\n",
      "[2020-10-29 06:44:17,106] \n",
      "380/1000 * Epoch 380 (train): loss_autoencoder=0.8500 | loss_discriminator=0.6931\n",
      "381/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.81it/s, loss_autoencoder=0.851, loss_discriminator=0.693]\n",
      "[2020-10-29 06:44:23,816] \n",
      "381/1000 * Epoch 381 (train): loss_autoencoder=0.8496 | loss_discriminator=0.6931\n",
      "382/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.65it/s, loss_autoencoder=0.852, loss_discriminator=0.693]\n",
      "[2020-10-29 06:44:30,626] \n",
      "382/1000 * Epoch 382 (train): loss_autoencoder=0.8502 | loss_discriminator=0.6931\n",
      "383/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.71it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 06:44:37,372] \n",
      "383/1000 * Epoch 383 (train): loss_autoencoder=0.8506 | loss_discriminator=0.6931\n",
      "384/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.69it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 06:44:44,152] \n",
      "384/1000 * Epoch 384 (train): loss_autoencoder=0.8495 | loss_discriminator=0.6931\n",
      "385/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.91it/s, loss_autoencoder=0.851, loss_discriminator=0.693]\n",
      "[2020-10-29 06:44:50,764] \n",
      "385/1000 * Epoch 385 (train): loss_autoencoder=0.8495 | loss_discriminator=0.6931\n",
      "386/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.54it/s, loss_autoencoder=0.860, loss_discriminator=0.693]\n",
      "[2020-10-29 06:44:57,622] \n",
      "386/1000 * Epoch 386 (train): loss_autoencoder=0.8506 | loss_discriminator=0.6931\n",
      "387/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.79it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 06:45:04,318] \n",
      "387/1000 * Epoch 387 (train): loss_autoencoder=0.8518 | loss_discriminator=0.6931\n",
      "388/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.73it/s, loss_autoencoder=0.852, loss_discriminator=0.693]\n",
      "[2020-10-29 06:45:11,056] \n",
      "388/1000 * Epoch 388 (train): loss_autoencoder=0.8495 | loss_discriminator=0.6931\n",
      "389/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.83it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 06:45:17,753] \n",
      "389/1000 * Epoch 389 (train): loss_autoencoder=0.8493 | loss_discriminator=0.6931\n",
      "390/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.70it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 06:45:24,513] \n",
      "390/1000 * Epoch 390 (train): loss_autoencoder=0.8492 | loss_discriminator=0.6931\n",
      "391/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.66it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 06:45:31,312] \n",
      "391/1000 * Epoch 391 (train): loss_autoencoder=0.8492 | loss_discriminator=0.6931\n",
      "392/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.85it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 06:45:37,982] \n",
      "392/1000 * Epoch 392 (train): loss_autoencoder=0.8491 | loss_discriminator=0.6931\n",
      "393/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.72it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 06:45:44,735] \n",
      "393/1000 * Epoch 393 (train): loss_autoencoder=0.8491 | loss_discriminator=0.6931\n",
      "394/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.84it/s, loss_autoencoder=0.851, loss_discriminator=0.693]\n",
      "[2020-10-29 06:45:51,405] \n",
      "394/1000 * Epoch 394 (train): loss_autoencoder=0.8490 | loss_discriminator=0.6931\n",
      "395/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.83it/s, loss_autoencoder=0.855, loss_discriminator=0.693]\n",
      "[2020-10-29 06:45:58,056] \n",
      "395/1000 * Epoch 395 (train): loss_autoencoder=0.8506 | loss_discriminator=0.6931\n",
      "396/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.70it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 06:46:04,839] \n",
      "396/1000 * Epoch 396 (train): loss_autoencoder=0.8496 | loss_discriminator=0.6931\n",
      "397/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.82it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 06:46:11,517] \n",
      "397/1000 * Epoch 397 (train): loss_autoencoder=0.8490 | loss_discriminator=0.6931\n",
      "398/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.45it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 06:46:18,459] \n",
      "398/1000 * Epoch 398 (train): loss_autoencoder=0.8489 | loss_discriminator=0.6931\n",
      "399/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.61it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 06:46:25,287] \n",
      "399/1000 * Epoch 399 (train): loss_autoencoder=0.8489 | loss_discriminator=0.6931\n",
      "400/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.60it/s, loss_autoencoder=0.851, loss_discriminator=0.693]\n",
      "[2020-10-29 06:46:32,121] \n",
      "400/1000 * Epoch 400 (train): loss_autoencoder=0.8497 | loss_discriminator=0.6931\n",
      "401/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.77it/s, loss_autoencoder=0.850, loss_discriminator=0.693]\n",
      "[2020-10-29 06:46:38,840] \n",
      "401/1000 * Epoch 401 (train): loss_autoencoder=0.8498 | loss_discriminator=0.6931\n",
      "402/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.86it/s, loss_autoencoder=0.852, loss_discriminator=0.693]\n",
      "[2020-10-29 06:46:45,525] \n",
      "402/1000 * Epoch 402 (train): loss_autoencoder=0.8489 | loss_discriminator=0.6931\n",
      "403/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.88it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 06:46:52,160] \n",
      "403/1000 * Epoch 403 (train): loss_autoencoder=0.8488 | loss_discriminator=0.6931\n",
      "404/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.79it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 06:46:58,863] \n",
      "404/1000 * Epoch 404 (train): loss_autoencoder=0.8488 | loss_discriminator=0.6931\n",
      "405/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.79it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 06:47:05,511] \n",
      "405/1000 * Epoch 405 (train): loss_autoencoder=0.8486 | loss_discriminator=0.6931\n",
      "406/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.90it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 06:47:12,124] \n",
      "406/1000 * Epoch 406 (train): loss_autoencoder=0.8488 | loss_discriminator=0.6931\n",
      "407/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.89it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 06:47:18,762] \n",
      "407/1000 * Epoch 407 (train): loss_autoencoder=0.8509 | loss_discriminator=0.6931\n",
      "408/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.85it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 06:47:25,419] \n",
      "408/1000 * Epoch 408 (train): loss_autoencoder=0.8487 | loss_discriminator=0.6931\n",
      "409/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.64it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 06:47:32,234] \n",
      "409/1000 * Epoch 409 (train): loss_autoencoder=0.8486 | loss_discriminator=0.6931\n",
      "410/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.91it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 06:47:38,852] \n",
      "410/1000 * Epoch 410 (train): loss_autoencoder=0.8486 | loss_discriminator=0.6931\n",
      "411/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  9.25it/s, loss_autoencoder=0.850, loss_discriminator=0.693]\n",
      "[2020-10-29 06:47:45,221] \n",
      "411/1000 * Epoch 411 (train): loss_autoencoder=0.8485 | loss_discriminator=0.6931\n",
      "412/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.57it/s, loss_autoencoder=0.851, loss_discriminator=0.693]\n",
      "[2020-10-29 06:47:52,048] \n",
      "412/1000 * Epoch 412 (train): loss_autoencoder=0.8486 | loss_discriminator=0.6931\n",
      "413/1000 * Epoch (train): 100% 58/58 [00:07<00:00,  7.94it/s, loss_autoencoder=0.850, loss_discriminator=0.693]\n",
      "[2020-10-29 06:47:59,444] \n",
      "413/1000 * Epoch 413 (train): loss_autoencoder=0.8494 | loss_discriminator=0.6931\n",
      "414/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.86it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 06:48:06,089] \n",
      "414/1000 * Epoch 414 (train): loss_autoencoder=0.8486 | loss_discriminator=0.6931\n",
      "415/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.84it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 06:48:12,712] \n",
      "415/1000 * Epoch 415 (train): loss_autoencoder=0.8485 | loss_discriminator=0.6931\n",
      "416/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.61it/s, loss_autoencoder=0.853, loss_discriminator=0.693]\n",
      "[2020-10-29 06:48:19,552] \n",
      "416/1000 * Epoch 416 (train): loss_autoencoder=0.8494 | loss_discriminator=0.6931\n",
      "417/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.69it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 06:48:26,330] \n",
      "417/1000 * Epoch 417 (train): loss_autoencoder=0.8490 | loss_discriminator=0.6931\n",
      "418/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.74it/s, loss_autoencoder=0.850, loss_discriminator=0.693]\n",
      "[2020-10-29 06:48:33,022] \n",
      "418/1000 * Epoch 418 (train): loss_autoencoder=0.8484 | loss_discriminator=0.6931\n",
      "419/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.72it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 06:48:39,769] \n",
      "419/1000 * Epoch 419 (train): loss_autoencoder=0.8483 | loss_discriminator=0.6931\n",
      "420/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.63it/s, loss_autoencoder=0.851, loss_discriminator=0.693]\n",
      "[2020-10-29 06:48:46,598] \n",
      "420/1000 * Epoch 420 (train): loss_autoencoder=0.8484 | loss_discriminator=0.6931\n",
      "421/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.98it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 06:48:53,114] \n",
      "421/1000 * Epoch 421 (train): loss_autoencoder=0.8482 | loss_discriminator=0.6931\n",
      "422/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.61it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 06:48:59,967] \n",
      "422/1000 * Epoch 422 (train): loss_autoencoder=0.8483 | loss_discriminator=0.6931\n",
      "423/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.60it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 06:49:06,809] \n",
      "423/1000 * Epoch 423 (train): loss_autoencoder=0.8485 | loss_discriminator=0.6931\n",
      "424/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.45it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 06:49:13,738] \n",
      "424/1000 * Epoch 424 (train): loss_autoencoder=0.8488 | loss_discriminator=0.6931\n",
      "425/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.89it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 06:49:20,360] \n",
      "425/1000 * Epoch 425 (train): loss_autoencoder=0.8483 | loss_discriminator=0.6931\n",
      "426/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.91it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 06:49:26,967] \n",
      "426/1000 * Epoch 426 (train): loss_autoencoder=0.8493 | loss_discriminator=0.6931\n",
      "427/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.93it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 06:49:33,558] \n",
      "427/1000 * Epoch 427 (train): loss_autoencoder=0.8486 | loss_discriminator=0.6931\n",
      "428/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.87it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 06:49:40,233] \n",
      "428/1000 * Epoch 428 (train): loss_autoencoder=0.8482 | loss_discriminator=0.6931\n",
      "429/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.57it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 06:49:47,105] \n",
      "429/1000 * Epoch 429 (train): loss_autoencoder=0.8482 | loss_discriminator=0.6931\n",
      "430/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.74it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 06:49:53,842] \n",
      "430/1000 * Epoch 430 (train): loss_autoencoder=0.8482 | loss_discriminator=0.6931\n",
      "431/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.93it/s, loss_autoencoder=0.850, loss_discriminator=0.693]\n",
      "[2020-10-29 06:50:00,444] \n",
      "431/1000 * Epoch 431 (train): loss_autoencoder=0.8482 | loss_discriminator=0.6931\n",
      "432/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.30it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 06:50:07,531] \n",
      "432/1000 * Epoch 432 (train): loss_autoencoder=0.8495 | loss_discriminator=0.6931\n",
      "433/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.90it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 06:50:14,147] \n",
      "433/1000 * Epoch 433 (train): loss_autoencoder=0.8482 | loss_discriminator=0.6931\n",
      "434/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.73it/s, loss_autoencoder=0.851, loss_discriminator=0.693]\n",
      "[2020-10-29 06:50:20,885] \n",
      "434/1000 * Epoch 434 (train): loss_autoencoder=0.8481 | loss_discriminator=0.6931\n",
      "435/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.76it/s, loss_autoencoder=0.850, loss_discriminator=0.693]\n",
      "[2020-10-29 06:50:27,602] \n",
      "435/1000 * Epoch 435 (train): loss_autoencoder=0.8481 | loss_discriminator=0.6931\n",
      "436/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.75it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 06:50:34,337] \n",
      "436/1000 * Epoch 436 (train): loss_autoencoder=0.8481 | loss_discriminator=0.6931\n",
      "437/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.88it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 06:50:40,962] \n",
      "437/1000 * Epoch 437 (train): loss_autoencoder=0.8481 | loss_discriminator=0.6931\n",
      "438/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.89it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 06:50:47,537] \n",
      "438/1000 * Epoch 438 (train): loss_autoencoder=0.8484 | loss_discriminator=0.6931\n",
      "439/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.71it/s, loss_autoencoder=0.850, loss_discriminator=0.693]\n",
      "[2020-10-29 06:50:54,285] \n",
      "439/1000 * Epoch 439 (train): loss_autoencoder=0.8481 | loss_discriminator=0.6931\n",
      "440/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.88it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 06:51:00,918] \n",
      "440/1000 * Epoch 440 (train): loss_autoencoder=0.8479 | loss_discriminator=0.6931\n",
      "441/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.40it/s, loss_autoencoder=0.844, loss_discriminator=0.693]\n",
      "[2020-10-29 06:51:07,920] \n",
      "441/1000 * Epoch 441 (train): loss_autoencoder=0.8479 | loss_discriminator=0.6931\n",
      "442/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.76it/s, loss_autoencoder=0.850, loss_discriminator=0.693]\n",
      "[2020-10-29 06:51:14,632] \n",
      "442/1000 * Epoch 442 (train): loss_autoencoder=0.8481 | loss_discriminator=0.6931\n",
      "443/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.87it/s, loss_autoencoder=0.851, loss_discriminator=0.693]\n",
      "[2020-10-29 06:51:21,276] \n",
      "443/1000 * Epoch 443 (train): loss_autoencoder=0.8490 | loss_discriminator=0.6931\n",
      "444/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.82it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 06:51:27,944] \n",
      "444/1000 * Epoch 444 (train): loss_autoencoder=0.8480 | loss_discriminator=0.6931\n",
      "445/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.85it/s, loss_autoencoder=0.852, loss_discriminator=0.693]\n",
      "[2020-10-29 06:51:34,605] \n",
      "445/1000 * Epoch 445 (train): loss_autoencoder=0.8479 | loss_discriminator=0.6931\n",
      "446/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.78it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 06:51:41,311] \n",
      "446/1000 * Epoch 446 (train): loss_autoencoder=0.8478 | loss_discriminator=0.6931\n",
      "447/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.59it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 06:51:48,159] \n",
      "447/1000 * Epoch 447 (train): loss_autoencoder=0.8478 | loss_discriminator=0.6931\n",
      "448/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.76it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 06:51:54,897] \n",
      "448/1000 * Epoch 448 (train): loss_autoencoder=0.8478 | loss_discriminator=0.6931\n",
      "449/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.86it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 06:52:01,546] \n",
      "449/1000 * Epoch 449 (train): loss_autoencoder=0.8478 | loss_discriminator=0.6931\n",
      "450/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.83it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 06:52:08,203] \n",
      "450/1000 * Epoch 450 (train): loss_autoencoder=0.8478 | loss_discriminator=0.6931\n",
      "451/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.63it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 06:52:15,032] \n",
      "451/1000 * Epoch 451 (train): loss_autoencoder=0.8478 | loss_discriminator=0.6931\n",
      "452/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.69it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 06:52:21,800] \n",
      "452/1000 * Epoch 452 (train): loss_autoencoder=0.8478 | loss_discriminator=0.6931\n",
      "453/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.66it/s, loss_autoencoder=0.850, loss_discriminator=0.693]\n",
      "[2020-10-29 06:52:28,622] \n",
      "453/1000 * Epoch 453 (train): loss_autoencoder=0.8496 | loss_discriminator=0.6931\n",
      "454/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.90it/s, loss_autoencoder=0.850, loss_discriminator=0.693]\n",
      "[2020-10-29 06:52:35,238] \n",
      "454/1000 * Epoch 454 (train): loss_autoencoder=0.8484 | loss_discriminator=0.6931\n",
      "455/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.83it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 06:52:41,942] \n",
      "455/1000 * Epoch 455 (train): loss_autoencoder=0.8478 | loss_discriminator=0.6931\n",
      "456/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.87it/s, loss_autoencoder=0.851, loss_discriminator=0.693]\n",
      "[2020-10-29 06:52:48,600] \n",
      "456/1000 * Epoch 456 (train): loss_autoencoder=0.8477 | loss_discriminator=0.6931\n",
      "457/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.81it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 06:52:55,279] \n",
      "457/1000 * Epoch 457 (train): loss_autoencoder=0.8477 | loss_discriminator=0.6931\n",
      "458/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.94it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 06:53:01,826] \n",
      "458/1000 * Epoch 458 (train): loss_autoencoder=0.8478 | loss_discriminator=0.6931\n",
      "459/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.82it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 06:53:08,492] \n",
      "459/1000 * Epoch 459 (train): loss_autoencoder=0.8476 | loss_discriminator=0.6931\n",
      "460/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.73it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 06:53:15,235] \n",
      "460/1000 * Epoch 460 (train): loss_autoencoder=0.8477 | loss_discriminator=0.6931\n",
      "461/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.85it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 06:53:21,905] \n",
      "461/1000 * Epoch 461 (train): loss_autoencoder=0.8477 | loss_discriminator=0.6931\n",
      "462/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.87it/s, loss_autoencoder=0.850, loss_discriminator=0.693]\n",
      "[2020-10-29 06:53:28,546] \n",
      "462/1000 * Epoch 462 (train): loss_autoencoder=0.8475 | loss_discriminator=0.6931\n",
      "463/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.72it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 06:53:35,297] \n",
      "463/1000 * Epoch 463 (train): loss_autoencoder=0.8477 | loss_discriminator=0.6931\n",
      "464/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.35it/s, loss_autoencoder=0.851, loss_discriminator=0.693]\n",
      "[2020-10-29 06:53:42,337] \n",
      "464/1000 * Epoch 464 (train): loss_autoencoder=0.8478 | loss_discriminator=0.6931\n",
      "465/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.68it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 06:53:49,117] \n",
      "465/1000 * Epoch 465 (train): loss_autoencoder=0.8476 | loss_discriminator=0.6931\n",
      "466/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.78it/s, loss_autoencoder=0.850, loss_discriminator=0.693]\n",
      "[2020-10-29 06:53:55,824] \n",
      "466/1000 * Epoch 466 (train): loss_autoencoder=0.8475 | loss_discriminator=0.6931\n",
      "467/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.78it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 06:54:02,537] \n",
      "467/1000 * Epoch 467 (train): loss_autoencoder=0.8477 | loss_discriminator=0.6931\n",
      "468/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.87it/s, loss_autoencoder=0.850, loss_discriminator=0.693]\n",
      "[2020-10-29 06:54:09,128] \n",
      "468/1000 * Epoch 468 (train): loss_autoencoder=0.8477 | loss_discriminator=0.6931\n",
      "469/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.90it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 06:54:15,751] \n",
      "469/1000 * Epoch 469 (train): loss_autoencoder=0.8476 | loss_discriminator=0.6931\n",
      "470/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.94it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 06:54:22,343] \n",
      "470/1000 * Epoch 470 (train): loss_autoencoder=0.8477 | loss_discriminator=0.6931\n",
      "471/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.87it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 06:54:28,988] \n",
      "471/1000 * Epoch 471 (train): loss_autoencoder=0.8477 | loss_discriminator=0.6931\n",
      "472/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.64it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 06:54:35,789] \n",
      "472/1000 * Epoch 472 (train): loss_autoencoder=0.8475 | loss_discriminator=0.6931\n",
      "473/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.84it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 06:54:42,452] \n",
      "473/1000 * Epoch 473 (train): loss_autoencoder=0.8476 | loss_discriminator=0.6931\n",
      "474/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.72it/s, loss_autoencoder=0.851, loss_discriminator=0.693]\n",
      "[2020-10-29 06:54:49,213] \n",
      "474/1000 * Epoch 474 (train): loss_autoencoder=0.8476 | loss_discriminator=0.6931\n",
      "475/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.77it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 06:54:55,926] \n",
      "475/1000 * Epoch 475 (train): loss_autoencoder=0.8476 | loss_discriminator=0.6931\n",
      "476/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.86it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 06:55:02,568] \n",
      "476/1000 * Epoch 476 (train): loss_autoencoder=0.8475 | loss_discriminator=0.6931\n",
      "477/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.66it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 06:55:09,365] \n",
      "477/1000 * Epoch 477 (train): loss_autoencoder=0.8475 | loss_discriminator=0.6931\n",
      "478/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.90it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 06:55:15,944] \n",
      "478/1000 * Epoch 478 (train): loss_autoencoder=0.8474 | loss_discriminator=0.6931\n",
      "479/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.72it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 06:55:22,681] \n",
      "479/1000 * Epoch 479 (train): loss_autoencoder=0.8476 | loss_discriminator=0.6931\n",
      "480/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.97it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 06:55:29,249] \n",
      "480/1000 * Epoch 480 (train): loss_autoencoder=0.8474 | loss_discriminator=0.6931\n",
      "481/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.68it/s, loss_autoencoder=0.850, loss_discriminator=0.693]\n",
      "[2020-10-29 06:55:36,028] \n",
      "481/1000 * Epoch 481 (train): loss_autoencoder=0.8474 | loss_discriminator=0.6931\n",
      "482/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.66it/s, loss_autoencoder=0.844, loss_discriminator=0.693]\n",
      "[2020-10-29 06:55:42,855] \n",
      "482/1000 * Epoch 482 (train): loss_autoencoder=0.8474 | loss_discriminator=0.6931\n",
      "483/1000 * Epoch (train): 100% 58/58 [00:07<00:00,  8.11it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 06:55:50,105] \n",
      "483/1000 * Epoch 483 (train): loss_autoencoder=0.8474 | loss_discriminator=0.6931\n",
      "484/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.69it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 06:55:56,885] \n",
      "484/1000 * Epoch 484 (train): loss_autoencoder=0.8473 | loss_discriminator=0.6931\n",
      "485/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.87it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 06:56:03,523] \n",
      "485/1000 * Epoch 485 (train): loss_autoencoder=0.8474 | loss_discriminator=0.6931\n",
      "486/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.53it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 06:56:10,417] \n",
      "486/1000 * Epoch 486 (train): loss_autoencoder=0.8475 | loss_discriminator=0.6931\n",
      "487/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.67it/s, loss_autoencoder=0.844, loss_discriminator=0.693]\n",
      "[2020-10-29 06:56:17,205] \n",
      "487/1000 * Epoch 487 (train): loss_autoencoder=0.8473 | loss_discriminator=0.6931\n",
      "488/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.82it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 06:56:23,880] \n",
      "488/1000 * Epoch 488 (train): loss_autoencoder=0.8474 | loss_discriminator=0.6931\n",
      "489/1000 * Epoch (train): 100% 58/58 [00:07<00:00,  8.27it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 06:56:30,983] \n",
      "489/1000 * Epoch 489 (train): loss_autoencoder=0.8475 | loss_discriminator=0.6931\n",
      "490/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.81it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 06:56:37,664] \n",
      "490/1000 * Epoch 490 (train): loss_autoencoder=0.8473 | loss_discriminator=0.6931\n",
      "491/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.63it/s, loss_autoencoder=0.842, loss_discriminator=0.693]\n",
      "[2020-10-29 06:56:44,496] \n",
      "491/1000 * Epoch 491 (train): loss_autoencoder=0.8473 | loss_discriminator=0.6931\n",
      "492/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.86it/s, loss_autoencoder=0.850, loss_discriminator=0.693]\n",
      "[2020-10-29 06:56:51,128] \n",
      "492/1000 * Epoch 492 (train): loss_autoencoder=0.8473 | loss_discriminator=0.6931\n",
      "493/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.72it/s, loss_autoencoder=0.850, loss_discriminator=0.693]\n",
      "[2020-10-29 06:56:57,883] \n",
      "493/1000 * Epoch 493 (train): loss_autoencoder=0.8473 | loss_discriminator=0.6931\n",
      "494/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.76it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 06:57:04,566] \n",
      "494/1000 * Epoch 494 (train): loss_autoencoder=0.8473 | loss_discriminator=0.6931\n",
      "495/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.66it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 06:57:11,355] \n",
      "495/1000 * Epoch 495 (train): loss_autoencoder=0.8472 | loss_discriminator=0.6931\n",
      "496/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.78it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 06:57:18,067] \n",
      "496/1000 * Epoch 496 (train): loss_autoencoder=0.8472 | loss_discriminator=0.6931\n",
      "497/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.78it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 06:57:24,778] \n",
      "497/1000 * Epoch 497 (train): loss_autoencoder=0.8473 | loss_discriminator=0.6931\n",
      "498/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.85it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 06:57:31,439] \n",
      "498/1000 * Epoch 498 (train): loss_autoencoder=0.8471 | loss_discriminator=0.6931\n",
      "499/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.45it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 06:57:38,420] \n",
      "499/1000 * Epoch 499 (train): loss_autoencoder=0.8472 | loss_discriminator=0.6931\n",
      "500/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.74it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 06:57:45,160] \n",
      "500/1000 * Epoch 500 (train): loss_autoencoder=0.8472 | loss_discriminator=0.6931\n",
      "501/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.78it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 06:57:51,873] \n",
      "501/1000 * Epoch 501 (train): loss_autoencoder=0.8472 | loss_discriminator=0.6931\n",
      "502/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.84it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 06:57:58,530] \n",
      "502/1000 * Epoch 502 (train): loss_autoencoder=0.8472 | loss_discriminator=0.6931\n",
      "503/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.87it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 06:58:05,170] \n",
      "503/1000 * Epoch 503 (train): loss_autoencoder=0.8472 | loss_discriminator=0.6931\n",
      "504/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.69it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 06:58:11,897] \n",
      "504/1000 * Epoch 504 (train): loss_autoencoder=0.8472 | loss_discriminator=0.6931\n",
      "505/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.80it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 06:58:18,585] \n",
      "505/1000 * Epoch 505 (train): loss_autoencoder=0.8472 | loss_discriminator=0.6931\n",
      "506/1000 * Epoch (train): 100% 58/58 [00:07<00:00,  7.97it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 06:58:25,967] \n",
      "506/1000 * Epoch 506 (train): loss_autoencoder=0.8471 | loss_discriminator=0.6931\n",
      "507/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.87it/s, loss_autoencoder=0.843, loss_discriminator=0.693]\n",
      "[2020-10-29 06:58:32,623] \n",
      "507/1000 * Epoch 507 (train): loss_autoencoder=0.8472 | loss_discriminator=0.6931\n",
      "508/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.84it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 06:58:39,283] \n",
      "508/1000 * Epoch 508 (train): loss_autoencoder=0.8472 | loss_discriminator=0.6931\n",
      "509/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.49it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 06:58:46,210] \n",
      "509/1000 * Epoch 509 (train): loss_autoencoder=0.8471 | loss_discriminator=0.6931\n",
      "510/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.86it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 06:58:52,851] \n",
      "510/1000 * Epoch 510 (train): loss_autoencoder=0.8471 | loss_discriminator=0.6931\n",
      "511/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.73it/s, loss_autoencoder=0.844, loss_discriminator=0.693]\n",
      "[2020-10-29 06:58:59,596] \n",
      "511/1000 * Epoch 511 (train): loss_autoencoder=0.8471 | loss_discriminator=0.6931\n",
      "512/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.86it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 06:59:06,238] \n",
      "512/1000 * Epoch 512 (train): loss_autoencoder=0.8470 | loss_discriminator=0.6931\n",
      "513/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.84it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 06:59:12,900] \n",
      "513/1000 * Epoch 513 (train): loss_autoencoder=0.8471 | loss_discriminator=0.6931\n",
      "514/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.76it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 06:59:19,612] \n",
      "514/1000 * Epoch 514 (train): loss_autoencoder=0.8471 | loss_discriminator=0.6931\n",
      "515/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.67it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 06:59:26,401] \n",
      "515/1000 * Epoch 515 (train): loss_autoencoder=0.8470 | loss_discriminator=0.6931\n",
      "516/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.78it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 06:59:33,111] \n",
      "516/1000 * Epoch 516 (train): loss_autoencoder=0.8470 | loss_discriminator=0.6931\n",
      "517/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.78it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 06:59:39,777] \n",
      "517/1000 * Epoch 517 (train): loss_autoencoder=0.8470 | loss_discriminator=0.6931\n",
      "518/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.79it/s, loss_autoencoder=0.850, loss_discriminator=0.693]\n",
      "[2020-10-29 06:59:46,470] \n",
      "518/1000 * Epoch 518 (train): loss_autoencoder=0.8472 | loss_discriminator=0.6931\n",
      "519/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.98it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 06:59:53,043] \n",
      "519/1000 * Epoch 519 (train): loss_autoencoder=0.8470 | loss_discriminator=0.6931\n",
      "520/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.49it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 06:59:59,975] \n",
      "520/1000 * Epoch 520 (train): loss_autoencoder=0.8470 | loss_discriminator=0.6931\n",
      "521/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.82it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:00:06,655] \n",
      "521/1000 * Epoch 521 (train): loss_autoencoder=0.8470 | loss_discriminator=0.6931\n",
      "522/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.66it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 07:00:13,442] \n",
      "522/1000 * Epoch 522 (train): loss_autoencoder=0.8470 | loss_discriminator=0.6931\n",
      "523/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.93it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:00:20,034] \n",
      "523/1000 * Epoch 523 (train): loss_autoencoder=0.8470 | loss_discriminator=0.6931\n",
      "524/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.83it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:00:26,704] \n",
      "524/1000 * Epoch 524 (train): loss_autoencoder=0.8470 | loss_discriminator=0.6931\n",
      "525/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.71it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 07:00:33,415] \n",
      "525/1000 * Epoch 525 (train): loss_autoencoder=0.8470 | loss_discriminator=0.6931\n",
      "526/1000 * Epoch (train): 100% 58/58 [00:07<00:00,  8.07it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 07:00:40,715] \n",
      "526/1000 * Epoch 526 (train): loss_autoencoder=0.8470 | loss_discriminator=0.6931\n",
      "527/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.72it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 07:00:47,474] \n",
      "527/1000 * Epoch 527 (train): loss_autoencoder=0.8469 | loss_discriminator=0.6931\n",
      "528/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.81it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:00:54,153] \n",
      "528/1000 * Epoch 528 (train): loss_autoencoder=0.8469 | loss_discriminator=0.6931\n",
      "529/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.90it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 07:01:00,773] \n",
      "529/1000 * Epoch 529 (train): loss_autoencoder=0.8469 | loss_discriminator=0.6931\n",
      "530/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.65it/s, loss_autoencoder=0.843, loss_discriminator=0.693]\n",
      "[2020-10-29 07:01:07,534] \n",
      "530/1000 * Epoch 530 (train): loss_autoencoder=0.8469 | loss_discriminator=0.6931\n",
      "531/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.64it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 07:01:14,355] \n",
      "531/1000 * Epoch 531 (train): loss_autoencoder=0.8469 | loss_discriminator=0.6931\n",
      "532/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.63it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 07:01:21,181] \n",
      "532/1000 * Epoch 532 (train): loss_autoencoder=0.8470 | loss_discriminator=0.6931\n",
      "533/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.80it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 07:01:27,832] \n",
      "533/1000 * Epoch 533 (train): loss_autoencoder=0.8468 | loss_discriminator=0.6931\n",
      "534/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.69it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:01:34,608] \n",
      "534/1000 * Epoch 534 (train): loss_autoencoder=0.8469 | loss_discriminator=0.6931\n",
      "535/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.50it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 07:01:41,537] \n",
      "535/1000 * Epoch 535 (train): loss_autoencoder=0.8469 | loss_discriminator=0.6931\n",
      "536/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.72it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 07:01:48,312] \n",
      "536/1000 * Epoch 536 (train): loss_autoencoder=0.8469 | loss_discriminator=0.6931\n",
      "537/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.85it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:01:54,965] \n",
      "537/1000 * Epoch 537 (train): loss_autoencoder=0.8468 | loss_discriminator=0.6931\n",
      "538/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.78it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:02:01,669] \n",
      "538/1000 * Epoch 538 (train): loss_autoencoder=0.8469 | loss_discriminator=0.6931\n",
      "539/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.52it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 07:02:08,570] \n",
      "539/1000 * Epoch 539 (train): loss_autoencoder=0.8470 | loss_discriminator=0.6931\n",
      "540/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.86it/s, loss_autoencoder=0.850, loss_discriminator=0.693]\n",
      "[2020-10-29 07:02:15,218] \n",
      "540/1000 * Epoch 540 (train): loss_autoencoder=0.8469 | loss_discriminator=0.6931\n",
      "541/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.72it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 07:02:21,965] \n",
      "541/1000 * Epoch 541 (train): loss_autoencoder=0.8469 | loss_discriminator=0.6931\n",
      "542/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.63it/s, loss_autoencoder=0.851, loss_discriminator=0.693]\n",
      "[2020-10-29 07:02:28,764] \n",
      "542/1000 * Epoch 542 (train): loss_autoencoder=0.8468 | loss_discriminator=0.6931\n",
      "543/1000 * Epoch (train): 100% 58/58 [00:07<00:00,  8.13it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 07:02:35,991] \n",
      "543/1000 * Epoch 543 (train): loss_autoencoder=0.8468 | loss_discriminator=0.6931\n",
      "544/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.74it/s, loss_autoencoder=0.850, loss_discriminator=0.693]\n",
      "[2020-10-29 07:02:42,730] \n",
      "544/1000 * Epoch 544 (train): loss_autoencoder=0.8469 | loss_discriminator=0.6931\n",
      "545/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.86it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 07:02:49,375] \n",
      "545/1000 * Epoch 545 (train): loss_autoencoder=0.8468 | loss_discriminator=0.6931\n",
      "546/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.77it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 07:02:56,077] \n",
      "546/1000 * Epoch 546 (train): loss_autoencoder=0.8468 | loss_discriminator=0.6931\n",
      "547/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.82it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:03:02,742] \n",
      "547/1000 * Epoch 547 (train): loss_autoencoder=0.8468 | loss_discriminator=0.6931\n",
      "548/1000 * Epoch (train): 100% 58/58 [00:07<00:00,  8.21it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:03:09,903] \n",
      "548/1000 * Epoch 548 (train): loss_autoencoder=0.8468 | loss_discriminator=0.6931\n",
      "549/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.45it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:03:16,829] \n",
      "549/1000 * Epoch 549 (train): loss_autoencoder=0.8467 | loss_discriminator=0.6931\n",
      "550/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.79it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:03:23,535] \n",
      "550/1000 * Epoch 550 (train): loss_autoencoder=0.8468 | loss_discriminator=0.6931\n",
      "551/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.87it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 07:03:30,174] \n",
      "551/1000 * Epoch 551 (train): loss_autoencoder=0.8468 | loss_discriminator=0.6931\n",
      "552/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.84it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 07:03:36,790] \n",
      "552/1000 * Epoch 552 (train): loss_autoencoder=0.8468 | loss_discriminator=0.6931\n",
      "553/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.68it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 07:03:43,578] \n",
      "553/1000 * Epoch 553 (train): loss_autoencoder=0.8467 | loss_discriminator=0.6931\n",
      "554/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.67it/s, loss_autoencoder=0.842, loss_discriminator=0.693]\n",
      "[2020-10-29 07:03:50,370] \n",
      "554/1000 * Epoch 554 (train): loss_autoencoder=0.8467 | loss_discriminator=0.6931\n",
      "555/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.85it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:03:57,021] \n",
      "555/1000 * Epoch 555 (train): loss_autoencoder=0.8468 | loss_discriminator=0.6931\n",
      "556/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.84it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 07:04:03,677] \n",
      "556/1000 * Epoch 556 (train): loss_autoencoder=0.8468 | loss_discriminator=0.6931\n",
      "557/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.88it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:04:10,303] \n",
      "557/1000 * Epoch 557 (train): loss_autoencoder=0.8467 | loss_discriminator=0.6931\n",
      "558/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.86it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 07:04:16,947] \n",
      "558/1000 * Epoch 558 (train): loss_autoencoder=0.8467 | loss_discriminator=0.6931\n",
      "559/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.44it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:04:23,943] \n",
      "559/1000 * Epoch 559 (train): loss_autoencoder=0.8466 | loss_discriminator=0.6931\n",
      "560/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.79it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 07:04:30,649] \n",
      "560/1000 * Epoch 560 (train): loss_autoencoder=0.8467 | loss_discriminator=0.6931\n",
      "561/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.73it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:04:37,393] \n",
      "561/1000 * Epoch 561 (train): loss_autoencoder=0.8467 | loss_discriminator=0.6931\n",
      "562/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.83it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 07:04:44,051] \n",
      "562/1000 * Epoch 562 (train): loss_autoencoder=0.8466 | loss_discriminator=0.6931\n",
      "563/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.59it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 07:04:50,909] \n",
      "563/1000 * Epoch 563 (train): loss_autoencoder=0.8467 | loss_discriminator=0.6931\n",
      "564/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.61it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 07:04:57,750] \n",
      "564/1000 * Epoch 564 (train): loss_autoencoder=0.8467 | loss_discriminator=0.6931\n",
      "565/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.65it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:05:04,551] \n",
      "565/1000 * Epoch 565 (train): loss_autoencoder=0.8467 | loss_discriminator=0.6931\n",
      "566/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.96it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 07:05:11,125] \n",
      "566/1000 * Epoch 566 (train): loss_autoencoder=0.8468 | loss_discriminator=0.6931\n",
      "567/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.62it/s, loss_autoencoder=0.844, loss_discriminator=0.693]\n",
      "[2020-10-29 07:05:17,964] \n",
      "567/1000 * Epoch 567 (train): loss_autoencoder=0.8467 | loss_discriminator=0.6931\n",
      "568/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.49it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:05:24,945] \n",
      "568/1000 * Epoch 568 (train): loss_autoencoder=0.8466 | loss_discriminator=0.6931\n",
      "569/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.34it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:05:32,002] \n",
      "569/1000 * Epoch 569 (train): loss_autoencoder=0.8467 | loss_discriminator=0.6931\n",
      "570/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  9.01it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:05:38,539] \n",
      "570/1000 * Epoch 570 (train): loss_autoencoder=0.8466 | loss_discriminator=0.6931\n",
      "571/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.72it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 07:05:45,291] \n",
      "571/1000 * Epoch 571 (train): loss_autoencoder=0.8467 | loss_discriminator=0.6931\n",
      "572/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.92it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 07:05:51,895] \n",
      "572/1000 * Epoch 572 (train): loss_autoencoder=0.8467 | loss_discriminator=0.6931\n",
      "573/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.74it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:05:58,633] \n",
      "573/1000 * Epoch 573 (train): loss_autoencoder=0.8466 | loss_discriminator=0.6931\n",
      "574/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.69it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:06:05,408] \n",
      "574/1000 * Epoch 574 (train): loss_autoencoder=0.8466 | loss_discriminator=0.6931\n",
      "575/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  9.26it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 07:06:11,775] \n",
      "575/1000 * Epoch 575 (train): loss_autoencoder=0.8467 | loss_discriminator=0.6931\n",
      "576/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  9.04it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:06:18,298] \n",
      "576/1000 * Epoch 576 (train): loss_autoencoder=0.8467 | loss_discriminator=0.6931\n",
      "577/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.75it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:06:25,027] \n",
      "577/1000 * Epoch 577 (train): loss_autoencoder=0.8465 | loss_discriminator=0.6931\n",
      "578/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.76it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 07:06:31,747] \n",
      "578/1000 * Epoch 578 (train): loss_autoencoder=0.8467 | loss_discriminator=0.6931\n",
      "579/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.55it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 07:06:38,626] \n",
      "579/1000 * Epoch 579 (train): loss_autoencoder=0.8467 | loss_discriminator=0.6931\n",
      "580/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.78it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 07:06:45,334] \n",
      "580/1000 * Epoch 580 (train): loss_autoencoder=0.8466 | loss_discriminator=0.6931\n",
      "581/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.82it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 07:06:52,014] \n",
      "581/1000 * Epoch 581 (train): loss_autoencoder=0.8465 | loss_discriminator=0.6931\n",
      "582/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.86it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 07:06:58,617] \n",
      "582/1000 * Epoch 582 (train): loss_autoencoder=0.8466 | loss_discriminator=0.6931\n",
      "583/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.68it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:07:05,398] \n",
      "583/1000 * Epoch 583 (train): loss_autoencoder=0.8465 | loss_discriminator=0.6931\n",
      "584/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.86it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:07:12,035] \n",
      "584/1000 * Epoch 584 (train): loss_autoencoder=0.8465 | loss_discriminator=0.6931\n",
      "585/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.76it/s, loss_autoencoder=0.843, loss_discriminator=0.693]\n",
      "[2020-10-29 07:07:18,769] \n",
      "585/1000 * Epoch 585 (train): loss_autoencoder=0.8465 | loss_discriminator=0.6931\n",
      "586/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.78it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 07:07:25,470] \n",
      "586/1000 * Epoch 586 (train): loss_autoencoder=0.8466 | loss_discriminator=0.6931\n",
      "587/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.86it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 07:07:32,127] \n",
      "587/1000 * Epoch 587 (train): loss_autoencoder=0.8466 | loss_discriminator=0.6931\n",
      "588/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.63it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:07:38,953] \n",
      "588/1000 * Epoch 588 (train): loss_autoencoder=0.8465 | loss_discriminator=0.6931\n",
      "589/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.91it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 07:07:45,563] \n",
      "589/1000 * Epoch 589 (train): loss_autoencoder=0.8465 | loss_discriminator=0.6931\n",
      "590/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.68it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 07:07:52,351] \n",
      "590/1000 * Epoch 590 (train): loss_autoencoder=0.8465 | loss_discriminator=0.6931\n",
      "591/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.91it/s, loss_autoencoder=0.844, loss_discriminator=0.693]\n",
      "[2020-10-29 07:07:58,953] \n",
      "591/1000 * Epoch 591 (train): loss_autoencoder=0.8466 | loss_discriminator=0.6931\n",
      "592/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.34it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:08:05,965] \n",
      "592/1000 * Epoch 592 (train): loss_autoencoder=0.8465 | loss_discriminator=0.6931\n",
      "593/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.96it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 07:08:12,538] \n",
      "593/1000 * Epoch 593 (train): loss_autoencoder=0.8466 | loss_discriminator=0.6931\n",
      "594/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.73it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 07:08:19,296] \n",
      "594/1000 * Epoch 594 (train): loss_autoencoder=0.8465 | loss_discriminator=0.6931\n",
      "595/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.74it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 07:08:26,032] \n",
      "595/1000 * Epoch 595 (train): loss_autoencoder=0.8465 | loss_discriminator=0.6931\n",
      "596/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.74it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 07:08:32,772] \n",
      "596/1000 * Epoch 596 (train): loss_autoencoder=0.8466 | loss_discriminator=0.6931\n",
      "597/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.44it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:08:39,747] \n",
      "597/1000 * Epoch 597 (train): loss_autoencoder=0.8465 | loss_discriminator=0.6931\n",
      "598/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.55it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 07:08:46,633] \n",
      "598/1000 * Epoch 598 (train): loss_autoencoder=0.8465 | loss_discriminator=0.6931\n",
      "599/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.81it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:08:53,317] \n",
      "599/1000 * Epoch 599 (train): loss_autoencoder=0.8464 | loss_discriminator=0.6931\n",
      "600/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.77it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:09:00,034] \n",
      "600/1000 * Epoch 600 (train): loss_autoencoder=0.8464 | loss_discriminator=0.6931\n",
      "601/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.73it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 07:09:06,777] \n",
      "601/1000 * Epoch 601 (train): loss_autoencoder=0.8465 | loss_discriminator=0.6931\n",
      "602/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.64it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 07:09:13,593] \n",
      "602/1000 * Epoch 602 (train): loss_autoencoder=0.8465 | loss_discriminator=0.6931\n",
      "603/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.59it/s, loss_autoencoder=0.850, loss_discriminator=0.693]\n",
      "[2020-10-29 07:09:20,448] \n",
      "603/1000 * Epoch 603 (train): loss_autoencoder=0.8465 | loss_discriminator=0.6931\n",
      "604/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.81it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 07:09:27,148] \n",
      "604/1000 * Epoch 604 (train): loss_autoencoder=0.8464 | loss_discriminator=0.6931\n",
      "605/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.83it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:09:33,821] \n",
      "605/1000 * Epoch 605 (train): loss_autoencoder=0.8463 | loss_discriminator=0.6931\n",
      "606/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.70it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 07:09:40,590] \n",
      "606/1000 * Epoch 606 (train): loss_autoencoder=0.8464 | loss_discriminator=0.6931\n",
      "607/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.59it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:09:47,445] \n",
      "607/1000 * Epoch 607 (train): loss_autoencoder=0.8464 | loss_discriminator=0.6931\n",
      "608/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.60it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 07:09:54,251] \n",
      "608/1000 * Epoch 608 (train): loss_autoencoder=0.8465 | loss_discriminator=0.6931\n",
      "609/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.76it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:10:00,973] \n",
      "609/1000 * Epoch 609 (train): loss_autoencoder=0.8465 | loss_discriminator=0.6931\n",
      "610/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.80it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:10:07,662] \n",
      "610/1000 * Epoch 610 (train): loss_autoencoder=0.8464 | loss_discriminator=0.6931\n",
      "611/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.79it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 07:10:14,359] \n",
      "611/1000 * Epoch 611 (train): loss_autoencoder=0.8464 | loss_discriminator=0.6931\n",
      "612/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.75it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:10:21,088] \n",
      "612/1000 * Epoch 612 (train): loss_autoencoder=0.8465 | loss_discriminator=0.6931\n",
      "613/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.74it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 07:10:27,827] \n",
      "613/1000 * Epoch 613 (train): loss_autoencoder=0.8464 | loss_discriminator=0.6931\n",
      "614/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.59it/s, loss_autoencoder=0.842, loss_discriminator=0.693]\n",
      "[2020-10-29 07:10:34,673] \n",
      "614/1000 * Epoch 614 (train): loss_autoencoder=0.8464 | loss_discriminator=0.6931\n",
      "615/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.68it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:10:41,472] \n",
      "615/1000 * Epoch 615 (train): loss_autoencoder=0.8464 | loss_discriminator=0.6931\n",
      "616/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.86it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 07:10:48,115] \n",
      "616/1000 * Epoch 616 (train): loss_autoencoder=0.8464 | loss_discriminator=0.6931\n",
      "617/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.88it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 07:10:54,747] \n",
      "617/1000 * Epoch 617 (train): loss_autoencoder=0.8465 | loss_discriminator=0.6931\n",
      "618/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.97it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:11:01,271] \n",
      "618/1000 * Epoch 618 (train): loss_autoencoder=0.8464 | loss_discriminator=0.6931\n",
      "619/1000 * Epoch (train): 100% 58/58 [00:07<00:00,  8.26it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:11:08,400] \n",
      "619/1000 * Epoch 619 (train): loss_autoencoder=0.8464 | loss_discriminator=0.6931\n",
      "620/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.71it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:11:15,167] \n",
      "620/1000 * Epoch 620 (train): loss_autoencoder=0.8463 | loss_discriminator=0.6931\n",
      "621/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.87it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:11:21,778] \n",
      "621/1000 * Epoch 621 (train): loss_autoencoder=0.8463 | loss_discriminator=0.6931\n",
      "622/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.77it/s, loss_autoencoder=0.851, loss_discriminator=0.693]\n",
      "[2020-10-29 07:11:28,490] \n",
      "622/1000 * Epoch 622 (train): loss_autoencoder=0.8464 | loss_discriminator=0.6931\n",
      "623/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.76it/s, loss_autoencoder=0.844, loss_discriminator=0.693]\n",
      "[2020-10-29 07:11:35,218] \n",
      "623/1000 * Epoch 623 (train): loss_autoencoder=0.8464 | loss_discriminator=0.6931\n",
      "624/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.79it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 07:11:41,911] \n",
      "624/1000 * Epoch 624 (train): loss_autoencoder=0.8465 | loss_discriminator=0.6931\n",
      "625/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.79it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 07:11:48,612] \n",
      "625/1000 * Epoch 625 (train): loss_autoencoder=0.8464 | loss_discriminator=0.6931\n",
      "626/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.86it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 07:11:55,248] \n",
      "626/1000 * Epoch 626 (train): loss_autoencoder=0.8464 | loss_discriminator=0.6931\n",
      "627/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.83it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:12:01,916] \n",
      "627/1000 * Epoch 627 (train): loss_autoencoder=0.8463 | loss_discriminator=0.6931\n",
      "628/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.60it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:12:08,766] \n",
      "628/1000 * Epoch 628 (train): loss_autoencoder=0.8463 | loss_discriminator=0.6931\n",
      "629/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.86it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 07:12:15,419] \n",
      "629/1000 * Epoch 629 (train): loss_autoencoder=0.8463 | loss_discriminator=0.6931\n",
      "630/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.89it/s, loss_autoencoder=0.843, loss_discriminator=0.693]\n",
      "[2020-10-29 07:12:22,047] \n",
      "630/1000 * Epoch 630 (train): loss_autoencoder=0.8464 | loss_discriminator=0.6931\n",
      "631/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.82it/s, loss_autoencoder=0.844, loss_discriminator=0.693]\n",
      "[2020-10-29 07:12:28,679] \n",
      "631/1000 * Epoch 631 (train): loss_autoencoder=0.8462 | loss_discriminator=0.6931\n",
      "632/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.35it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:12:35,711] \n",
      "632/1000 * Epoch 632 (train): loss_autoencoder=0.8464 | loss_discriminator=0.6931\n",
      "633/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.64it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 07:12:42,525] \n",
      "633/1000 * Epoch 633 (train): loss_autoencoder=0.8463 | loss_discriminator=0.6931\n",
      "634/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.63it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:12:49,306] \n",
      "634/1000 * Epoch 634 (train): loss_autoencoder=0.8464 | loss_discriminator=0.6931\n",
      "635/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.49it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:12:56,251] \n",
      "635/1000 * Epoch 635 (train): loss_autoencoder=0.8463 | loss_discriminator=0.6931\n",
      "636/1000 * Epoch (train): 100% 58/58 [00:07<00:00,  8.23it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:13:03,400] \n",
      "636/1000 * Epoch 636 (train): loss_autoencoder=0.8463 | loss_discriminator=0.6931\n",
      "637/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.73it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 07:13:10,194] \n",
      "637/1000 * Epoch 637 (train): loss_autoencoder=0.8463 | loss_discriminator=0.6931\n",
      "638/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.68it/s, loss_autoencoder=0.842, loss_discriminator=0.693]\n",
      "[2020-10-29 07:13:16,977] \n",
      "638/1000 * Epoch 638 (train): loss_autoencoder=0.8463 | loss_discriminator=0.6931\n",
      "639/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.77it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 07:13:23,690] \n",
      "639/1000 * Epoch 639 (train): loss_autoencoder=0.8463 | loss_discriminator=0.6931\n",
      "640/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.89it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 07:13:30,322] \n",
      "640/1000 * Epoch 640 (train): loss_autoencoder=0.8463 | loss_discriminator=0.6931\n",
      "641/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.41it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 07:13:37,320] \n",
      "641/1000 * Epoch 641 (train): loss_autoencoder=0.8464 | loss_discriminator=0.6931\n",
      "642/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.85it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 07:13:43,981] \n",
      "642/1000 * Epoch 642 (train): loss_autoencoder=0.8463 | loss_discriminator=0.6931\n",
      "643/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.79it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:13:50,637] \n",
      "643/1000 * Epoch 643 (train): loss_autoencoder=0.8463 | loss_discriminator=0.6931\n",
      "644/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.72it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:13:57,395] \n",
      "644/1000 * Epoch 644 (train): loss_autoencoder=0.8462 | loss_discriminator=0.6931\n",
      "645/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.64it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 07:14:04,212] \n",
      "645/1000 * Epoch 645 (train): loss_autoencoder=0.8464 | loss_discriminator=0.6931\n",
      "646/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.81it/s, loss_autoencoder=0.850, loss_discriminator=0.693]\n",
      "[2020-10-29 07:14:10,859] \n",
      "646/1000 * Epoch 646 (train): loss_autoencoder=0.8461 | loss_discriminator=0.6931\n",
      "647/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.77it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 07:14:17,526] \n",
      "647/1000 * Epoch 647 (train): loss_autoencoder=0.8463 | loss_discriminator=0.6931\n",
      "648/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.83it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:14:24,193] \n",
      "648/1000 * Epoch 648 (train): loss_autoencoder=0.8464 | loss_discriminator=0.6931\n",
      "649/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.54it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 07:14:31,108] \n",
      "649/1000 * Epoch 649 (train): loss_autoencoder=0.8463 | loss_discriminator=0.6931\n",
      "650/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.92it/s, loss_autoencoder=0.844, loss_discriminator=0.693]\n",
      "[2020-10-29 07:14:37,718] \n",
      "650/1000 * Epoch 650 (train): loss_autoencoder=0.8463 | loss_discriminator=0.6931\n",
      "651/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.65it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:14:44,528] \n",
      "651/1000 * Epoch 651 (train): loss_autoencoder=0.8462 | loss_discriminator=0.6931\n",
      "652/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.72it/s, loss_autoencoder=0.843, loss_discriminator=0.693]\n",
      "[2020-10-29 07:14:51,250] \n",
      "652/1000 * Epoch 652 (train): loss_autoencoder=0.8462 | loss_discriminator=0.6931\n",
      "653/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.64it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 07:14:58,028] \n",
      "653/1000 * Epoch 653 (train): loss_autoencoder=0.8462 | loss_discriminator=0.6931\n",
      "654/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.55it/s, loss_autoencoder=0.844, loss_discriminator=0.693]\n",
      "[2020-10-29 07:15:04,935] \n",
      "654/1000 * Epoch 654 (train): loss_autoencoder=0.8463 | loss_discriminator=0.6931\n",
      "655/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.90it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 07:15:11,549] \n",
      "655/1000 * Epoch 655 (train): loss_autoencoder=0.8461 | loss_discriminator=0.6931\n",
      "656/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.87it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 07:15:18,144] \n",
      "656/1000 * Epoch 656 (train): loss_autoencoder=0.8462 | loss_discriminator=0.6931\n",
      "657/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.82it/s, loss_autoencoder=0.844, loss_discriminator=0.693]\n",
      "[2020-10-29 07:15:24,788] \n",
      "657/1000 * Epoch 657 (train): loss_autoencoder=0.8462 | loss_discriminator=0.6931\n",
      "658/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.58it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 07:15:31,649] \n",
      "658/1000 * Epoch 658 (train): loss_autoencoder=0.8463 | loss_discriminator=0.6931\n",
      "659/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.81it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:15:38,292] \n",
      "659/1000 * Epoch 659 (train): loss_autoencoder=0.8462 | loss_discriminator=0.6931\n",
      "660/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.36it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 07:15:45,334] \n",
      "660/1000 * Epoch 660 (train): loss_autoencoder=0.8461 | loss_discriminator=0.6931\n",
      "661/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.83it/s, loss_autoencoder=0.844, loss_discriminator=0.693]\n",
      "[2020-10-29 07:15:52,011] \n",
      "661/1000 * Epoch 661 (train): loss_autoencoder=0.8463 | loss_discriminator=0.6931\n",
      "662/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.72it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:15:58,726] \n",
      "662/1000 * Epoch 662 (train): loss_autoencoder=0.8462 | loss_discriminator=0.6931\n",
      "663/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.74it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:16:05,462] \n",
      "663/1000 * Epoch 663 (train): loss_autoencoder=0.8462 | loss_discriminator=0.6931\n",
      "664/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.83it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 07:16:12,133] \n",
      "664/1000 * Epoch 664 (train): loss_autoencoder=0.8462 | loss_discriminator=0.6931\n",
      "665/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.65it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 07:16:18,895] \n",
      "665/1000 * Epoch 665 (train): loss_autoencoder=0.8462 | loss_discriminator=0.6931\n",
      "666/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.80it/s, loss_autoencoder=0.843, loss_discriminator=0.693]\n",
      "[2020-10-29 07:16:25,592] \n",
      "666/1000 * Epoch 666 (train): loss_autoencoder=0.8462 | loss_discriminator=0.6931\n",
      "667/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.74it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 07:16:32,315] \n",
      "667/1000 * Epoch 667 (train): loss_autoencoder=0.8462 | loss_discriminator=0.6931\n",
      "668/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.88it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:16:38,900] \n",
      "668/1000 * Epoch 668 (train): loss_autoencoder=0.8462 | loss_discriminator=0.6931\n",
      "669/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.76it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:16:45,632] \n",
      "669/1000 * Epoch 669 (train): loss_autoencoder=0.8462 | loss_discriminator=0.6931\n",
      "670/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.50it/s, loss_autoencoder=0.843, loss_discriminator=0.693]\n",
      "[2020-10-29 07:16:52,569] \n",
      "670/1000 * Epoch 670 (train): loss_autoencoder=0.8462 | loss_discriminator=0.6931\n",
      "671/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.57it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:16:59,409] \n",
      "671/1000 * Epoch 671 (train): loss_autoencoder=0.8461 | loss_discriminator=0.6931\n",
      "672/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.78it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:17:06,108] \n",
      "672/1000 * Epoch 672 (train): loss_autoencoder=0.8462 | loss_discriminator=0.6931\n",
      "673/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.75it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:17:12,841] \n",
      "673/1000 * Epoch 673 (train): loss_autoencoder=0.8461 | loss_discriminator=0.6931\n",
      "674/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.85it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 07:17:19,457] \n",
      "674/1000 * Epoch 674 (train): loss_autoencoder=0.8462 | loss_discriminator=0.6931\n",
      "675/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.68it/s, loss_autoencoder=0.844, loss_discriminator=0.693]\n",
      "[2020-10-29 07:17:26,235] \n",
      "675/1000 * Epoch 675 (train): loss_autoencoder=0.8461 | loss_discriminator=0.6931\n",
      "676/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.63it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:17:33,062] \n",
      "676/1000 * Epoch 676 (train): loss_autoencoder=0.8462 | loss_discriminator=0.6931\n",
      "677/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.30it/s, loss_autoencoder=0.842, loss_discriminator=0.693]\n",
      "[2020-10-29 07:17:40,107] \n",
      "677/1000 * Epoch 677 (train): loss_autoencoder=0.8462 | loss_discriminator=0.6931\n",
      "678/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.84it/s, loss_autoencoder=0.844, loss_discriminator=0.693]\n",
      "[2020-10-29 07:17:46,768] \n",
      "678/1000 * Epoch 678 (train): loss_autoencoder=0.8461 | loss_discriminator=0.6931\n",
      "679/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.59it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 07:17:53,624] \n",
      "679/1000 * Epoch 679 (train): loss_autoencoder=0.8462 | loss_discriminator=0.6931\n",
      "680/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.76it/s, loss_autoencoder=0.842, loss_discriminator=0.693]\n",
      "[2020-10-29 07:18:00,328] \n",
      "680/1000 * Epoch 680 (train): loss_autoencoder=0.8461 | loss_discriminator=0.6931\n",
      "681/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.77it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:18:07,042] \n",
      "681/1000 * Epoch 681 (train): loss_autoencoder=0.8461 | loss_discriminator=0.6931\n",
      "682/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.97it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 07:18:13,612] \n",
      "682/1000 * Epoch 682 (train): loss_autoencoder=0.8461 | loss_discriminator=0.6931\n",
      "683/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.90it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:18:20,189] \n",
      "683/1000 * Epoch 683 (train): loss_autoencoder=0.8461 | loss_discriminator=0.6931\n",
      "684/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.85it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 07:18:26,842] \n",
      "684/1000 * Epoch 684 (train): loss_autoencoder=0.8463 | loss_discriminator=0.6931\n",
      "685/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.87it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 07:18:33,476] \n",
      "685/1000 * Epoch 685 (train): loss_autoencoder=0.8461 | loss_discriminator=0.6931\n",
      "686/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.87it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:18:40,126] \n",
      "686/1000 * Epoch 686 (train): loss_autoencoder=0.8462 | loss_discriminator=0.6931\n",
      "687/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.92it/s, loss_autoencoder=0.841, loss_discriminator=0.693]\n",
      "[2020-10-29 07:18:46,737] \n",
      "687/1000 * Epoch 687 (train): loss_autoencoder=0.8461 | loss_discriminator=0.6931\n",
      "688/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.83it/s, loss_autoencoder=0.844, loss_discriminator=0.693]\n",
      "[2020-10-29 07:18:53,410] \n",
      "688/1000 * Epoch 688 (train): loss_autoencoder=0.8461 | loss_discriminator=0.6931\n",
      "689/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.65it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:19:00,215] \n",
      "689/1000 * Epoch 689 (train): loss_autoencoder=0.8461 | loss_discriminator=0.6931\n",
      "690/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.79it/s, loss_autoencoder=0.843, loss_discriminator=0.693]\n",
      "[2020-10-29 07:19:06,909] \n",
      "690/1000 * Epoch 690 (train): loss_autoencoder=0.8461 | loss_discriminator=0.6931\n",
      "691/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.86it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 07:19:13,557] \n",
      "691/1000 * Epoch 691 (train): loss_autoencoder=0.8461 | loss_discriminator=0.6931\n",
      "692/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.87it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 07:19:20,200] \n",
      "692/1000 * Epoch 692 (train): loss_autoencoder=0.8462 | loss_discriminator=0.6931\n",
      "693/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.75it/s, loss_autoencoder=0.842, loss_discriminator=0.693]\n",
      "[2020-10-29 07:19:26,960] \n",
      "693/1000 * Epoch 693 (train): loss_autoencoder=0.8461 | loss_discriminator=0.6931\n",
      "694/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.75it/s, loss_autoencoder=0.844, loss_discriminator=0.693]\n",
      "[2020-10-29 07:19:33,687] \n",
      "694/1000 * Epoch 694 (train): loss_autoencoder=0.8461 | loss_discriminator=0.6931\n",
      "695/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.89it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:19:40,314] \n",
      "695/1000 * Epoch 695 (train): loss_autoencoder=0.8460 | loss_discriminator=0.6931\n",
      "696/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.70it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 07:19:47,100] \n",
      "696/1000 * Epoch 696 (train): loss_autoencoder=0.8461 | loss_discriminator=0.6931\n",
      "697/1000 * Epoch (train): 100% 58/58 [00:07<00:00,  8.27it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 07:19:54,222] \n",
      "697/1000 * Epoch 697 (train): loss_autoencoder=0.8460 | loss_discriminator=0.6931\n",
      "698/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.55it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 07:20:01,110] \n",
      "698/1000 * Epoch 698 (train): loss_autoencoder=0.8461 | loss_discriminator=0.6931\n",
      "699/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.82it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 07:20:07,795] \n",
      "699/1000 * Epoch 699 (train): loss_autoencoder=0.8461 | loss_discriminator=0.6931\n",
      "700/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.79it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:20:14,494] \n",
      "700/1000 * Epoch 700 (train): loss_autoencoder=0.8460 | loss_discriminator=0.6931\n",
      "701/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.67it/s, loss_autoencoder=0.844, loss_discriminator=0.693]\n",
      "[2020-10-29 07:20:21,287] \n",
      "701/1000 * Epoch 701 (train): loss_autoencoder=0.8459 | loss_discriminator=0.6931\n",
      "702/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.65it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:20:28,122] \n",
      "702/1000 * Epoch 702 (train): loss_autoencoder=0.8461 | loss_discriminator=0.6931\n",
      "703/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.73it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 07:20:34,860] \n",
      "703/1000 * Epoch 703 (train): loss_autoencoder=0.8460 | loss_discriminator=0.6931\n",
      "704/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  9.21it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 07:20:41,275] \n",
      "704/1000 * Epoch 704 (train): loss_autoencoder=0.8460 | loss_discriminator=0.6931\n",
      "705/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.71it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:20:48,040] \n",
      "705/1000 * Epoch 705 (train): loss_autoencoder=0.8460 | loss_discriminator=0.6931\n",
      "706/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.75it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 07:20:54,806] \n",
      "706/1000 * Epoch 706 (train): loss_autoencoder=0.8461 | loss_discriminator=0.6931\n",
      "707/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.59it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:21:01,664] \n",
      "707/1000 * Epoch 707 (train): loss_autoencoder=0.8460 | loss_discriminator=0.6931\n",
      "708/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.63it/s, loss_autoencoder=0.851, loss_discriminator=0.693]\n",
      "[2020-10-29 07:21:08,498] \n",
      "708/1000 * Epoch 708 (train): loss_autoencoder=0.8460 | loss_discriminator=0.6931\n",
      "709/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.63it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 07:21:15,336] \n",
      "709/1000 * Epoch 709 (train): loss_autoencoder=0.8460 | loss_discriminator=0.6931\n",
      "710/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.85it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 07:21:22,012] \n",
      "710/1000 * Epoch 710 (train): loss_autoencoder=0.8460 | loss_discriminator=0.6931\n",
      "711/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.60it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 07:21:28,858] \n",
      "711/1000 * Epoch 711 (train): loss_autoencoder=0.8460 | loss_discriminator=0.6931\n",
      "712/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.85it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 07:21:35,551] \n",
      "712/1000 * Epoch 712 (train): loss_autoencoder=0.8461 | loss_discriminator=0.6931\n",
      "713/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.86it/s, loss_autoencoder=0.844, loss_discriminator=0.693]\n",
      "[2020-10-29 07:21:42,196] \n",
      "713/1000 * Epoch 713 (train): loss_autoencoder=0.8460 | loss_discriminator=0.6931\n",
      "714/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.74it/s, loss_autoencoder=0.843, loss_discriminator=0.693]\n",
      "[2020-10-29 07:21:48,952] \n",
      "714/1000 * Epoch 714 (train): loss_autoencoder=0.8460 | loss_discriminator=0.6931\n",
      "715/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.75it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:21:55,693] \n",
      "715/1000 * Epoch 715 (train): loss_autoencoder=0.8460 | loss_discriminator=0.6931\n",
      "716/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.31it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 07:22:02,788] \n",
      "716/1000 * Epoch 716 (train): loss_autoencoder=0.8460 | loss_discriminator=0.6931\n",
      "717/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.78it/s, loss_autoencoder=0.843, loss_discriminator=0.693]\n",
      "[2020-10-29 07:22:09,500] \n",
      "717/1000 * Epoch 717 (train): loss_autoencoder=0.8460 | loss_discriminator=0.6931\n",
      "718/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.79it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 07:22:16,200] \n",
      "718/1000 * Epoch 718 (train): loss_autoencoder=0.8460 | loss_discriminator=0.6931\n",
      "719/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.60it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:22:23,047] \n",
      "719/1000 * Epoch 719 (train): loss_autoencoder=0.8460 | loss_discriminator=0.6931\n",
      "720/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.77it/s, loss_autoencoder=0.850, loss_discriminator=0.693]\n",
      "[2020-10-29 07:22:29,768] \n",
      "720/1000 * Epoch 720 (train): loss_autoencoder=0.8460 | loss_discriminator=0.6931\n",
      "721/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.79it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 07:22:36,473] \n",
      "721/1000 * Epoch 721 (train): loss_autoencoder=0.8460 | loss_discriminator=0.6931\n",
      "722/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.77it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:22:43,149] \n",
      "722/1000 * Epoch 722 (train): loss_autoencoder=0.8460 | loss_discriminator=0.6931\n",
      "723/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.87it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 07:22:49,797] \n",
      "723/1000 * Epoch 723 (train): loss_autoencoder=0.8459 | loss_discriminator=0.6931\n",
      "724/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.81it/s, loss_autoencoder=0.843, loss_discriminator=0.693]\n",
      "[2020-10-29 07:22:56,489] \n",
      "724/1000 * Epoch 724 (train): loss_autoencoder=0.8460 | loss_discriminator=0.6931\n",
      "725/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.83it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:23:03,158] \n",
      "725/1000 * Epoch 725 (train): loss_autoencoder=0.8459 | loss_discriminator=0.6931\n",
      "726/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.89it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:23:09,783] \n",
      "726/1000 * Epoch 726 (train): loss_autoencoder=0.8460 | loss_discriminator=0.6931\n",
      "727/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.73it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 07:23:16,527] \n",
      "727/1000 * Epoch 727 (train): loss_autoencoder=0.8460 | loss_discriminator=0.6931\n",
      "728/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.89it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:23:23,152] \n",
      "728/1000 * Epoch 728 (train): loss_autoencoder=0.8460 | loss_discriminator=0.6931\n",
      "729/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.72it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 07:23:29,891] \n",
      "729/1000 * Epoch 729 (train): loss_autoencoder=0.8461 | loss_discriminator=0.6931\n",
      "730/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.82it/s, loss_autoencoder=0.843, loss_discriminator=0.693]\n",
      "[2020-10-29 07:23:36,570] \n",
      "730/1000 * Epoch 730 (train): loss_autoencoder=0.8459 | loss_discriminator=0.6931\n",
      "731/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.82it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:23:43,261] \n",
      "731/1000 * Epoch 731 (train): loss_autoencoder=0.8459 | loss_discriminator=0.6931\n",
      "732/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.75it/s, loss_autoencoder=0.844, loss_discriminator=0.693]\n",
      "[2020-10-29 07:23:49,946] \n",
      "732/1000 * Epoch 732 (train): loss_autoencoder=0.8459 | loss_discriminator=0.6931\n",
      "733/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.88it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 07:23:56,568] \n",
      "733/1000 * Epoch 733 (train): loss_autoencoder=0.8461 | loss_discriminator=0.6931\n",
      "734/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.75it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:24:03,297] \n",
      "734/1000 * Epoch 734 (train): loss_autoencoder=0.8459 | loss_discriminator=0.6931\n",
      "735/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.74it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:24:10,029] \n",
      "735/1000 * Epoch 735 (train): loss_autoencoder=0.8459 | loss_discriminator=0.6931\n",
      "736/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.65it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:24:16,862] \n",
      "736/1000 * Epoch 736 (train): loss_autoencoder=0.8460 | loss_discriminator=0.6931\n",
      "737/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.82it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 07:24:23,541] \n",
      "737/1000 * Epoch 737 (train): loss_autoencoder=0.8460 | loss_discriminator=0.6931\n",
      "738/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.45it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:24:30,498] \n",
      "738/1000 * Epoch 738 (train): loss_autoencoder=0.8459 | loss_discriminator=0.6931\n",
      "739/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.85it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:24:37,155] \n",
      "739/1000 * Epoch 739 (train): loss_autoencoder=0.8460 | loss_discriminator=0.6931\n",
      "740/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.58it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:24:44,017] \n",
      "740/1000 * Epoch 740 (train): loss_autoencoder=0.8459 | loss_discriminator=0.6931\n",
      "741/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.86it/s, loss_autoencoder=0.842, loss_discriminator=0.693]\n",
      "[2020-10-29 07:24:50,660] \n",
      "741/1000 * Epoch 741 (train): loss_autoencoder=0.8460 | loss_discriminator=0.6931\n",
      "742/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.51it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:24:57,585] \n",
      "742/1000 * Epoch 742 (train): loss_autoencoder=0.8461 | loss_discriminator=0.6931\n",
      "743/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  9.15it/s, loss_autoencoder=0.850, loss_discriminator=0.693]\n",
      "[2020-10-29 07:25:04,025] \n",
      "743/1000 * Epoch 743 (train): loss_autoencoder=0.8459 | loss_discriminator=0.6931\n",
      "744/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.91it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 07:25:10,635] \n",
      "744/1000 * Epoch 744 (train): loss_autoencoder=0.8460 | loss_discriminator=0.6931\n",
      "745/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.84it/s, loss_autoencoder=0.844, loss_discriminator=0.693]\n",
      "[2020-10-29 07:25:17,259] \n",
      "745/1000 * Epoch 745 (train): loss_autoencoder=0.8459 | loss_discriminator=0.6931\n",
      "746/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.58it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:25:24,120] \n",
      "746/1000 * Epoch 746 (train): loss_autoencoder=0.8459 | loss_discriminator=0.6931\n",
      "747/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.86it/s, loss_autoencoder=0.850, loss_discriminator=0.693]\n",
      "[2020-10-29 07:25:30,767] \n",
      "747/1000 * Epoch 747 (train): loss_autoencoder=0.8459 | loss_discriminator=0.6931\n",
      "748/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.84it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 07:25:37,384] \n",
      "748/1000 * Epoch 748 (train): loss_autoencoder=0.8459 | loss_discriminator=0.6931\n",
      "749/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.73it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:25:44,134] \n",
      "749/1000 * Epoch 749 (train): loss_autoencoder=0.8459 | loss_discriminator=0.6931\n",
      "750/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.54it/s, loss_autoencoder=0.844, loss_discriminator=0.693]\n",
      "[2020-10-29 07:25:51,025] \n",
      "750/1000 * Epoch 750 (train): loss_autoencoder=0.8459 | loss_discriminator=0.6931\n",
      "751/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.57it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 07:25:57,886] \n",
      "751/1000 * Epoch 751 (train): loss_autoencoder=0.8459 | loss_discriminator=0.6931\n",
      "752/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.83it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 07:26:04,547] \n",
      "752/1000 * Epoch 752 (train): loss_autoencoder=0.8460 | loss_discriminator=0.6931\n",
      "753/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.89it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:26:11,174] \n",
      "753/1000 * Epoch 753 (train): loss_autoencoder=0.8459 | loss_discriminator=0.6931\n",
      "754/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.93it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 07:26:17,779] \n",
      "754/1000 * Epoch 754 (train): loss_autoencoder=0.8458 | loss_discriminator=0.6931\n",
      "755/1000 * Epoch (train): 100% 58/58 [00:07<00:00,  8.13it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 07:26:24,975] \n",
      "755/1000 * Epoch 755 (train): loss_autoencoder=0.8459 | loss_discriminator=0.6931\n",
      "756/1000 * Epoch (train): 100% 58/58 [00:07<00:00,  7.81it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:26:32,509] \n",
      "756/1000 * Epoch 756 (train): loss_autoencoder=0.8459 | loss_discriminator=0.6931\n",
      "757/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.56it/s, loss_autoencoder=0.844, loss_discriminator=0.693]\n",
      "[2020-10-29 07:26:39,390] \n",
      "757/1000 * Epoch 757 (train): loss_autoencoder=0.8458 | loss_discriminator=0.6931\n",
      "758/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.79it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 07:26:46,101] \n",
      "758/1000 * Epoch 758 (train): loss_autoencoder=0.8460 | loss_discriminator=0.6931\n",
      "759/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.89it/s, loss_autoencoder=0.844, loss_discriminator=0.693]\n",
      "[2020-10-29 07:26:52,727] \n",
      "759/1000 * Epoch 759 (train): loss_autoencoder=0.8458 | loss_discriminator=0.6931\n",
      "760/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.89it/s, loss_autoencoder=0.844, loss_discriminator=0.693]\n",
      "[2020-10-29 07:26:59,357] \n",
      "760/1000 * Epoch 760 (train): loss_autoencoder=0.8459 | loss_discriminator=0.6931\n",
      "761/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.40it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 07:27:06,355] \n",
      "761/1000 * Epoch 761 (train): loss_autoencoder=0.8458 | loss_discriminator=0.6931\n",
      "762/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.90it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:27:12,977] \n",
      "762/1000 * Epoch 762 (train): loss_autoencoder=0.8460 | loss_discriminator=0.6931\n",
      "763/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.82it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:27:19,649] \n",
      "763/1000 * Epoch 763 (train): loss_autoencoder=0.8459 | loss_discriminator=0.6931\n",
      "764/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.61it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 07:27:26,484] \n",
      "764/1000 * Epoch 764 (train): loss_autoencoder=0.8458 | loss_discriminator=0.6931\n",
      "765/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.75it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:27:33,219] \n",
      "765/1000 * Epoch 765 (train): loss_autoencoder=0.8459 | loss_discriminator=0.6931\n",
      "766/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.78it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 07:27:39,936] \n",
      "766/1000 * Epoch 766 (train): loss_autoencoder=0.8459 | loss_discriminator=0.6931\n",
      "767/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.67it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:27:46,728] \n",
      "767/1000 * Epoch 767 (train): loss_autoencoder=0.8459 | loss_discriminator=0.6931\n",
      "768/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.69it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 07:27:53,494] \n",
      "768/1000 * Epoch 768 (train): loss_autoencoder=0.8459 | loss_discriminator=0.6931\n",
      "769/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.75it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:28:00,226] \n",
      "769/1000 * Epoch 769 (train): loss_autoencoder=0.8458 | loss_discriminator=0.6931\n",
      "770/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.58it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:28:07,086] \n",
      "770/1000 * Epoch 770 (train): loss_autoencoder=0.8459 | loss_discriminator=0.6931\n",
      "771/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.92it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:28:13,701] \n",
      "771/1000 * Epoch 771 (train): loss_autoencoder=0.8458 | loss_discriminator=0.6931\n",
      "772/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.49it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:28:20,638] \n",
      "772/1000 * Epoch 772 (train): loss_autoencoder=0.8458 | loss_discriminator=0.6931\n",
      "773/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.80it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:28:27,338] \n",
      "773/1000 * Epoch 773 (train): loss_autoencoder=0.8458 | loss_discriminator=0.6931\n",
      "774/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.72it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:28:34,097] \n",
      "774/1000 * Epoch 774 (train): loss_autoencoder=0.8459 | loss_discriminator=0.6931\n",
      "775/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  9.46it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:28:40,329] \n",
      "775/1000 * Epoch 775 (train): loss_autoencoder=0.8459 | loss_discriminator=0.6931\n",
      "776/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.65it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:28:47,133] \n",
      "776/1000 * Epoch 776 (train): loss_autoencoder=0.8459 | loss_discriminator=0.6931\n",
      "777/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.93it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:28:53,723] \n",
      "777/1000 * Epoch 777 (train): loss_autoencoder=0.8459 | loss_discriminator=0.6931\n",
      "778/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.56it/s, loss_autoencoder=0.844, loss_discriminator=0.693]\n",
      "[2020-10-29 07:29:00,587] \n",
      "778/1000 * Epoch 778 (train): loss_autoencoder=0.8458 | loss_discriminator=0.6931\n",
      "779/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.60it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:29:07,441] \n",
      "779/1000 * Epoch 779 (train): loss_autoencoder=0.8458 | loss_discriminator=0.6931\n",
      "780/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.56it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:29:14,324] \n",
      "780/1000 * Epoch 780 (train): loss_autoencoder=0.8458 | loss_discriminator=0.6931\n",
      "781/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.48it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 07:29:21,270] \n",
      "781/1000 * Epoch 781 (train): loss_autoencoder=0.8458 | loss_discriminator=0.6931\n",
      "782/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.62it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 07:29:28,108] \n",
      "782/1000 * Epoch 782 (train): loss_autoencoder=0.8458 | loss_discriminator=0.6931\n",
      "783/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.78it/s, loss_autoencoder=0.843, loss_discriminator=0.693]\n",
      "[2020-10-29 07:29:34,817] \n",
      "783/1000 * Epoch 783 (train): loss_autoencoder=0.8459 | loss_discriminator=0.6931\n",
      "784/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.98it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 07:29:41,381] \n",
      "784/1000 * Epoch 784 (train): loss_autoencoder=0.8458 | loss_discriminator=0.6931\n",
      "785/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.68it/s, loss_autoencoder=0.842, loss_discriminator=0.693]\n",
      "[2020-10-29 07:29:48,172] \n",
      "785/1000 * Epoch 785 (train): loss_autoencoder=0.8458 | loss_discriminator=0.6931\n",
      "786/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.58it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 07:29:55,037] \n",
      "786/1000 * Epoch 786 (train): loss_autoencoder=0.8458 | loss_discriminator=0.6931\n",
      "787/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.92it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:30:01,602] \n",
      "787/1000 * Epoch 787 (train): loss_autoencoder=0.8458 | loss_discriminator=0.6931\n",
      "788/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.72it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:30:08,357] \n",
      "788/1000 * Epoch 788 (train): loss_autoencoder=0.8458 | loss_discriminator=0.6931\n",
      "789/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.73it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:30:15,101] \n",
      "789/1000 * Epoch 789 (train): loss_autoencoder=0.8458 | loss_discriminator=0.6931\n",
      "790/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.81it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 07:30:21,802] \n",
      "790/1000 * Epoch 790 (train): loss_autoencoder=0.8458 | loss_discriminator=0.6931\n",
      "791/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.62it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:30:28,629] \n",
      "791/1000 * Epoch 791 (train): loss_autoencoder=0.8458 | loss_discriminator=0.6931\n",
      "792/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.76it/s, loss_autoencoder=0.843, loss_discriminator=0.693]\n",
      "[2020-10-29 07:30:35,358] \n",
      "792/1000 * Epoch 792 (train): loss_autoencoder=0.8459 | loss_discriminator=0.6931\n",
      "793/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.62it/s, loss_autoencoder=0.843, loss_discriminator=0.693]\n",
      "[2020-10-29 07:30:42,206] \n",
      "793/1000 * Epoch 793 (train): loss_autoencoder=0.8458 | loss_discriminator=0.6931\n",
      "794/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.70it/s, loss_autoencoder=0.842, loss_discriminator=0.693]\n",
      "[2020-10-29 07:30:48,980] \n",
      "794/1000 * Epoch 794 (train): loss_autoencoder=0.8458 | loss_discriminator=0.6931\n",
      "795/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.78it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:30:55,697] \n",
      "795/1000 * Epoch 795 (train): loss_autoencoder=0.8457 | loss_discriminator=0.6931\n",
      "796/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.71it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:31:02,460] \n",
      "796/1000 * Epoch 796 (train): loss_autoencoder=0.8458 | loss_discriminator=0.6931\n",
      "797/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.73it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:31:09,167] \n",
      "797/1000 * Epoch 797 (train): loss_autoencoder=0.8458 | loss_discriminator=0.6931\n",
      "798/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.79it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:31:15,875] \n",
      "798/1000 * Epoch 798 (train): loss_autoencoder=0.8458 | loss_discriminator=0.6931\n",
      "799/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.79it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:31:22,579] \n",
      "799/1000 * Epoch 799 (train): loss_autoencoder=0.8458 | loss_discriminator=0.6931\n",
      "800/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.83it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:31:29,249] \n",
      "800/1000 * Epoch 800 (train): loss_autoencoder=0.8458 | loss_discriminator=0.6931\n",
      "801/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.82it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 07:31:35,929] \n",
      "801/1000 * Epoch 801 (train): loss_autoencoder=0.8457 | loss_discriminator=0.6931\n",
      "802/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.92it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:31:42,541] \n",
      "802/1000 * Epoch 802 (train): loss_autoencoder=0.8458 | loss_discriminator=0.6931\n",
      "803/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  9.14it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:31:48,994] \n",
      "803/1000 * Epoch 803 (train): loss_autoencoder=0.8457 | loss_discriminator=0.6931\n",
      "804/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.95it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:31:55,599] \n",
      "804/1000 * Epoch 804 (train): loss_autoencoder=0.8456 | loss_discriminator=0.6931\n",
      "805/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.77it/s, loss_autoencoder=0.842, loss_discriminator=0.693]\n",
      "[2020-10-29 07:32:02,317] \n",
      "805/1000 * Epoch 805 (train): loss_autoencoder=0.8457 | loss_discriminator=0.6931\n",
      "806/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.68it/s, loss_autoencoder=0.843, loss_discriminator=0.693]\n",
      "[2020-10-29 07:32:09,100] \n",
      "806/1000 * Epoch 806 (train): loss_autoencoder=0.8457 | loss_discriminator=0.6931\n",
      "807/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.69it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:32:15,831] \n",
      "807/1000 * Epoch 807 (train): loss_autoencoder=0.8457 | loss_discriminator=0.6931\n",
      "808/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.83it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:32:22,498] \n",
      "808/1000 * Epoch 808 (train): loss_autoencoder=0.8457 | loss_discriminator=0.6931\n",
      "809/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.72it/s, loss_autoencoder=0.844, loss_discriminator=0.693]\n",
      "[2020-10-29 07:32:29,256] \n",
      "809/1000 * Epoch 809 (train): loss_autoencoder=0.8458 | loss_discriminator=0.6931\n",
      "810/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.55it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:32:36,145] \n",
      "810/1000 * Epoch 810 (train): loss_autoencoder=0.8457 | loss_discriminator=0.6931\n",
      "811/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.72it/s, loss_autoencoder=0.843, loss_discriminator=0.693]\n",
      "[2020-10-29 07:32:42,897] \n",
      "811/1000 * Epoch 811 (train): loss_autoencoder=0.8458 | loss_discriminator=0.6931\n",
      "812/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.50it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:32:49,830] \n",
      "812/1000 * Epoch 812 (train): loss_autoencoder=0.8458 | loss_discriminator=0.6931\n",
      "813/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.87it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:32:56,475] \n",
      "813/1000 * Epoch 813 (train): loss_autoencoder=0.8458 | loss_discriminator=0.6931\n",
      "814/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.79it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 07:33:03,173] \n",
      "814/1000 * Epoch 814 (train): loss_autoencoder=0.8457 | loss_discriminator=0.6931\n",
      "815/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.82it/s, loss_autoencoder=0.843, loss_discriminator=0.693]\n",
      "[2020-10-29 07:33:09,859] \n",
      "815/1000 * Epoch 815 (train): loss_autoencoder=0.8456 | loss_discriminator=0.6931\n",
      "816/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.72it/s, loss_autoencoder=0.844, loss_discriminator=0.693]\n",
      "[2020-10-29 07:33:16,623] \n",
      "816/1000 * Epoch 816 (train): loss_autoencoder=0.8458 | loss_discriminator=0.6931\n",
      "817/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.78it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:33:23,328] \n",
      "817/1000 * Epoch 817 (train): loss_autoencoder=0.8457 | loss_discriminator=0.6931\n",
      "818/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.74it/s, loss_autoencoder=0.844, loss_discriminator=0.693]\n",
      "[2020-10-29 07:33:30,070] \n",
      "818/1000 * Epoch 818 (train): loss_autoencoder=0.8458 | loss_discriminator=0.6931\n",
      "819/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.78it/s, loss_autoencoder=0.844, loss_discriminator=0.693]\n",
      "[2020-10-29 07:33:36,774] \n",
      "819/1000 * Epoch 819 (train): loss_autoencoder=0.8458 | loss_discriminator=0.6931\n",
      "820/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.82it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:33:43,416] \n",
      "820/1000 * Epoch 820 (train): loss_autoencoder=0.8458 | loss_discriminator=0.6931\n",
      "821/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.84it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 07:33:50,082] \n",
      "821/1000 * Epoch 821 (train): loss_autoencoder=0.8457 | loss_discriminator=0.6931\n",
      "822/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.65it/s, loss_autoencoder=0.842, loss_discriminator=0.693]\n",
      "[2020-10-29 07:33:56,894] \n",
      "822/1000 * Epoch 822 (train): loss_autoencoder=0.8458 | loss_discriminator=0.6931\n",
      "823/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.77it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 07:34:03,620] \n",
      "823/1000 * Epoch 823 (train): loss_autoencoder=0.8457 | loss_discriminator=0.6931\n",
      "824/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.77it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 07:34:10,332] \n",
      "824/1000 * Epoch 824 (train): loss_autoencoder=0.8457 | loss_discriminator=0.6931\n",
      "825/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.80it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 07:34:17,022] \n",
      "825/1000 * Epoch 825 (train): loss_autoencoder=0.8457 | loss_discriminator=0.6931\n",
      "826/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.79it/s, loss_autoencoder=0.842, loss_discriminator=0.693]\n",
      "[2020-10-29 07:34:23,729] \n",
      "826/1000 * Epoch 826 (train): loss_autoencoder=0.8457 | loss_discriminator=0.6931\n",
      "827/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.64it/s, loss_autoencoder=0.844, loss_discriminator=0.693]\n",
      "[2020-10-29 07:34:30,549] \n",
      "827/1000 * Epoch 827 (train): loss_autoencoder=0.8457 | loss_discriminator=0.6931\n",
      "828/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.74it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 07:34:37,295] \n",
      "828/1000 * Epoch 828 (train): loss_autoencoder=0.8457 | loss_discriminator=0.6931\n",
      "829/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.78it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 07:34:44,016] \n",
      "829/1000 * Epoch 829 (train): loss_autoencoder=0.8456 | loss_discriminator=0.6931\n",
      "830/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.64it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:34:50,823] \n",
      "830/1000 * Epoch 830 (train): loss_autoencoder=0.8457 | loss_discriminator=0.6931\n",
      "831/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.82it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:34:57,504] \n",
      "831/1000 * Epoch 831 (train): loss_autoencoder=0.8457 | loss_discriminator=0.6931\n",
      "832/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.94it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:35:04,093] \n",
      "832/1000 * Epoch 832 (train): loss_autoencoder=0.8457 | loss_discriminator=0.6931\n",
      "833/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.70it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 07:35:10,818] \n",
      "833/1000 * Epoch 833 (train): loss_autoencoder=0.8457 | loss_discriminator=0.6931\n",
      "834/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.66it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:35:17,623] \n",
      "834/1000 * Epoch 834 (train): loss_autoencoder=0.8457 | loss_discriminator=0.6931\n",
      "835/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.78it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 07:35:24,339] \n",
      "835/1000 * Epoch 835 (train): loss_autoencoder=0.8457 | loss_discriminator=0.6931\n",
      "836/1000 * Epoch (train): 100% 58/58 [00:07<00:00,  8.23it/s, loss_autoencoder=0.844, loss_discriminator=0.693]\n",
      "[2020-10-29 07:35:31,527] \n",
      "836/1000 * Epoch 836 (train): loss_autoencoder=0.8456 | loss_discriminator=0.6931\n",
      "837/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.64it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:35:38,297] \n",
      "837/1000 * Epoch 837 (train): loss_autoencoder=0.8456 | loss_discriminator=0.6931\n",
      "838/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.83it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:35:44,968] \n",
      "838/1000 * Epoch 838 (train): loss_autoencoder=0.8456 | loss_discriminator=0.6931\n",
      "839/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.86it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:35:51,583] \n",
      "839/1000 * Epoch 839 (train): loss_autoencoder=0.8457 | loss_discriminator=0.6931\n",
      "840/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.46it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:35:58,559] \n",
      "840/1000 * Epoch 840 (train): loss_autoencoder=0.8457 | loss_discriminator=0.6931\n",
      "841/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.84it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 07:36:05,225] \n",
      "841/1000 * Epoch 841 (train): loss_autoencoder=0.8455 | loss_discriminator=0.6931\n",
      "842/1000 * Epoch (train): 100% 58/58 [00:07<00:00,  8.00it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:36:12,585] \n",
      "842/1000 * Epoch 842 (train): loss_autoencoder=0.8456 | loss_discriminator=0.6931\n",
      "843/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.75it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 07:36:19,315] \n",
      "843/1000 * Epoch 843 (train): loss_autoencoder=0.8456 | loss_discriminator=0.6931\n",
      "844/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.80it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:36:26,076] \n",
      "844/1000 * Epoch 844 (train): loss_autoencoder=0.8456 | loss_discriminator=0.6931\n",
      "845/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.86it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 07:36:32,725] \n",
      "845/1000 * Epoch 845 (train): loss_autoencoder=0.8457 | loss_discriminator=0.6931\n",
      "846/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.69it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:36:39,492] \n",
      "846/1000 * Epoch 846 (train): loss_autoencoder=0.8457 | loss_discriminator=0.6931\n",
      "847/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.85it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:36:46,138] \n",
      "847/1000 * Epoch 847 (train): loss_autoencoder=0.8456 | loss_discriminator=0.6931\n",
      "848/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.79it/s, loss_autoencoder=0.843, loss_discriminator=0.693]\n",
      "[2020-10-29 07:36:52,845] \n",
      "848/1000 * Epoch 848 (train): loss_autoencoder=0.8456 | loss_discriminator=0.6931\n",
      "849/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.56it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:36:59,724] \n",
      "849/1000 * Epoch 849 (train): loss_autoencoder=0.8457 | loss_discriminator=0.6931\n",
      "850/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.71it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:37:06,493] \n",
      "850/1000 * Epoch 850 (train): loss_autoencoder=0.8456 | loss_discriminator=0.6931\n",
      "851/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.92it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 07:37:13,104] \n",
      "851/1000 * Epoch 851 (train): loss_autoencoder=0.8458 | loss_discriminator=0.6931\n",
      "852/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.80it/s, loss_autoencoder=0.844, loss_discriminator=0.693]\n",
      "[2020-10-29 07:37:19,758] \n",
      "852/1000 * Epoch 852 (train): loss_autoencoder=0.8456 | loss_discriminator=0.6931\n",
      "853/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.95it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 07:37:26,342] \n",
      "853/1000 * Epoch 853 (train): loss_autoencoder=0.8456 | loss_discriminator=0.6931\n",
      "854/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.70it/s, loss_autoencoder=0.842, loss_discriminator=0.693]\n",
      "[2020-10-29 07:37:33,118] \n",
      "854/1000 * Epoch 854 (train): loss_autoencoder=0.8456 | loss_discriminator=0.6931\n",
      "855/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.95it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 07:37:39,653] \n",
      "855/1000 * Epoch 855 (train): loss_autoencoder=0.8455 | loss_discriminator=0.6931\n",
      "856/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.84it/s, loss_autoencoder=0.843, loss_discriminator=0.693]\n",
      "[2020-10-29 07:37:46,315] \n",
      "856/1000 * Epoch 856 (train): loss_autoencoder=0.8457 | loss_discriminator=0.6931\n",
      "857/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.82it/s, loss_autoencoder=0.844, loss_discriminator=0.693]\n",
      "[2020-10-29 07:37:52,990] \n",
      "857/1000 * Epoch 857 (train): loss_autoencoder=0.8455 | loss_discriminator=0.6931\n",
      "858/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.79it/s, loss_autoencoder=0.843, loss_discriminator=0.693]\n",
      "[2020-10-29 07:37:59,695] \n",
      "858/1000 * Epoch 858 (train): loss_autoencoder=0.8456 | loss_discriminator=0.6931\n",
      "859/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.73it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 07:38:06,401] \n",
      "859/1000 * Epoch 859 (train): loss_autoencoder=0.8456 | loss_discriminator=0.6931\n",
      "860/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.75it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:38:13,137] \n",
      "860/1000 * Epoch 860 (train): loss_autoencoder=0.8456 | loss_discriminator=0.6931\n",
      "861/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.73it/s, loss_autoencoder=0.841, loss_discriminator=0.693]\n",
      "[2020-10-29 07:38:19,916] \n",
      "861/1000 * Epoch 861 (train): loss_autoencoder=0.8456 | loss_discriminator=0.6931\n",
      "862/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.90it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 07:38:26,561] \n",
      "862/1000 * Epoch 862 (train): loss_autoencoder=0.8455 | loss_discriminator=0.6931\n",
      "863/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.60it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 07:38:33,401] \n",
      "863/1000 * Epoch 863 (train): loss_autoencoder=0.8456 | loss_discriminator=0.6931\n",
      "864/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.64it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:38:40,236] \n",
      "864/1000 * Epoch 864 (train): loss_autoencoder=0.8456 | loss_discriminator=0.6931\n",
      "865/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.90it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:38:46,857] \n",
      "865/1000 * Epoch 865 (train): loss_autoencoder=0.8455 | loss_discriminator=0.6931\n",
      "866/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.64it/s, loss_autoencoder=0.844, loss_discriminator=0.693]\n",
      "[2020-10-29 07:38:53,676] \n",
      "866/1000 * Epoch 866 (train): loss_autoencoder=0.8456 | loss_discriminator=0.6931\n",
      "867/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.74it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 07:39:00,375] \n",
      "867/1000 * Epoch 867 (train): loss_autoencoder=0.8456 | loss_discriminator=0.6931\n",
      "868/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.84it/s, loss_autoencoder=0.842, loss_discriminator=0.693]\n",
      "[2020-10-29 07:39:07,043] \n",
      "868/1000 * Epoch 868 (train): loss_autoencoder=0.8455 | loss_discriminator=0.6931\n",
      "869/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.82it/s, loss_autoencoder=0.842, loss_discriminator=0.693]\n",
      "[2020-10-29 07:39:13,705] \n",
      "869/1000 * Epoch 869 (train): loss_autoencoder=0.8456 | loss_discriminator=0.6931\n",
      "870/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.79it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:39:20,411] \n",
      "870/1000 * Epoch 870 (train): loss_autoencoder=0.8455 | loss_discriminator=0.6931\n",
      "871/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.91it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 07:39:27,022] \n",
      "871/1000 * Epoch 871 (train): loss_autoencoder=0.8456 | loss_discriminator=0.6931\n",
      "872/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.72it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:39:33,802] \n",
      "872/1000 * Epoch 872 (train): loss_autoencoder=0.8455 | loss_discriminator=0.6931\n",
      "873/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.86it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 07:39:40,463] \n",
      "873/1000 * Epoch 873 (train): loss_autoencoder=0.8455 | loss_discriminator=0.6931\n",
      "874/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.78it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 07:39:47,180] \n",
      "874/1000 * Epoch 874 (train): loss_autoencoder=0.8456 | loss_discriminator=0.6931\n",
      "875/1000 * Epoch (train): 100% 58/58 [00:07<00:00,  8.20it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 07:39:54,373] \n",
      "875/1000 * Epoch 875 (train): loss_autoencoder=0.8456 | loss_discriminator=0.6931\n",
      "876/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.89it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:40:01,004] \n",
      "876/1000 * Epoch 876 (train): loss_autoencoder=0.8455 | loss_discriminator=0.6931\n",
      "877/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.74it/s, loss_autoencoder=0.844, loss_discriminator=0.693]\n",
      "[2020-10-29 07:40:07,749] \n",
      "877/1000 * Epoch 877 (train): loss_autoencoder=0.8456 | loss_discriminator=0.6931\n",
      "878/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.75it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 07:40:14,484] \n",
      "878/1000 * Epoch 878 (train): loss_autoencoder=0.8456 | loss_discriminator=0.6931\n",
      "879/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.75it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:40:21,220] \n",
      "879/1000 * Epoch 879 (train): loss_autoencoder=0.8456 | loss_discriminator=0.6931\n",
      "880/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.47it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:40:28,167] \n",
      "880/1000 * Epoch 880 (train): loss_autoencoder=0.8455 | loss_discriminator=0.6931\n",
      "881/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.68it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:40:34,957] \n",
      "881/1000 * Epoch 881 (train): loss_autoencoder=0.8456 | loss_discriminator=0.6931\n",
      "882/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.80it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:40:41,653] \n",
      "882/1000 * Epoch 882 (train): loss_autoencoder=0.8455 | loss_discriminator=0.6931\n",
      "883/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.59it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:40:48,509] \n",
      "883/1000 * Epoch 883 (train): loss_autoencoder=0.8455 | loss_discriminator=0.6931\n",
      "884/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.54it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 07:40:55,405] \n",
      "884/1000 * Epoch 884 (train): loss_autoencoder=0.8455 | loss_discriminator=0.6931\n",
      "885/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.86it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 07:41:02,065] \n",
      "885/1000 * Epoch 885 (train): loss_autoencoder=0.8455 | loss_discriminator=0.6931\n",
      "886/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.90it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 07:41:08,685] \n",
      "886/1000 * Epoch 886 (train): loss_autoencoder=0.8455 | loss_discriminator=0.6931\n",
      "887/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.45it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 07:41:15,659] \n",
      "887/1000 * Epoch 887 (train): loss_autoencoder=0.8455 | loss_discriminator=0.6931\n",
      "888/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.92it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:41:22,223] \n",
      "888/1000 * Epoch 888 (train): loss_autoencoder=0.8456 | loss_discriminator=0.6931\n",
      "889/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.61it/s, loss_autoencoder=0.843, loss_discriminator=0.693]\n",
      "[2020-10-29 07:41:29,065] \n",
      "889/1000 * Epoch 889 (train): loss_autoencoder=0.8456 | loss_discriminator=0.6931\n",
      "890/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.60it/s, loss_autoencoder=0.843, loss_discriminator=0.693]\n",
      "[2020-10-29 07:41:35,902] \n",
      "890/1000 * Epoch 890 (train): loss_autoencoder=0.8456 | loss_discriminator=0.6931\n",
      "891/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.73it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:41:42,620] \n",
      "891/1000 * Epoch 891 (train): loss_autoencoder=0.8455 | loss_discriminator=0.6931\n",
      "892/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.77it/s, loss_autoencoder=0.852, loss_discriminator=0.693]\n",
      "[2020-10-29 07:41:49,341] \n",
      "892/1000 * Epoch 892 (train): loss_autoencoder=0.8456 | loss_discriminator=0.6931\n",
      "893/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.83it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:41:56,019] \n",
      "893/1000 * Epoch 893 (train): loss_autoencoder=0.8456 | loss_discriminator=0.6931\n",
      "894/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.66it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 07:42:02,821] \n",
      "894/1000 * Epoch 894 (train): loss_autoencoder=0.8456 | loss_discriminator=0.6931\n",
      "895/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.92it/s, loss_autoencoder=0.844, loss_discriminator=0.693]\n",
      "[2020-10-29 07:42:09,431] \n",
      "895/1000 * Epoch 895 (train): loss_autoencoder=0.8455 | loss_discriminator=0.6931\n",
      "896/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.68it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:42:16,219] \n",
      "896/1000 * Epoch 896 (train): loss_autoencoder=0.8455 | loss_discriminator=0.6931\n",
      "897/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.78it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:42:22,928] \n",
      "897/1000 * Epoch 897 (train): loss_autoencoder=0.8456 | loss_discriminator=0.6931\n",
      "898/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.78it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:42:29,641] \n",
      "898/1000 * Epoch 898 (train): loss_autoencoder=0.8455 | loss_discriminator=0.6931\n",
      "899/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.52it/s, loss_autoencoder=0.844, loss_discriminator=0.693]\n",
      "[2020-10-29 07:42:36,551] \n",
      "899/1000 * Epoch 899 (train): loss_autoencoder=0.8455 | loss_discriminator=0.6931\n",
      "900/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.77it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 07:42:43,276] \n",
      "900/1000 * Epoch 900 (train): loss_autoencoder=0.8456 | loss_discriminator=0.6931\n",
      "901/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.60it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:42:50,118] \n",
      "901/1000 * Epoch 901 (train): loss_autoencoder=0.8455 | loss_discriminator=0.6931\n",
      "902/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.82it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 07:42:56,792] \n",
      "902/1000 * Epoch 902 (train): loss_autoencoder=0.8455 | loss_discriminator=0.6931\n",
      "903/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.66it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:43:03,600] \n",
      "903/1000 * Epoch 903 (train): loss_autoencoder=0.8456 | loss_discriminator=0.6931\n",
      "904/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.75it/s, loss_autoencoder=0.844, loss_discriminator=0.693]\n",
      "[2020-10-29 07:43:10,354] \n",
      "904/1000 * Epoch 904 (train): loss_autoencoder=0.8455 | loss_discriminator=0.6931\n",
      "905/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.70it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 07:43:17,111] \n",
      "905/1000 * Epoch 905 (train): loss_autoencoder=0.8455 | loss_discriminator=0.6931\n",
      "906/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.74it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:43:23,862] \n",
      "906/1000 * Epoch 906 (train): loss_autoencoder=0.8455 | loss_discriminator=0.6931\n",
      "907/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.94it/s, loss_autoencoder=0.844, loss_discriminator=0.693]\n",
      "[2020-10-29 07:43:30,453] \n",
      "907/1000 * Epoch 907 (train): loss_autoencoder=0.8455 | loss_discriminator=0.6931\n",
      "908/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.85it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:43:37,109] \n",
      "908/1000 * Epoch 908 (train): loss_autoencoder=0.8456 | loss_discriminator=0.6931\n",
      "909/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.94it/s, loss_autoencoder=0.844, loss_discriminator=0.693]\n",
      "[2020-10-29 07:43:43,702] \n",
      "909/1000 * Epoch 909 (train): loss_autoencoder=0.8455 | loss_discriminator=0.6931\n",
      "910/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.63it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 07:43:50,522] \n",
      "910/1000 * Epoch 910 (train): loss_autoencoder=0.8455 | loss_discriminator=0.6931\n",
      "911/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.80it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:43:57,228] \n",
      "911/1000 * Epoch 911 (train): loss_autoencoder=0.8455 | loss_discriminator=0.6931\n",
      "912/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.72it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:44:03,987] \n",
      "912/1000 * Epoch 912 (train): loss_autoencoder=0.8455 | loss_discriminator=0.6931\n",
      "913/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.65it/s, loss_autoencoder=0.843, loss_discriminator=0.693]\n",
      "[2020-10-29 07:44:10,803] \n",
      "913/1000 * Epoch 913 (train): loss_autoencoder=0.8455 | loss_discriminator=0.6931\n",
      "914/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.77it/s, loss_autoencoder=0.844, loss_discriminator=0.693]\n",
      "[2020-10-29 07:44:17,480] \n",
      "914/1000 * Epoch 914 (train): loss_autoencoder=0.8455 | loss_discriminator=0.6931\n",
      "915/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.76it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:44:24,210] \n",
      "915/1000 * Epoch 915 (train): loss_autoencoder=0.8454 | loss_discriminator=0.6931\n",
      "916/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.58it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:44:31,088] \n",
      "916/1000 * Epoch 916 (train): loss_autoencoder=0.8455 | loss_discriminator=0.6931\n",
      "917/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.68it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:44:37,880] \n",
      "917/1000 * Epoch 917 (train): loss_autoencoder=0.8455 | loss_discriminator=0.6931\n",
      "918/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.70it/s, loss_autoencoder=0.844, loss_discriminator=0.693]\n",
      "[2020-10-29 07:44:44,612] \n",
      "918/1000 * Epoch 918 (train): loss_autoencoder=0.8455 | loss_discriminator=0.6931\n",
      "919/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.83it/s, loss_autoencoder=0.843, loss_discriminator=0.693]\n",
      "[2020-10-29 07:44:51,294] \n",
      "919/1000 * Epoch 919 (train): loss_autoencoder=0.8455 | loss_discriminator=0.6931\n",
      "920/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.89it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 07:44:57,921] \n",
      "920/1000 * Epoch 920 (train): loss_autoencoder=0.8455 | loss_discriminator=0.6931\n",
      "921/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.75it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:45:04,654] \n",
      "921/1000 * Epoch 921 (train): loss_autoencoder=0.8455 | loss_discriminator=0.6931\n",
      "922/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.92it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 07:45:11,251] \n",
      "922/1000 * Epoch 922 (train): loss_autoencoder=0.8455 | loss_discriminator=0.6931\n",
      "923/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.46it/s, loss_autoencoder=0.844, loss_discriminator=0.693]\n",
      "[2020-10-29 07:45:18,210] \n",
      "923/1000 * Epoch 923 (train): loss_autoencoder=0.8455 | loss_discriminator=0.6931\n",
      "924/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.64it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 07:45:24,987] \n",
      "924/1000 * Epoch 924 (train): loss_autoencoder=0.8455 | loss_discriminator=0.6931\n",
      "925/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.65it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:45:31,802] \n",
      "925/1000 * Epoch 925 (train): loss_autoencoder=0.8454 | loss_discriminator=0.6931\n",
      "926/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.86it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:45:38,456] \n",
      "926/1000 * Epoch 926 (train): loss_autoencoder=0.8454 | loss_discriminator=0.6931\n",
      "927/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.81it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 07:45:45,104] \n",
      "927/1000 * Epoch 927 (train): loss_autoencoder=0.8455 | loss_discriminator=0.6931\n",
      "928/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.76it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 07:45:51,832] \n",
      "928/1000 * Epoch 928 (train): loss_autoencoder=0.8455 | loss_discriminator=0.6931\n",
      "929/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.81it/s, loss_autoencoder=0.844, loss_discriminator=0.693]\n",
      "[2020-10-29 07:45:58,516] \n",
      "929/1000 * Epoch 929 (train): loss_autoencoder=0.8455 | loss_discriminator=0.6931\n",
      "930/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.77it/s, loss_autoencoder=0.844, loss_discriminator=0.693]\n",
      "[2020-10-29 07:46:05,232] \n",
      "930/1000 * Epoch 930 (train): loss_autoencoder=0.8455 | loss_discriminator=0.6931\n",
      "931/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.67it/s, loss_autoencoder=0.844, loss_discriminator=0.693]\n",
      "[2020-10-29 07:46:12,028] \n",
      "931/1000 * Epoch 931 (train): loss_autoencoder=0.8454 | loss_discriminator=0.6931\n",
      "932/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.77it/s, loss_autoencoder=0.843, loss_discriminator=0.693]\n",
      "[2020-10-29 07:46:18,740] \n",
      "932/1000 * Epoch 932 (train): loss_autoencoder=0.8455 | loss_discriminator=0.6931\n",
      "933/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.67it/s, loss_autoencoder=0.844, loss_discriminator=0.693]\n",
      "[2020-10-29 07:46:25,495] \n",
      "933/1000 * Epoch 933 (train): loss_autoencoder=0.8455 | loss_discriminator=0.6931\n",
      "934/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.63it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:46:32,318] \n",
      "934/1000 * Epoch 934 (train): loss_autoencoder=0.8455 | loss_discriminator=0.6931\n",
      "935/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.97it/s, loss_autoencoder=0.840, loss_discriminator=0.693]\n",
      "[2020-10-29 07:46:38,894] \n",
      "935/1000 * Epoch 935 (train): loss_autoencoder=0.8456 | loss_discriminator=0.6931\n",
      "936/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.72it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 07:46:45,607] \n",
      "936/1000 * Epoch 936 (train): loss_autoencoder=0.8455 | loss_discriminator=0.6931\n",
      "937/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.83it/s, loss_autoencoder=0.843, loss_discriminator=0.693]\n",
      "[2020-10-29 07:46:52,241] \n",
      "937/1000 * Epoch 937 (train): loss_autoencoder=0.8454 | loss_discriminator=0.6931\n",
      "938/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.84it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 07:46:58,910] \n",
      "938/1000 * Epoch 938 (train): loss_autoencoder=0.8456 | loss_discriminator=0.6931\n",
      "939/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.72it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 07:47:05,670] \n",
      "939/1000 * Epoch 939 (train): loss_autoencoder=0.8455 | loss_discriminator=0.6931\n",
      "940/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.72it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:47:12,428] \n",
      "940/1000 * Epoch 940 (train): loss_autoencoder=0.8454 | loss_discriminator=0.6931\n",
      "941/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.35it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:47:19,476] \n",
      "941/1000 * Epoch 941 (train): loss_autoencoder=0.8455 | loss_discriminator=0.6931\n",
      "942/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.94it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 07:47:26,077] \n",
      "942/1000 * Epoch 942 (train): loss_autoencoder=0.8453 | loss_discriminator=0.6931\n",
      "943/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.65it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:47:32,889] \n",
      "943/1000 * Epoch 943 (train): loss_autoencoder=0.8454 | loss_discriminator=0.6931\n",
      "944/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.43it/s, loss_autoencoder=0.844, loss_discriminator=0.693]\n",
      "[2020-10-29 07:47:39,877] \n",
      "944/1000 * Epoch 944 (train): loss_autoencoder=0.8454 | loss_discriminator=0.6931\n",
      "945/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.64it/s, loss_autoencoder=0.844, loss_discriminator=0.693]\n",
      "[2020-10-29 07:47:46,658] \n",
      "945/1000 * Epoch 945 (train): loss_autoencoder=0.8455 | loss_discriminator=0.6931\n",
      "946/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.70it/s, loss_autoencoder=0.842, loss_discriminator=0.693]\n",
      "[2020-10-29 07:47:53,434] \n",
      "946/1000 * Epoch 946 (train): loss_autoencoder=0.8454 | loss_discriminator=0.6931\n",
      "947/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.74it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:48:00,146] \n",
      "947/1000 * Epoch 947 (train): loss_autoencoder=0.8453 | loss_discriminator=0.6931\n",
      "948/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.90it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:48:06,725] \n",
      "948/1000 * Epoch 948 (train): loss_autoencoder=0.8454 | loss_discriminator=0.6931\n",
      "949/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.79it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 07:48:13,429] \n",
      "949/1000 * Epoch 949 (train): loss_autoencoder=0.8454 | loss_discriminator=0.6931\n",
      "950/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.70it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 07:48:20,208] \n",
      "950/1000 * Epoch 950 (train): loss_autoencoder=0.8455 | loss_discriminator=0.6931\n",
      "951/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.86it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 07:48:26,867] \n",
      "951/1000 * Epoch 951 (train): loss_autoencoder=0.8455 | loss_discriminator=0.6931\n",
      "952/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.87it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:48:33,512] \n",
      "952/1000 * Epoch 952 (train): loss_autoencoder=0.8453 | loss_discriminator=0.6931\n",
      "953/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.77it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:48:40,229] \n",
      "953/1000 * Epoch 953 (train): loss_autoencoder=0.8454 | loss_discriminator=0.6931\n",
      "954/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.87it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:48:46,865] \n",
      "954/1000 * Epoch 954 (train): loss_autoencoder=0.8454 | loss_discriminator=0.6931\n",
      "955/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.80it/s, loss_autoencoder=0.843, loss_discriminator=0.693]\n",
      "[2020-10-29 07:48:53,564] \n",
      "955/1000 * Epoch 955 (train): loss_autoencoder=0.8454 | loss_discriminator=0.6931\n",
      "956/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.95it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:49:00,156] \n",
      "956/1000 * Epoch 956 (train): loss_autoencoder=0.8454 | loss_discriminator=0.6931\n",
      "957/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.83it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:49:06,827] \n",
      "957/1000 * Epoch 957 (train): loss_autoencoder=0.8454 | loss_discriminator=0.6931\n",
      "958/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.83it/s, loss_autoencoder=0.842, loss_discriminator=0.693]\n",
      "[2020-10-29 07:49:13,503] \n",
      "958/1000 * Epoch 958 (train): loss_autoencoder=0.8455 | loss_discriminator=0.6931\n",
      "959/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.84it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 07:49:20,170] \n",
      "959/1000 * Epoch 959 (train): loss_autoencoder=0.8454 | loss_discriminator=0.6931\n",
      "960/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.41it/s, loss_autoencoder=0.844, loss_discriminator=0.693]\n",
      "[2020-10-29 07:49:27,169] \n",
      "960/1000 * Epoch 960 (train): loss_autoencoder=0.8456 | loss_discriminator=0.6931\n",
      "961/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.77it/s, loss_autoencoder=0.842, loss_discriminator=0.693]\n",
      "[2020-10-29 07:49:33,886] \n",
      "961/1000 * Epoch 961 (train): loss_autoencoder=0.8454 | loss_discriminator=0.6931\n",
      "962/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.80it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 07:49:40,584] \n",
      "962/1000 * Epoch 962 (train): loss_autoencoder=0.8454 | loss_discriminator=0.6931\n",
      "963/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.78it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 07:49:47,301] \n",
      "963/1000 * Epoch 963 (train): loss_autoencoder=0.8454 | loss_discriminator=0.6931\n",
      "964/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  9.57it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:49:53,484] \n",
      "964/1000 * Epoch 964 (train): loss_autoencoder=0.8454 | loss_discriminator=0.6931\n",
      "965/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.81it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:50:00,137] \n",
      "965/1000 * Epoch 965 (train): loss_autoencoder=0.8454 | loss_discriminator=0.6931\n",
      "966/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.86it/s, loss_autoencoder=0.843, loss_discriminator=0.693]\n",
      "[2020-10-29 07:50:06,787] \n",
      "966/1000 * Epoch 966 (train): loss_autoencoder=0.8454 | loss_discriminator=0.6931\n",
      "967/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.83it/s, loss_autoencoder=0.843, loss_discriminator=0.693]\n",
      "[2020-10-29 07:50:13,456] \n",
      "967/1000 * Epoch 967 (train): loss_autoencoder=0.8454 | loss_discriminator=0.6931\n",
      "968/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.82it/s, loss_autoencoder=0.844, loss_discriminator=0.693]\n",
      "[2020-10-29 07:50:20,149] \n",
      "968/1000 * Epoch 968 (train): loss_autoencoder=0.8455 | loss_discriminator=0.6931\n",
      "969/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  9.07it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:50:26,650] \n",
      "969/1000 * Epoch 969 (train): loss_autoencoder=0.8454 | loss_discriminator=0.6931\n",
      "970/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.84it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:50:33,309] \n",
      "970/1000 * Epoch 970 (train): loss_autoencoder=0.8453 | loss_discriminator=0.6931\n",
      "971/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.58it/s, loss_autoencoder=0.850, loss_discriminator=0.693]\n",
      "[2020-10-29 07:50:40,183] \n",
      "971/1000 * Epoch 971 (train): loss_autoencoder=0.8454 | loss_discriminator=0.6931\n",
      "972/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.81it/s, loss_autoencoder=0.843, loss_discriminator=0.693]\n",
      "[2020-10-29 07:50:46,868] \n",
      "972/1000 * Epoch 972 (train): loss_autoencoder=0.8453 | loss_discriminator=0.6931\n",
      "973/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.86it/s, loss_autoencoder=0.843, loss_discriminator=0.693]\n",
      "[2020-10-29 07:50:53,518] \n",
      "973/1000 * Epoch 973 (train): loss_autoencoder=0.8454 | loss_discriminator=0.6931\n",
      "974/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.71it/s, loss_autoencoder=0.843, loss_discriminator=0.693]\n",
      "[2020-10-29 07:51:00,242] \n",
      "974/1000 * Epoch 974 (train): loss_autoencoder=0.8454 | loss_discriminator=0.6931\n",
      "975/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.32it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:51:07,320] \n",
      "975/1000 * Epoch 975 (train): loss_autoencoder=0.8454 | loss_discriminator=0.6931\n",
      "976/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.66it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:51:14,125] \n",
      "976/1000 * Epoch 976 (train): loss_autoencoder=0.8453 | loss_discriminator=0.6931\n",
      "977/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.53it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:51:20,993] \n",
      "977/1000 * Epoch 977 (train): loss_autoencoder=0.8454 | loss_discriminator=0.6931\n",
      "978/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.56it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 07:51:27,880] \n",
      "978/1000 * Epoch 978 (train): loss_autoencoder=0.8453 | loss_discriminator=0.6931\n",
      "979/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.77it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 07:51:34,592] \n",
      "979/1000 * Epoch 979 (train): loss_autoencoder=0.8454 | loss_discriminator=0.6931\n",
      "980/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.80it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 07:51:41,295] \n",
      "980/1000 * Epoch 980 (train): loss_autoencoder=0.8455 | loss_discriminator=0.6931\n",
      "981/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.73it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:51:48,047] \n",
      "981/1000 * Epoch 981 (train): loss_autoencoder=0.8453 | loss_discriminator=0.6931\n",
      "982/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.64it/s, loss_autoencoder=0.847, loss_discriminator=0.693]\n",
      "[2020-10-29 07:51:54,866] \n",
      "982/1000 * Epoch 982 (train): loss_autoencoder=0.8452 | loss_discriminator=0.6931\n",
      "983/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.77it/s, loss_autoencoder=0.844, loss_discriminator=0.693]\n",
      "[2020-10-29 07:52:01,591] \n",
      "983/1000 * Epoch 983 (train): loss_autoencoder=0.8454 | loss_discriminator=0.6931\n",
      "984/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.80it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:52:08,296] \n",
      "984/1000 * Epoch 984 (train): loss_autoencoder=0.8454 | loss_discriminator=0.6931\n",
      "985/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.62it/s, loss_autoencoder=0.850, loss_discriminator=0.693]\n",
      "[2020-10-29 07:52:15,121] \n",
      "985/1000 * Epoch 985 (train): loss_autoencoder=0.8454 | loss_discriminator=0.6931\n",
      "986/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.33it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:52:22,151] \n",
      "986/1000 * Epoch 986 (train): loss_autoencoder=0.8453 | loss_discriminator=0.6931\n",
      "987/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.51it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:52:29,067] \n",
      "987/1000 * Epoch 987 (train): loss_autoencoder=0.8454 | loss_discriminator=0.6931\n",
      "988/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.83it/s, loss_autoencoder=0.843, loss_discriminator=0.693]\n",
      "[2020-10-29 07:52:35,743] \n",
      "988/1000 * Epoch 988 (train): loss_autoencoder=0.8453 | loss_discriminator=0.6931\n",
      "989/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.63it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:52:42,568] \n",
      "989/1000 * Epoch 989 (train): loss_autoencoder=0.8453 | loss_discriminator=0.6931\n",
      "990/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.71it/s, loss_autoencoder=0.841, loss_discriminator=0.693]\n",
      "[2020-10-29 07:52:49,339] \n",
      "990/1000 * Epoch 990 (train): loss_autoencoder=0.8453 | loss_discriminator=0.6931\n",
      "991/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.75it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:52:56,072] \n",
      "991/1000 * Epoch 991 (train): loss_autoencoder=0.8453 | loss_discriminator=0.6931\n",
      "992/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.88it/s, loss_autoencoder=0.843, loss_discriminator=0.693]\n",
      "[2020-10-29 07:53:02,700] \n",
      "992/1000 * Epoch 992 (train): loss_autoencoder=0.8453 | loss_discriminator=0.6931\n",
      "993/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.76it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:53:09,420] \n",
      "993/1000 * Epoch 993 (train): loss_autoencoder=0.8453 | loss_discriminator=0.6931\n",
      "994/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.79it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:53:16,128] \n",
      "994/1000 * Epoch 994 (train): loss_autoencoder=0.8454 | loss_discriminator=0.6931\n",
      "995/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.86it/s, loss_autoencoder=0.846, loss_discriminator=0.693]\n",
      "[2020-10-29 07:53:22,775] \n",
      "995/1000 * Epoch 995 (train): loss_autoencoder=0.8454 | loss_discriminator=0.6931\n",
      "996/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.53it/s, loss_autoencoder=0.843, loss_discriminator=0.693]\n",
      "[2020-10-29 07:53:29,681] \n",
      "996/1000 * Epoch 996 (train): loss_autoencoder=0.8453 | loss_discriminator=0.6931\n",
      "997/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.76it/s, loss_autoencoder=0.848, loss_discriminator=0.693]\n",
      "[2020-10-29 07:53:36,407] \n",
      "997/1000 * Epoch 997 (train): loss_autoencoder=0.8453 | loss_discriminator=0.6931\n",
      "998/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.83it/s, loss_autoencoder=0.843, loss_discriminator=0.693]\n",
      "[2020-10-29 07:53:43,075] \n",
      "998/1000 * Epoch 998 (train): loss_autoencoder=0.8453 | loss_discriminator=0.6931\n",
      "999/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.86it/s, loss_autoencoder=0.845, loss_discriminator=0.693]\n",
      "[2020-10-29 07:53:49,754] \n",
      "999/1000 * Epoch 999 (train): loss_autoencoder=0.8453 | loss_discriminator=0.6931\n",
      "1000/1000 * Epoch (train): 100% 58/58 [00:06<00:00,  8.76it/s, loss_autoencoder=0.849, loss_discriminator=0.693]\n",
      "[2020-10-29 07:53:56,485] \n",
      "1000/1000 * Epoch 1000 (train): loss_autoencoder=0.8453 | loss_discriminator=0.6931\n",
      "Top best models:\n",
      "logs/20201029-060129/checkpoints/train.982.pth\t0.8452\n"
     ]
    }
   ],
   "source": [
    "runner.train(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    loaders=loaders,\n",
    "    callbacks=callbacks,\n",
    "    num_epochs=1000,\n",
    "    verbose=True,\n",
    "    logdir=logdir,\n",
    "    main_metric=\"loss_autoencoder\",\n",
    "    minimize_metric=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
